02/16 05:03:42 AM | 
02/16 05:03:42 AM | Parameters:
02/16 05:03:42 AM | ALPHA_LR=3e-05
02/16 05:03:42 AM | ALPHA_WEIGHT_DECAY=0.0001
02/16 05:03:42 AM | BATCH_SIZE=64
02/16 05:03:42 AM | DATA_PATH=/home/a2sriniv/featurize/data/
02/16 05:03:42 AM | DATASET1=cifar10
02/16 05:03:42 AM | DATASET2=cifar100
02/16 05:03:42 AM | EPOCHS=50
02/16 05:03:42 AM | GPUS=[0, 1]
02/16 05:03:42 AM | INIT_CHANNELS=16
02/16 05:03:42 AM | LAYERS=8
02/16 05:03:42 AM | NAME=cifar
02/16 05:03:42 AM | PATH=searches/cifar
02/16 05:03:42 AM | PLOT_PATH=searches/cifar/plots
02/16 05:03:42 AM | PRINT_FREQ=50
02/16 05:03:42 AM | SEED=2
02/16 05:03:42 AM | W_GRAD_CLIP=5.0
02/16 05:03:42 AM | W_LR=0.025
02/16 05:03:42 AM | W_LR_MIN=0.001
02/16 05:03:42 AM | W_MOMENTUM=0.9
02/16 05:03:42 AM | W_WEIGHT_DECAY=0.0003
02/16 05:03:42 AM | WORKERS=0
02/16 05:03:42 AM | 
02/16 05:03:42 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 05:03:59 AM | Train: [ 1/50] Step 000/078 Loss1 5.037 Prec1@(1,5) (7.8%, 62.5%)
02/16 05:10:31 AM | Train: [ 1/50] Step 050/078 Loss1 4.787 Prec1@(1,5) (26.3%, 79.9%)
02/16 05:14:05 AM | Train: [ 1/50] Step 078/078 Loss1 4.715 Prec1@(1,5) (28.4%, 81.4%)
02/16 05:14:05 AM | Train: [ 1/50] Final Prec1@1 28.4200%
02/16 05:14:05 AM | Valid: [ 1/50] Step 000/078 Loss1 2.318 Prec1@(1,5) (21.9%, 75.0%)
02/16 05:14:18 AM | Valid: [ 1/50] Step 050/078 Loss1 2.045 Prec1@(1,5) (29.7%, 80.4%)
02/16 05:14:24 AM | Valid: [ 1/50] Step 078/078 Loss1 2.027 Prec1@(1,5) (29.8%, 80.7%)
02/16 05:14:24 AM | Valid: [ 1/50] Final Prec1@1 29.8400%
02/16 05:14:24 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_3x3', 3)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 1), ('dil_conv_5x5', 0)], [('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('max_pool_3x3', 1), ('sep_conv_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1252, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1252, 0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1250, 0.1246, 0.1248, 0.1253, 0.1248, 0.1250, 0.1252, 0.1254],
        [0.1249, 0.1249, 0.1248, 0.1251, 0.1252, 0.1250, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1248, 0.1250, 0.1250, 0.1250, 0.1253, 0.1252, 0.1250],
        [0.1249, 0.1249, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1251],
        [0.1249, 0.1249, 0.1250, 0.1252, 0.1250, 0.1251, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1248, 0.1250, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1249, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1254, 0.1251, 0.1251, 0.1248, 0.1250],
        [0.1249, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1253, 0.1249, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1247, 0.1249, 0.1251, 0.1252, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 05:14:33 AM | Train: [ 2/50] Step 000/078 Loss1 4.504 Prec1@(1,5) (39.1%, 89.1%)
02/16 05:20:51 AM | Train: [ 2/50] Step 050/078 Loss1 4.417 Prec1@(1,5) (37.0%, 88.3%)
02/16 05:24:24 AM | Train: [ 2/50] Step 078/078 Loss1 4.379 Prec1@(1,5) (38.7%, 88.9%)
02/16 05:24:24 AM | Train: [ 2/50] Final Prec1@1 38.7000%
02/16 05:24:25 AM | Valid: [ 2/50] Step 000/078 Loss1 1.850 Prec1@(1,5) (34.4%, 87.5%)
02/16 05:24:36 AM | Valid: [ 2/50] Step 050/078 Loss1 1.664 Prec1@(1,5) (41.8%, 88.7%)
02/16 05:24:43 AM | Valid: [ 2/50] Step 078/078 Loss1 1.692 Prec1@(1,5) (40.9%, 88.6%)
02/16 05:24:43 AM | Valid: [ 2/50] Final Prec1@1 40.9400%
02/16 05:24:43 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_5x5', 2)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 4)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1248, 0.1249, 0.1253, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1250, 0.1245, 0.1247, 0.1253, 0.1249, 0.1250, 0.1251, 0.1254],
        [0.1248, 0.1248, 0.1248, 0.1252, 0.1253, 0.1250, 0.1251, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1248, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1252],
        [0.1249, 0.1247, 0.1250, 0.1250, 0.1250, 0.1253, 0.1252, 0.1250],
        [0.1248, 0.1248, 0.1250, 0.1249, 0.1251, 0.1251, 0.1252, 0.1252],
        [0.1249, 0.1249, 0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1248, 0.1247, 0.1250, 0.1252, 0.1251, 0.1250, 0.1253],
        [0.1249, 0.1250, 0.1251, 0.1249, 0.1250, 0.1249, 0.1249, 0.1253],
        [0.1249, 0.1248, 0.1249, 0.1252, 0.1250, 0.1252, 0.1250, 0.1251],
        [0.1247, 0.1248, 0.1248, 0.1255, 0.1252, 0.1252, 0.1248, 0.1251],
        [0.1248, 0.1248, 0.1249, 0.1250, 0.1250, 0.1252, 0.1252, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1248, 0.1250, 0.1252, 0.1249, 0.1250, 0.1249, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1249],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1247, 0.1249, 0.1251, 0.1252, 0.1248, 0.1252, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1253, 0.1249, 0.1250, 0.1248],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1249, 0.1251, 0.1249],
        [0.1251, 0.1250, 0.1251, 0.1250, 0.1247, 0.1252, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1249],
        [0.1252, 0.1248, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1249, 0.1250, 0.1251, 0.1248, 0.1250, 0.1251, 0.1252],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 05:24:51 AM | Train: [ 3/50] Step 000/078 Loss1 4.446 Prec1@(1,5) (34.4%, 89.1%)
02/16 05:30:58 AM | Train: [ 3/50] Step 050/078 Loss1 4.211 Prec1@(1,5) (44.5%, 91.4%)
02/16 05:34:27 AM | Train: [ 3/50] Step 078/078 Loss1 4.182 Prec1@(1,5) (45.4%, 91.7%)
02/16 05:34:27 AM | Train: [ 3/50] Final Prec1@1 45.3600%
02/16 05:34:27 AM | Valid: [ 3/50] Step 000/078 Loss1 1.939 Prec1@(1,5) (29.7%, 90.6%)
02/16 05:34:40 AM | Valid: [ 3/50] Step 050/078 Loss1 1.510 Prec1@(1,5) (48.0%, 90.5%)
02/16 05:34:47 AM | Valid: [ 3/50] Step 078/078 Loss1 1.509 Prec1@(1,5) (47.5%, 91.1%)
02/16 05:34:47 AM | Valid: [ 3/50] Final Prec1@1 47.4800%
02/16 05:34:47 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_5x5', 2)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 4)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1249, 0.1248, 0.1250, 0.1249, 0.1253, 0.1249, 0.1251],
        [0.1249, 0.1248, 0.1248, 0.1249, 0.1254, 0.1251, 0.1251, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1248, 0.1252, 0.1249, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1244, 0.1247, 0.1253, 0.1249, 0.1250, 0.1251, 0.1254],
        [0.1247, 0.1246, 0.1247, 0.1253, 0.1253, 0.1251, 0.1252, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1252],
        [0.1249, 0.1246, 0.1249, 0.1250, 0.1250, 0.1254, 0.1253, 0.1250],
        [0.1247, 0.1246, 0.1249, 0.1250, 0.1251, 0.1252, 0.1253, 0.1252],
        [0.1248, 0.1247, 0.1249, 0.1252, 0.1252, 0.1252, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1247, 0.1246, 0.1251, 0.1252, 0.1251, 0.1250, 0.1253],
        [0.1249, 0.1249, 0.1251, 0.1249, 0.1251, 0.1249, 0.1249, 0.1254],
        [0.1248, 0.1247, 0.1248, 0.1253, 0.1250, 0.1252, 0.1251, 0.1252],
        [0.1246, 0.1246, 0.1247, 0.1255, 0.1253, 0.1253, 0.1248, 0.1251],
        [0.1246, 0.1246, 0.1248, 0.1250, 0.1251, 0.1253, 0.1252, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1248, 0.1249, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1247, 0.1250, 0.1252, 0.1250, 0.1250, 0.1249, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1249],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1247, 0.1248, 0.1249, 0.1251, 0.1250, 0.1252, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1247, 0.1250, 0.1252, 0.1252, 0.1247, 0.1251, 0.1248],
        [0.1251, 0.1248, 0.1250, 0.1251, 0.1253, 0.1249, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1251, 0.1249, 0.1250, 0.1249, 0.1252, 0.1249],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1252, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1249, 0.1251, 0.1251, 0.1248, 0.1249, 0.1249],
        [0.1252, 0.1247, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250, 0.1251, 0.1252],
        [0.1251, 0.1248, 0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1249],
        [0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 05:34:55 AM | Train: [ 4/50] Step 000/078 Loss1 4.193 Prec1@(1,5) (39.1%, 89.1%)
02/16 05:41:30 AM | Train: [ 4/50] Step 050/078 Loss1 4.085 Prec1@(1,5) (49.8%, 92.9%)
02/16 05:45:00 AM | Train: [ 4/50] Step 078/078 Loss1 4.055 Prec1@(1,5) (50.0%, 93.0%)
02/16 05:45:00 AM | Train: [ 4/50] Final Prec1@1 49.9800%
02/16 05:45:00 AM | Valid: [ 4/50] Step 000/078 Loss1 1.582 Prec1@(1,5) (43.8%, 92.2%)
02/16 05:45:13 AM | Valid: [ 4/50] Step 050/078 Loss1 1.458 Prec1@(1,5) (47.2%, 92.7%)
02/16 05:45:20 AM | Valid: [ 4/50] Step 078/078 Loss1 1.451 Prec1@(1,5) (47.7%, 92.6%)
02/16 05:45:20 AM | Valid: [ 4/50] Final Prec1@1 47.7000%
02/16 05:45:20 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('dil_conv_3x3', 1), ('dil_conv_5x5', 2)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1247, 0.1247, 0.1250, 0.1250, 0.1254, 0.1250, 0.1251],
        [0.1248, 0.1246, 0.1247, 0.1249, 0.1255, 0.1251, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1247, 0.1247, 0.1253, 0.1250, 0.1251, 0.1251, 0.1251],
        [0.1250, 0.1243, 0.1246, 0.1253, 0.1251, 0.1251, 0.1252, 0.1255],
        [0.1246, 0.1245, 0.1246, 0.1253, 0.1253, 0.1251, 0.1253, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1245, 0.1248, 0.1252, 0.1251, 0.1252, 0.1249, 0.1253],
        [0.1249, 0.1245, 0.1248, 0.1250, 0.1251, 0.1255, 0.1252, 0.1251],
        [0.1247, 0.1245, 0.1248, 0.1251, 0.1251, 0.1253, 0.1253, 0.1253],
        [0.1247, 0.1246, 0.1248, 0.1252, 0.1253, 0.1252, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1245, 0.1245, 0.1252, 0.1253, 0.1252, 0.1250, 0.1254],
        [0.1248, 0.1247, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1254],
        [0.1246, 0.1245, 0.1247, 0.1253, 0.1251, 0.1253, 0.1251, 0.1253],
        [0.1244, 0.1244, 0.1246, 0.1256, 0.1254, 0.1253, 0.1249, 0.1253],
        [0.1245, 0.1244, 0.1247, 0.1251, 0.1252, 0.1253, 0.1254, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1248, 0.1248, 0.1252, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1250, 0.1246, 0.1250, 0.1252, 0.1250, 0.1249, 0.1251, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1254, 0.1247, 0.1251, 0.1249, 0.1252, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1247, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252],
        [0.1250, 0.1246, 0.1248, 0.1249, 0.1252, 0.1251, 0.1252, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1254, 0.1246, 0.1250, 0.1252, 0.1253, 0.1247, 0.1251, 0.1247],
        [0.1250, 0.1247, 0.1250, 0.1251, 0.1253, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1248, 0.1250, 0.1249, 0.1251, 0.1249, 0.1252, 0.1250],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1248, 0.1252, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1249, 0.1249, 0.1251, 0.1251, 0.1248, 0.1250, 0.1248],
        [0.1252, 0.1246, 0.1251, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1249, 0.1246, 0.1250, 0.1251, 0.1249, 0.1251, 0.1252, 0.1252],
        [0.1250, 0.1246, 0.1249, 0.1252, 0.1250, 0.1253, 0.1251, 0.1249],
        [0.1248, 0.1247, 0.1249, 0.1252, 0.1250, 0.1252, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 05:45:28 AM | Train: [ 5/50] Step 000/078 Loss1 3.860 Prec1@(1,5) (56.2%, 95.3%)
02/16 05:51:26 AM | Train: [ 5/50] Step 050/078 Loss1 3.951 Prec1@(1,5) (53.1%, 94.0%)
02/16 05:54:46 AM | Train: [ 5/50] Step 078/078 Loss1 3.928 Prec1@(1,5) (53.3%, 94.3%)
02/16 05:54:46 AM | Train: [ 5/50] Final Prec1@1 53.2800%
02/16 05:54:46 AM | Valid: [ 5/50] Step 000/078 Loss1 1.286 Prec1@(1,5) (51.6%, 95.3%)
02/16 05:54:58 AM | Valid: [ 5/50] Step 050/078 Loss1 1.366 Prec1@(1,5) (51.5%, 93.9%)
02/16 05:55:04 AM | Valid: [ 5/50] Step 078/078 Loss1 1.357 Prec1@(1,5) (52.0%, 93.9%)
02/16 05:55:04 AM | Valid: [ 5/50] Final Prec1@1 52.0000%
02/16 05:55:04 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_5x5', 2)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1245, 0.1246, 0.1250, 0.1251, 0.1256, 0.1250, 0.1251],
        [0.1248, 0.1245, 0.1246, 0.1249, 0.1256, 0.1252, 0.1252, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1245, 0.1245, 0.1255, 0.1251, 0.1251, 0.1252, 0.1251],
        [0.1249, 0.1241, 0.1245, 0.1254, 0.1252, 0.1251, 0.1252, 0.1255],
        [0.1245, 0.1243, 0.1246, 0.1254, 0.1254, 0.1252, 0.1253, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1243, 0.1246, 0.1253, 0.1251, 0.1252, 0.1251, 0.1253],
        [0.1249, 0.1243, 0.1247, 0.1250, 0.1251, 0.1256, 0.1253, 0.1251],
        [0.1246, 0.1243, 0.1248, 0.1251, 0.1251, 0.1253, 0.1254, 0.1254],
        [0.1246, 0.1244, 0.1247, 0.1253, 0.1254, 0.1253, 0.1251, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1243, 0.1244, 0.1253, 0.1253, 0.1252, 0.1251, 0.1255],
        [0.1248, 0.1245, 0.1249, 0.1251, 0.1253, 0.1249, 0.1251, 0.1255],
        [0.1245, 0.1243, 0.1246, 0.1254, 0.1252, 0.1254, 0.1252, 0.1255],
        [0.1243, 0.1242, 0.1245, 0.1257, 0.1255, 0.1254, 0.1250, 0.1254],
        [0.1243, 0.1242, 0.1245, 0.1252, 0.1253, 0.1255, 0.1256, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1251, 0.1247, 0.1248, 0.1253, 0.1251, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1245, 0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1255, 0.1247, 0.1251, 0.1249, 0.1252, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1246, 0.1251, 0.1251, 0.1251, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1244, 0.1248, 0.1249, 0.1252, 0.1251, 0.1253, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1255, 0.1246, 0.1249, 0.1251, 0.1254, 0.1247, 0.1252, 0.1247],
        [0.1251, 0.1246, 0.1250, 0.1251, 0.1253, 0.1249, 0.1250, 0.1250],
        [0.1250, 0.1247, 0.1250, 0.1249, 0.1252, 0.1249, 0.1253, 0.1250],
        [0.1250, 0.1246, 0.1249, 0.1253, 0.1249, 0.1253, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1254, 0.1248, 0.1247, 0.1252, 0.1251, 0.1248, 0.1251, 0.1248],
        [0.1251, 0.1245, 0.1251, 0.1253, 0.1250, 0.1250, 0.1249, 0.1251],
        [0.1249, 0.1245, 0.1249, 0.1251, 0.1249, 0.1251, 0.1252, 0.1253],
        [0.1250, 0.1244, 0.1248, 0.1253, 0.1251, 0.1253, 0.1251, 0.1250],
        [0.1248, 0.1245, 0.1248, 0.1252, 0.1251, 0.1254, 0.1252, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 05:55:11 AM | Train: [ 6/50] Step 000/078 Loss1 3.918 Prec1@(1,5) (51.6%, 95.3%)
02/16 06:01:07 AM | Train: [ 6/50] Step 050/078 Loss1 3.823 Prec1@(1,5) (56.3%, 95.5%)
02/16 06:04:22 AM | Train: [ 6/50] Step 078/078 Loss1 3.809 Prec1@(1,5) (57.1%, 95.3%)
02/16 06:04:22 AM | Train: [ 6/50] Final Prec1@1 57.1200%
02/16 06:04:23 AM | Valid: [ 6/50] Step 000/078 Loss1 1.445 Prec1@(1,5) (48.4%, 89.1%)
02/16 06:04:34 AM | Valid: [ 6/50] Step 050/078 Loss1 1.284 Prec1@(1,5) (53.6%, 93.9%)
02/16 06:04:40 AM | Valid: [ 6/50] Step 078/078 Loss1 1.277 Prec1@(1,5) (54.1%, 94.1%)
02/16 06:04:40 AM | Valid: [ 6/50] Final Prec1@1 54.0600%
02/16 06:04:40 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('dil_conv_3x3', 4), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1244, 0.1245, 0.1251, 0.1252, 0.1257, 0.1251, 0.1252],
        [0.1248, 0.1244, 0.1246, 0.1249, 0.1257, 0.1253, 0.1252, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1244, 0.1244, 0.1256, 0.1252, 0.1251, 0.1252, 0.1251],
        [0.1249, 0.1240, 0.1244, 0.1254, 0.1253, 0.1251, 0.1252, 0.1256],
        [0.1244, 0.1241, 0.1245, 0.1255, 0.1255, 0.1254, 0.1252, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1242, 0.1246, 0.1253, 0.1251, 0.1253, 0.1251, 0.1254],
        [0.1249, 0.1243, 0.1247, 0.1250, 0.1251, 0.1256, 0.1253, 0.1251],
        [0.1245, 0.1242, 0.1247, 0.1251, 0.1250, 0.1254, 0.1255, 0.1255],
        [0.1245, 0.1242, 0.1246, 0.1253, 0.1255, 0.1254, 0.1251, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1242, 0.1243, 0.1254, 0.1253, 0.1252, 0.1250, 0.1256],
        [0.1247, 0.1244, 0.1248, 0.1251, 0.1254, 0.1249, 0.1251, 0.1256],
        [0.1244, 0.1241, 0.1245, 0.1254, 0.1253, 0.1255, 0.1252, 0.1256],
        [0.1242, 0.1241, 0.1244, 0.1258, 0.1255, 0.1255, 0.1250, 0.1255],
        [0.1242, 0.1240, 0.1243, 0.1253, 0.1253, 0.1256, 0.1257, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1251, 0.1247, 0.1248, 0.1252, 0.1251, 0.1249, 0.1251, 0.1249],
        [0.1249, 0.1244, 0.1250, 0.1252, 0.1250, 0.1248, 0.1252, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1256, 0.1248, 0.1250, 0.1248, 0.1252, 0.1249, 0.1249, 0.1248],
        [0.1249, 0.1245, 0.1252, 0.1251, 0.1251, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1243, 0.1248, 0.1249, 0.1252, 0.1252, 0.1253, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1256, 0.1246, 0.1249, 0.1251, 0.1254, 0.1247, 0.1252, 0.1246],
        [0.1251, 0.1245, 0.1250, 0.1251, 0.1254, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1247, 0.1250, 0.1249, 0.1252, 0.1250, 0.1253, 0.1249],
        [0.1250, 0.1245, 0.1249, 0.1254, 0.1251, 0.1253, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1254, 0.1248, 0.1246, 0.1253, 0.1251, 0.1249, 0.1252, 0.1247],
        [0.1251, 0.1244, 0.1250, 0.1254, 0.1251, 0.1251, 0.1249, 0.1251],
        [0.1249, 0.1243, 0.1249, 0.1252, 0.1250, 0.1251, 0.1253, 0.1253],
        [0.1249, 0.1242, 0.1247, 0.1254, 0.1252, 0.1254, 0.1251, 0.1250],
        [0.1247, 0.1244, 0.1247, 0.1252, 0.1252, 0.1255, 0.1253, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 06:04:48 AM | Train: [ 7/50] Step 000/078 Loss1 3.551 Prec1@(1,5) (64.1%, 100.0%)
02/16 06:10:43 AM | Train: [ 7/50] Step 050/078 Loss1 3.697 Prec1@(1,5) (60.7%, 96.0%)
02/16 06:14:03 AM | Train: [ 7/50] Step 078/078 Loss1 3.681 Prec1@(1,5) (61.2%, 96.2%)
02/16 06:14:03 AM | Train: [ 7/50] Final Prec1@1 61.1800%
02/16 06:14:04 AM | Valid: [ 7/50] Step 000/078 Loss1 1.382 Prec1@(1,5) (48.4%, 98.4%)
02/16 06:14:14 AM | Valid: [ 7/50] Step 050/078 Loss1 1.286 Prec1@(1,5) (54.4%, 94.4%)
02/16 06:14:20 AM | Valid: [ 7/50] Step 078/078 Loss1 1.281 Prec1@(1,5) (54.8%, 94.3%)
02/16 06:14:20 AM | Valid: [ 7/50] Final Prec1@1 54.7600%
02/16 06:14:20 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 3), ('dil_conv_3x3', 1)], [('dil_conv_5x5', 4), ('sep_conv_3x3', 3)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('dil_conv_3x3', 4), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1242, 0.1244, 0.1251, 0.1253, 0.1257, 0.1252, 0.1253],
        [0.1248, 0.1243, 0.1245, 0.1248, 0.1258, 0.1252, 0.1253, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1242, 0.1243, 0.1257, 0.1253, 0.1252, 0.1252, 0.1253],
        [0.1249, 0.1239, 0.1244, 0.1254, 0.1254, 0.1252, 0.1252, 0.1256],
        [0.1242, 0.1239, 0.1244, 0.1256, 0.1256, 0.1255, 0.1252, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1240, 0.1244, 0.1254, 0.1251, 0.1253, 0.1252, 0.1254],
        [0.1249, 0.1242, 0.1247, 0.1249, 0.1252, 0.1256, 0.1253, 0.1251],
        [0.1244, 0.1240, 0.1247, 0.1251, 0.1251, 0.1255, 0.1256, 0.1256],
        [0.1244, 0.1241, 0.1245, 0.1253, 0.1256, 0.1255, 0.1251, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1247, 0.1240, 0.1242, 0.1255, 0.1254, 0.1252, 0.1252, 0.1258],
        [0.1246, 0.1243, 0.1247, 0.1251, 0.1254, 0.1249, 0.1253, 0.1257],
        [0.1242, 0.1239, 0.1244, 0.1255, 0.1254, 0.1256, 0.1253, 0.1257],
        [0.1240, 0.1238, 0.1243, 0.1258, 0.1257, 0.1256, 0.1252, 0.1257],
        [0.1239, 0.1238, 0.1242, 0.1254, 0.1254, 0.1257, 0.1258, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1251, 0.1247, 0.1247, 0.1253, 0.1251, 0.1249, 0.1251, 0.1250],
        [0.1248, 0.1243, 0.1250, 0.1252, 0.1251, 0.1248, 0.1252, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1256, 0.1247, 0.1251, 0.1249, 0.1252, 0.1249, 0.1248, 0.1248],
        [0.1249, 0.1243, 0.1252, 0.1250, 0.1252, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1242, 0.1248, 0.1249, 0.1252, 0.1252, 0.1253, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1257, 0.1246, 0.1248, 0.1251, 0.1254, 0.1246, 0.1252, 0.1246],
        [0.1250, 0.1244, 0.1250, 0.1250, 0.1255, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1245, 0.1250, 0.1248, 0.1253, 0.1249, 0.1254, 0.1250],
        [0.1249, 0.1243, 0.1248, 0.1254, 0.1252, 0.1254, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1254, 0.1247, 0.1246, 0.1253, 0.1251, 0.1249, 0.1254, 0.1246],
        [0.1250, 0.1243, 0.1250, 0.1254, 0.1251, 0.1251, 0.1249, 0.1252],
        [0.1250, 0.1242, 0.1249, 0.1253, 0.1250, 0.1250, 0.1253, 0.1253],
        [0.1248, 0.1241, 0.1246, 0.1255, 0.1252, 0.1255, 0.1251, 0.1250],
        [0.1246, 0.1242, 0.1246, 0.1252, 0.1253, 0.1255, 0.1254, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 06:14:28 AM | Train: [ 8/50] Step 000/078 Loss1 3.571 Prec1@(1,5) (60.9%, 98.4%)
02/16 06:20:26 AM | Train: [ 8/50] Step 050/078 Loss1 3.619 Prec1@(1,5) (63.1%, 96.2%)
02/16 06:23:47 AM | Train: [ 8/50] Step 078/078 Loss1 3.631 Prec1@(1,5) (62.4%, 96.3%)
02/16 06:23:47 AM | Train: [ 8/50] Final Prec1@1 62.3600%
02/16 06:23:47 AM | Valid: [ 8/50] Step 000/078 Loss1 1.299 Prec1@(1,5) (56.2%, 93.8%)
02/16 06:23:57 AM | Valid: [ 8/50] Step 050/078 Loss1 1.240 Prec1@(1,5) (57.3%, 95.1%)
02/16 06:24:03 AM | Valid: [ 8/50] Step 078/078 Loss1 1.236 Prec1@(1,5) (57.1%, 94.9%)
02/16 06:24:03 AM | Valid: [ 8/50] Final Prec1@1 57.1200%
02/16 06:24:03 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('sep_conv_3x3', 2)], [('sep_conv_5x5', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('sep_conv_5x5', 3)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1248, 0.1240, 0.1243, 0.1251, 0.1254, 0.1258, 0.1253, 0.1253],
        [0.1247, 0.1241, 0.1245, 0.1248, 0.1259, 0.1253, 0.1254, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1240, 0.1242, 0.1260, 0.1254, 0.1252, 0.1252, 0.1253],
        [0.1248, 0.1237, 0.1243, 0.1255, 0.1256, 0.1252, 0.1253, 0.1256],
        [0.1240, 0.1237, 0.1243, 0.1257, 0.1257, 0.1257, 0.1253, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1239, 0.1243, 0.1255, 0.1251, 0.1254, 0.1252, 0.1256],
        [0.1248, 0.1241, 0.1246, 0.1250, 0.1253, 0.1257, 0.1253, 0.1252],
        [0.1242, 0.1238, 0.1246, 0.1251, 0.1251, 0.1256, 0.1257, 0.1258],
        [0.1242, 0.1238, 0.1244, 0.1253, 0.1258, 0.1257, 0.1252, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1246, 0.1238, 0.1240, 0.1257, 0.1255, 0.1252, 0.1252, 0.1259],
        [0.1245, 0.1241, 0.1246, 0.1252, 0.1256, 0.1249, 0.1254, 0.1258],
        [0.1239, 0.1236, 0.1242, 0.1256, 0.1255, 0.1257, 0.1254, 0.1259],
        [0.1237, 0.1236, 0.1241, 0.1258, 0.1259, 0.1257, 0.1253, 0.1259],
        [0.1236, 0.1235, 0.1239, 0.1256, 0.1255, 0.1258, 0.1261, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1252, 0.1246, 0.1247, 0.1254, 0.1251, 0.1249, 0.1252, 0.1250],
        [0.1248, 0.1242, 0.1250, 0.1253, 0.1251, 0.1248, 0.1252, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1257, 0.1247, 0.1251, 0.1248, 0.1252, 0.1249, 0.1249, 0.1247],
        [0.1249, 0.1243, 0.1253, 0.1250, 0.1253, 0.1250, 0.1251, 0.1252],
        [0.1250, 0.1240, 0.1247, 0.1249, 0.1253, 0.1253, 0.1255, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1257, 0.1245, 0.1249, 0.1251, 0.1255, 0.1245, 0.1253, 0.1246],
        [0.1251, 0.1244, 0.1251, 0.1249, 0.1255, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1243, 0.1250, 0.1248, 0.1254, 0.1250, 0.1255, 0.1251],
        [0.1248, 0.1242, 0.1247, 0.1255, 0.1252, 0.1255, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1255, 0.1246, 0.1245, 0.1253, 0.1251, 0.1249, 0.1254, 0.1246],
        [0.1250, 0.1241, 0.1250, 0.1254, 0.1251, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1240, 0.1249, 0.1254, 0.1249, 0.1250, 0.1255, 0.1253],
        [0.1248, 0.1239, 0.1246, 0.1256, 0.1253, 0.1255, 0.1252, 0.1251],
        [0.1246, 0.1241, 0.1246, 0.1252, 0.1253, 0.1256, 0.1254, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 06:24:11 AM | Train: [ 9/50] Step 000/078 Loss1 3.512 Prec1@(1,5) (60.9%, 98.4%)
02/16 06:30:09 AM | Train: [ 9/50] Step 050/078 Loss1 3.522 Prec1@(1,5) (65.4%, 97.2%)
02/16 06:33:30 AM | Train: [ 9/50] Step 078/078 Loss1 3.509 Prec1@(1,5) (65.7%, 97.0%)
02/16 06:33:30 AM | Train: [ 9/50] Final Prec1@1 65.7000%
02/16 06:33:30 AM | Valid: [ 9/50] Step 000/078 Loss1 1.042 Prec1@(1,5) (62.5%, 98.4%)
02/16 06:33:41 AM | Valid: [ 9/50] Step 050/078 Loss1 1.159 Prec1@(1,5) (59.9%, 95.6%)
02/16 06:33:47 AM | Valid: [ 9/50] Step 078/078 Loss1 1.179 Prec1@(1,5) (59.5%, 95.7%)
02/16 06:33:47 AM | Valid: [ 9/50] Final Prec1@1 59.5200%
02/16 06:33:47 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('sep_conv_3x3', 2)], [('sep_conv_5x5', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('sep_conv_5x5', 3)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1248, 0.1238, 0.1242, 0.1251, 0.1255, 0.1258, 0.1254, 0.1254],
        [0.1245, 0.1239, 0.1243, 0.1249, 0.1260, 0.1254, 0.1255, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1247, 0.1238, 0.1240, 0.1261, 0.1255, 0.1253, 0.1252, 0.1254],
        [0.1247, 0.1235, 0.1241, 0.1256, 0.1257, 0.1253, 0.1253, 0.1258],
        [0.1239, 0.1234, 0.1242, 0.1258, 0.1257, 0.1258, 0.1254, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1237, 0.1242, 0.1257, 0.1252, 0.1254, 0.1253, 0.1257],
        [0.1247, 0.1239, 0.1245, 0.1250, 0.1255, 0.1258, 0.1253, 0.1253],
        [0.1241, 0.1236, 0.1245, 0.1252, 0.1252, 0.1257, 0.1258, 0.1259],
        [0.1239, 0.1236, 0.1242, 0.1253, 0.1260, 0.1259, 0.1253, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1245, 0.1236, 0.1239, 0.1258, 0.1256, 0.1253, 0.1253, 0.1261],
        [0.1243, 0.1239, 0.1244, 0.1253, 0.1257, 0.1249, 0.1255, 0.1260],
        [0.1237, 0.1234, 0.1240, 0.1257, 0.1256, 0.1259, 0.1255, 0.1261],
        [0.1234, 0.1233, 0.1238, 0.1260, 0.1260, 0.1259, 0.1255, 0.1262],
        [0.1234, 0.1232, 0.1236, 0.1257, 0.1256, 0.1260, 0.1262, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1253, 0.1246, 0.1247, 0.1253, 0.1251, 0.1249, 0.1252, 0.1249],
        [0.1248, 0.1242, 0.1249, 0.1253, 0.1251, 0.1248, 0.1253, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1258, 0.1247, 0.1251, 0.1248, 0.1253, 0.1248, 0.1248, 0.1247],
        [0.1249, 0.1242, 0.1254, 0.1249, 0.1254, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1239, 0.1247, 0.1249, 0.1253, 0.1253, 0.1255, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1257, 0.1245, 0.1249, 0.1250, 0.1255, 0.1245, 0.1253, 0.1245],
        [0.1250, 0.1243, 0.1251, 0.1249, 0.1255, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1242, 0.1251, 0.1247, 0.1254, 0.1250, 0.1255, 0.1251],
        [0.1248, 0.1240, 0.1247, 0.1256, 0.1252, 0.1256, 0.1253, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1255, 0.1246, 0.1245, 0.1254, 0.1251, 0.1250, 0.1254, 0.1245],
        [0.1250, 0.1241, 0.1249, 0.1255, 0.1251, 0.1251, 0.1250, 0.1253],
        [0.1250, 0.1239, 0.1249, 0.1254, 0.1249, 0.1250, 0.1255, 0.1254],
        [0.1247, 0.1237, 0.1246, 0.1257, 0.1254, 0.1255, 0.1253, 0.1251],
        [0.1245, 0.1239, 0.1246, 0.1252, 0.1255, 0.1256, 0.1255, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 06:33:55 AM | Train: [10/50] Step 000/078 Loss1 3.600 Prec1@(1,5) (62.5%, 90.6%)
02/16 06:39:49 AM | Train: [10/50] Step 050/078 Loss1 3.456 Prec1@(1,5) (66.3%, 97.3%)
02/16 06:43:09 AM | Train: [10/50] Step 078/078 Loss1 3.445 Prec1@(1,5) (67.0%, 97.3%)
02/16 06:43:09 AM | Train: [10/50] Final Prec1@1 67.0000%
02/16 06:43:10 AM | Valid: [10/50] Step 000/078 Loss1 1.543 Prec1@(1,5) (54.7%, 92.2%)
02/16 06:43:20 AM | Valid: [10/50] Step 050/078 Loss1 1.228 Prec1@(1,5) (57.3%, 95.0%)
02/16 06:43:26 AM | Valid: [10/50] Step 078/078 Loss1 1.216 Prec1@(1,5) (58.1%, 94.9%)
02/16 06:43:26 AM | Valid: [10/50] Final Prec1@1 58.0600%
02/16 06:43:26 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('sep_conv_3x3', 2)], [('sep_conv_5x5', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('sep_conv_3x3', 3)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1247, 0.1236, 0.1241, 0.1251, 0.1256, 0.1259, 0.1254, 0.1254],
        [0.1244, 0.1237, 0.1242, 0.1248, 0.1261, 0.1255, 0.1257, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1246, 0.1236, 0.1239, 0.1262, 0.1256, 0.1254, 0.1253, 0.1255],
        [0.1245, 0.1233, 0.1240, 0.1256, 0.1259, 0.1253, 0.1254, 0.1259],
        [0.1237, 0.1232, 0.1241, 0.1259, 0.1258, 0.1259, 0.1254, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1236, 0.1241, 0.1257, 0.1252, 0.1254, 0.1253, 0.1258],
        [0.1246, 0.1237, 0.1244, 0.1251, 0.1256, 0.1259, 0.1254, 0.1254],
        [0.1239, 0.1234, 0.1245, 0.1252, 0.1252, 0.1258, 0.1259, 0.1261],
        [0.1237, 0.1234, 0.1240, 0.1253, 0.1261, 0.1260, 0.1255, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1244, 0.1234, 0.1237, 0.1258, 0.1257, 0.1254, 0.1254, 0.1262],
        [0.1241, 0.1237, 0.1243, 0.1253, 0.1259, 0.1250, 0.1256, 0.1261],
        [0.1234, 0.1231, 0.1239, 0.1259, 0.1257, 0.1260, 0.1256, 0.1263],
        [0.1231, 0.1230, 0.1236, 0.1261, 0.1261, 0.1260, 0.1257, 0.1264],
        [0.1231, 0.1229, 0.1234, 0.1258, 0.1258, 0.1261, 0.1264, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1254, 0.1246, 0.1246, 0.1253, 0.1251, 0.1249, 0.1251, 0.1250],
        [0.1248, 0.1242, 0.1249, 0.1253, 0.1252, 0.1248, 0.1253, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1247, 0.1252, 0.1247, 0.1253, 0.1248, 0.1248, 0.1246],
        [0.1249, 0.1242, 0.1254, 0.1249, 0.1254, 0.1249, 0.1252, 0.1251],
        [0.1249, 0.1237, 0.1246, 0.1250, 0.1253, 0.1254, 0.1256, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1258, 0.1244, 0.1249, 0.1250, 0.1255, 0.1245, 0.1253, 0.1245],
        [0.1251, 0.1243, 0.1252, 0.1249, 0.1256, 0.1249, 0.1251, 0.1251],
        [0.1249, 0.1241, 0.1251, 0.1247, 0.1255, 0.1250, 0.1255, 0.1252],
        [0.1247, 0.1239, 0.1247, 0.1257, 0.1254, 0.1256, 0.1253, 0.1247]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1256, 0.1245, 0.1245, 0.1254, 0.1251, 0.1251, 0.1254, 0.1244],
        [0.1249, 0.1240, 0.1248, 0.1256, 0.1252, 0.1252, 0.1250, 0.1253],
        [0.1248, 0.1236, 0.1249, 0.1256, 0.1250, 0.1250, 0.1256, 0.1255],
        [0.1246, 0.1236, 0.1246, 0.1258, 0.1254, 0.1256, 0.1253, 0.1252],
        [0.1243, 0.1237, 0.1245, 0.1251, 0.1257, 0.1257, 0.1257, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 06:43:34 AM | Train: [11/50] Step 000/078 Loss1 3.287 Prec1@(1,5) (62.5%, 100.0%)
02/16 06:49:29 AM | Train: [11/50] Step 050/078 Loss1 3.314 Prec1@(1,5) (71.5%, 98.1%)
02/16 06:52:48 AM | Train: [11/50] Step 078/078 Loss1 3.349 Prec1@(1,5) (69.8%, 97.9%)
02/16 06:52:48 AM | Train: [11/50] Final Prec1@1 69.7600%
02/16 06:52:48 AM | Valid: [11/50] Step 000/078 Loss1 1.171 Prec1@(1,5) (65.6%, 92.2%)
02/16 06:52:59 AM | Valid: [11/50] Step 050/078 Loss1 1.255 Prec1@(1,5) (58.9%, 95.3%)
02/16 06:53:05 AM | Valid: [11/50] Step 078/078 Loss1 1.260 Prec1@(1,5) (58.5%, 95.0%)
02/16 06:53:05 AM | Valid: [11/50] Final Prec1@1 58.5000%
02/16 06:53:05 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('sep_conv_5x5', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_5x5', 4), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1247, 0.1235, 0.1240, 0.1252, 0.1257, 0.1260, 0.1255, 0.1255],
        [0.1243, 0.1235, 0.1241, 0.1248, 0.1262, 0.1256, 0.1257, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1245, 0.1234, 0.1238, 0.1264, 0.1257, 0.1254, 0.1253, 0.1255],
        [0.1244, 0.1231, 0.1238, 0.1257, 0.1260, 0.1254, 0.1256, 0.1260],
        [0.1235, 0.1230, 0.1240, 0.1259, 0.1259, 0.1260, 0.1254, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1234, 0.1240, 0.1258, 0.1253, 0.1255, 0.1254, 0.1258],
        [0.1244, 0.1236, 0.1243, 0.1251, 0.1257, 0.1259, 0.1255, 0.1255],
        [0.1238, 0.1231, 0.1244, 0.1252, 0.1253, 0.1259, 0.1260, 0.1263],
        [0.1235, 0.1232, 0.1239, 0.1253, 0.1262, 0.1261, 0.1256, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1243, 0.1232, 0.1236, 0.1260, 0.1258, 0.1254, 0.1255, 0.1263],
        [0.1240, 0.1235, 0.1241, 0.1254, 0.1260, 0.1250, 0.1257, 0.1262],
        [0.1233, 0.1229, 0.1238, 0.1259, 0.1257, 0.1262, 0.1256, 0.1265],
        [0.1230, 0.1228, 0.1234, 0.1262, 0.1262, 0.1260, 0.1258, 0.1266],
        [0.1229, 0.1226, 0.1232, 0.1260, 0.1259, 0.1262, 0.1265, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1255, 0.1246, 0.1246, 0.1253, 0.1251, 0.1249, 0.1250, 0.1249],
        [0.1249, 0.1242, 0.1248, 0.1253, 0.1252, 0.1247, 0.1255, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1260, 0.1247, 0.1252, 0.1247, 0.1252, 0.1247, 0.1248, 0.1246],
        [0.1249, 0.1241, 0.1254, 0.1248, 0.1254, 0.1249, 0.1252, 0.1251],
        [0.1249, 0.1235, 0.1246, 0.1250, 0.1252, 0.1255, 0.1257, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1244, 0.1250, 0.1250, 0.1255, 0.1245, 0.1253, 0.1245],
        [0.1251, 0.1242, 0.1252, 0.1248, 0.1256, 0.1249, 0.1251, 0.1251],
        [0.1249, 0.1240, 0.1252, 0.1246, 0.1256, 0.1251, 0.1255, 0.1252],
        [0.1247, 0.1238, 0.1247, 0.1257, 0.1254, 0.1256, 0.1254, 0.1247]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1257, 0.1245, 0.1244, 0.1253, 0.1252, 0.1251, 0.1255, 0.1244],
        [0.1250, 0.1239, 0.1248, 0.1257, 0.1252, 0.1252, 0.1250, 0.1253],
        [0.1248, 0.1235, 0.1249, 0.1256, 0.1250, 0.1250, 0.1256, 0.1255],
        [0.1246, 0.1234, 0.1246, 0.1259, 0.1253, 0.1256, 0.1253, 0.1253],
        [0.1243, 0.1236, 0.1245, 0.1251, 0.1259, 0.1258, 0.1257, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 06:53:12 AM | Train: [12/50] Step 000/078 Loss1 3.321 Prec1@(1,5) (68.8%, 98.4%)
02/16 06:59:07 AM | Train: [12/50] Step 050/078 Loss1 3.294 Prec1@(1,5) (71.0%, 98.1%)
02/16 07:02:31 AM | Train: [12/50] Step 078/078 Loss1 3.292 Prec1@(1,5) (70.6%, 98.1%)
02/16 07:02:31 AM | Train: [12/50] Final Prec1@1 70.6000%
02/16 07:02:31 AM | Valid: [12/50] Step 000/078 Loss1 0.982 Prec1@(1,5) (68.8%, 95.3%)
02/16 07:02:42 AM | Valid: [12/50] Step 050/078 Loss1 1.155 Prec1@(1,5) (61.6%, 96.0%)
02/16 07:02:48 AM | Valid: [12/50] Step 078/078 Loss1 1.166 Prec1@(1,5) (61.3%, 95.8%)
02/16 07:02:48 AM | Valid: [12/50] Final Prec1@1 61.2800%
02/16 07:02:48 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_5x5', 4), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1246, 0.1234, 0.1240, 0.1251, 0.1258, 0.1261, 0.1256, 0.1254],
        [0.1241, 0.1234, 0.1240, 0.1248, 0.1263, 0.1257, 0.1258, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1245, 0.1232, 0.1237, 0.1265, 0.1257, 0.1254, 0.1254, 0.1256],
        [0.1242, 0.1230, 0.1237, 0.1257, 0.1260, 0.1255, 0.1257, 0.1261],
        [0.1232, 0.1227, 0.1239, 0.1260, 0.1261, 0.1261, 0.1255, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1233, 0.1240, 0.1258, 0.1253, 0.1255, 0.1254, 0.1259],
        [0.1243, 0.1234, 0.1242, 0.1252, 0.1258, 0.1260, 0.1256, 0.1256],
        [0.1235, 0.1229, 0.1243, 0.1252, 0.1254, 0.1261, 0.1261, 0.1265],
        [0.1233, 0.1230, 0.1238, 0.1253, 0.1263, 0.1263, 0.1256, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1242, 0.1230, 0.1235, 0.1261, 0.1258, 0.1254, 0.1255, 0.1264],
        [0.1238, 0.1233, 0.1240, 0.1255, 0.1262, 0.1251, 0.1258, 0.1264],
        [0.1230, 0.1226, 0.1236, 0.1260, 0.1258, 0.1264, 0.1257, 0.1268],
        [0.1227, 0.1225, 0.1232, 0.1263, 0.1263, 0.1262, 0.1260, 0.1269],
        [0.1226, 0.1224, 0.1229, 0.1261, 0.1260, 0.1264, 0.1266, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1256, 0.1246, 0.1245, 0.1254, 0.1251, 0.1248, 0.1250, 0.1249],
        [0.1249, 0.1242, 0.1248, 0.1253, 0.1252, 0.1247, 0.1255, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1261, 0.1247, 0.1252, 0.1247, 0.1252, 0.1248, 0.1248, 0.1246],
        [0.1250, 0.1241, 0.1255, 0.1248, 0.1254, 0.1250, 0.1252, 0.1251],
        [0.1249, 0.1234, 0.1246, 0.1250, 0.1252, 0.1255, 0.1258, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1244, 0.1251, 0.1250, 0.1255, 0.1245, 0.1253, 0.1244],
        [0.1251, 0.1242, 0.1252, 0.1248, 0.1256, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1238, 0.1252, 0.1246, 0.1256, 0.1251, 0.1256, 0.1253],
        [0.1246, 0.1237, 0.1247, 0.1258, 0.1254, 0.1256, 0.1255, 0.1247]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1257, 0.1244, 0.1244, 0.1254, 0.1252, 0.1251, 0.1255, 0.1243],
        [0.1250, 0.1239, 0.1247, 0.1257, 0.1252, 0.1254, 0.1249, 0.1252],
        [0.1248, 0.1233, 0.1249, 0.1256, 0.1251, 0.1250, 0.1257, 0.1257],
        [0.1245, 0.1233, 0.1246, 0.1259, 0.1253, 0.1256, 0.1254, 0.1254],
        [0.1243, 0.1234, 0.1244, 0.1250, 0.1260, 0.1258, 0.1258, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 07:02:56 AM | Train: [13/50] Step 000/078 Loss1 3.396 Prec1@(1,5) (68.8%, 95.3%)
02/16 07:08:53 AM | Train: [13/50] Step 050/078 Loss1 3.212 Prec1@(1,5) (73.7%, 98.1%)
02/16 07:12:05 AM | Train: [13/50] Step 078/078 Loss1 3.218 Prec1@(1,5) (72.7%, 98.0%)
02/16 07:12:05 AM | Train: [13/50] Final Prec1@1 72.6600%
02/16 07:12:05 AM | Valid: [13/50] Step 000/078 Loss1 0.984 Prec1@(1,5) (65.6%, 93.8%)
02/16 07:12:16 AM | Valid: [13/50] Step 050/078 Loss1 1.158 Prec1@(1,5) (62.0%, 96.2%)
02/16 07:12:22 AM | Valid: [13/50] Step 078/078 Loss1 1.151 Prec1@(1,5) (62.3%, 96.4%)
02/16 07:12:22 AM | Valid: [13/50] Final Prec1@1 62.3000%
02/16 07:12:22 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_5x5', 4), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1245, 0.1232, 0.1239, 0.1252, 0.1259, 0.1262, 0.1257, 0.1254],
        [0.1239, 0.1232, 0.1239, 0.1249, 0.1264, 0.1258, 0.1259, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1244, 0.1230, 0.1236, 0.1266, 0.1257, 0.1256, 0.1254, 0.1257],
        [0.1241, 0.1228, 0.1236, 0.1258, 0.1261, 0.1256, 0.1258, 0.1262],
        [0.1230, 0.1224, 0.1238, 0.1262, 0.1262, 0.1263, 0.1255, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1247, 0.1231, 0.1239, 0.1260, 0.1254, 0.1255, 0.1254, 0.1260],
        [0.1241, 0.1232, 0.1241, 0.1252, 0.1259, 0.1261, 0.1258, 0.1257],
        [0.1233, 0.1226, 0.1241, 0.1253, 0.1254, 0.1262, 0.1263, 0.1266],
        [0.1231, 0.1227, 0.1237, 0.1253, 0.1264, 0.1265, 0.1257, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1241, 0.1228, 0.1234, 0.1262, 0.1259, 0.1254, 0.1256, 0.1266],
        [0.1235, 0.1231, 0.1238, 0.1256, 0.1263, 0.1252, 0.1260, 0.1265],
        [0.1227, 0.1223, 0.1234, 0.1262, 0.1259, 0.1266, 0.1259, 0.1271],
        [0.1224, 0.1222, 0.1230, 0.1264, 0.1264, 0.1263, 0.1262, 0.1271],
        [0.1223, 0.1220, 0.1226, 0.1262, 0.1262, 0.1266, 0.1268, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1257, 0.1247, 0.1245, 0.1253, 0.1250, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1241, 0.1247, 0.1252, 0.1252, 0.1248, 0.1255, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1262, 0.1247, 0.1253, 0.1246, 0.1252, 0.1247, 0.1249, 0.1245],
        [0.1249, 0.1241, 0.1256, 0.1247, 0.1255, 0.1249, 0.1253, 0.1250],
        [0.1249, 0.1233, 0.1246, 0.1250, 0.1252, 0.1256, 0.1259, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1260, 0.1244, 0.1251, 0.1249, 0.1254, 0.1245, 0.1253, 0.1244],
        [0.1251, 0.1242, 0.1252, 0.1247, 0.1257, 0.1249, 0.1252, 0.1251],
        [0.1248, 0.1237, 0.1251, 0.1246, 0.1258, 0.1250, 0.1255, 0.1254],
        [0.1246, 0.1236, 0.1247, 0.1258, 0.1256, 0.1256, 0.1255, 0.1246]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1258, 0.1245, 0.1243, 0.1253, 0.1252, 0.1250, 0.1256, 0.1243],
        [0.1249, 0.1238, 0.1247, 0.1258, 0.1252, 0.1254, 0.1250, 0.1253],
        [0.1247, 0.1231, 0.1248, 0.1257, 0.1251, 0.1250, 0.1258, 0.1257],
        [0.1245, 0.1232, 0.1246, 0.1260, 0.1253, 0.1257, 0.1254, 0.1254],
        [0.1242, 0.1234, 0.1244, 0.1249, 0.1261, 0.1257, 0.1259, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 07:12:30 AM | Train: [14/50] Step 000/078 Loss1 3.152 Prec1@(1,5) (79.7%, 100.0%)
02/16 07:18:27 AM | Train: [14/50] Step 050/078 Loss1 3.130 Prec1@(1,5) (75.5%, 98.9%)
02/16 07:21:46 AM | Train: [14/50] Step 078/078 Loss1 3.126 Prec1@(1,5) (75.3%, 98.6%)
02/16 07:21:46 AM | Train: [14/50] Final Prec1@1 75.2800%
02/16 07:21:46 AM | Valid: [14/50] Step 000/078 Loss1 1.132 Prec1@(1,5) (57.8%, 96.9%)
02/16 07:21:57 AM | Valid: [14/50] Step 050/078 Loss1 1.176 Prec1@(1,5) (63.5%, 96.0%)
02/16 07:22:03 AM | Valid: [14/50] Step 078/078 Loss1 1.181 Prec1@(1,5) (63.2%, 96.0%)
02/16 07:22:03 AM | Valid: [14/50] Final Prec1@1 63.2200%
02/16 07:22:03 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 4), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1245, 0.1230, 0.1239, 0.1253, 0.1259, 0.1262, 0.1259, 0.1254],
        [0.1238, 0.1230, 0.1237, 0.1249, 0.1265, 0.1259, 0.1260, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1243, 0.1228, 0.1235, 0.1268, 0.1258, 0.1256, 0.1254, 0.1257],
        [0.1239, 0.1225, 0.1234, 0.1258, 0.1262, 0.1257, 0.1260, 0.1264],
        [0.1227, 0.1221, 0.1237, 0.1263, 0.1263, 0.1264, 0.1257, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1247, 0.1230, 0.1238, 0.1260, 0.1255, 0.1256, 0.1255, 0.1260],
        [0.1239, 0.1230, 0.1239, 0.1252, 0.1260, 0.1262, 0.1259, 0.1259],
        [0.1231, 0.1223, 0.1240, 0.1253, 0.1255, 0.1264, 0.1265, 0.1269],
        [0.1229, 0.1224, 0.1235, 0.1254, 0.1265, 0.1266, 0.1259, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1240, 0.1227, 0.1233, 0.1263, 0.1260, 0.1254, 0.1255, 0.1268],
        [0.1233, 0.1228, 0.1236, 0.1257, 0.1265, 0.1253, 0.1261, 0.1267],
        [0.1224, 0.1220, 0.1233, 0.1263, 0.1260, 0.1268, 0.1259, 0.1274],
        [0.1221, 0.1219, 0.1228, 0.1266, 0.1265, 0.1264, 0.1263, 0.1274],
        [0.1220, 0.1217, 0.1223, 0.1264, 0.1264, 0.1268, 0.1269, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1259, 0.1248, 0.1244, 0.1253, 0.1250, 0.1247, 0.1250, 0.1248],
        [0.1249, 0.1241, 0.1246, 0.1252, 0.1251, 0.1248, 0.1255, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1263, 0.1248, 0.1253, 0.1245, 0.1252, 0.1246, 0.1249, 0.1244],
        [0.1250, 0.1241, 0.1257, 0.1246, 0.1255, 0.1249, 0.1252, 0.1251],
        [0.1248, 0.1231, 0.1245, 0.1250, 0.1252, 0.1257, 0.1260, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1261, 0.1245, 0.1251, 0.1248, 0.1254, 0.1245, 0.1254, 0.1243],
        [0.1251, 0.1242, 0.1252, 0.1246, 0.1257, 0.1249, 0.1252, 0.1251],
        [0.1247, 0.1235, 0.1251, 0.1247, 0.1259, 0.1251, 0.1255, 0.1255],
        [0.1245, 0.1234, 0.1247, 0.1259, 0.1256, 0.1257, 0.1256, 0.1246]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1246, 0.1242, 0.1252, 0.1253, 0.1250, 0.1256, 0.1241],
        [0.1249, 0.1237, 0.1246, 0.1258, 0.1251, 0.1255, 0.1250, 0.1253],
        [0.1247, 0.1230, 0.1249, 0.1257, 0.1250, 0.1250, 0.1259, 0.1259],
        [0.1244, 0.1230, 0.1246, 0.1261, 0.1253, 0.1257, 0.1254, 0.1255],
        [0.1241, 0.1232, 0.1244, 0.1249, 0.1262, 0.1258, 0.1260, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 07:22:11 AM | Train: [15/50] Step 000/078 Loss1 3.154 Prec1@(1,5) (79.7%, 98.4%)
02/16 07:28:07 AM | Train: [15/50] Step 050/078 Loss1 3.085 Prec1@(1,5) (76.2%, 98.8%)
02/16 07:31:25 AM | Train: [15/50] Step 078/078 Loss1 3.077 Prec1@(1,5) (76.4%, 98.8%)
02/16 07:31:25 AM | Train: [15/50] Final Prec1@1 76.3800%
02/16 07:31:25 AM | Valid: [15/50] Step 000/078 Loss1 1.380 Prec1@(1,5) (62.5%, 96.9%)
02/16 07:31:36 AM | Valid: [15/50] Step 050/078 Loss1 1.070 Prec1@(1,5) (64.7%, 97.2%)
02/16 07:31:42 AM | Valid: [15/50] Step 078/078 Loss1 1.046 Prec1@(1,5) (66.2%, 96.9%)
02/16 07:31:42 AM | Valid: [15/50] Final Prec1@1 66.1600%
02/16 07:31:42 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 4), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1244, 0.1229, 0.1238, 0.1253, 0.1260, 0.1262, 0.1260, 0.1254],
        [0.1237, 0.1228, 0.1236, 0.1249, 0.1266, 0.1260, 0.1261, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1242, 0.1226, 0.1233, 0.1270, 0.1258, 0.1257, 0.1255, 0.1258],
        [0.1238, 0.1224, 0.1233, 0.1259, 0.1263, 0.1257, 0.1260, 0.1265],
        [0.1225, 0.1219, 0.1235, 0.1263, 0.1264, 0.1265, 0.1257, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1246, 0.1227, 0.1237, 0.1261, 0.1255, 0.1256, 0.1255, 0.1262],
        [0.1238, 0.1228, 0.1237, 0.1253, 0.1261, 0.1263, 0.1260, 0.1260],
        [0.1229, 0.1221, 0.1239, 0.1253, 0.1256, 0.1265, 0.1266, 0.1271],
        [0.1226, 0.1221, 0.1233, 0.1253, 0.1266, 0.1268, 0.1261, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1239, 0.1225, 0.1231, 0.1264, 0.1261, 0.1254, 0.1255, 0.1270],
        [0.1231, 0.1226, 0.1234, 0.1259, 0.1267, 0.1254, 0.1262, 0.1269],
        [0.1221, 0.1217, 0.1231, 0.1264, 0.1261, 0.1270, 0.1261, 0.1276],
        [0.1218, 0.1216, 0.1225, 0.1267, 0.1267, 0.1265, 0.1265, 0.1277],
        [0.1217, 0.1214, 0.1220, 0.1265, 0.1265, 0.1269, 0.1271, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1261, 0.1249, 0.1244, 0.1253, 0.1250, 0.1247, 0.1249, 0.1248],
        [0.1250, 0.1242, 0.1245, 0.1251, 0.1251, 0.1248, 0.1255, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1264, 0.1248, 0.1253, 0.1244, 0.1252, 0.1246, 0.1249, 0.1243],
        [0.1251, 0.1241, 0.1257, 0.1245, 0.1255, 0.1249, 0.1252, 0.1250],
        [0.1248, 0.1230, 0.1245, 0.1250, 0.1251, 0.1258, 0.1261, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1262, 0.1245, 0.1250, 0.1248, 0.1254, 0.1245, 0.1254, 0.1243],
        [0.1253, 0.1242, 0.1252, 0.1245, 0.1258, 0.1248, 0.1252, 0.1250],
        [0.1247, 0.1233, 0.1251, 0.1247, 0.1260, 0.1251, 0.1256, 0.1255],
        [0.1245, 0.1233, 0.1247, 0.1259, 0.1257, 0.1257, 0.1256, 0.1246]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1260, 0.1245, 0.1241, 0.1252, 0.1254, 0.1250, 0.1257, 0.1241],
        [0.1250, 0.1237, 0.1246, 0.1259, 0.1251, 0.1255, 0.1250, 0.1253],
        [0.1247, 0.1227, 0.1249, 0.1257, 0.1250, 0.1250, 0.1260, 0.1260],
        [0.1245, 0.1228, 0.1246, 0.1261, 0.1252, 0.1258, 0.1253, 0.1256],
        [0.1240, 0.1231, 0.1244, 0.1249, 0.1263, 0.1257, 0.1261, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 07:31:50 AM | Train: [16/50] Step 000/078 Loss1 2.875 Prec1@(1,5) (84.4%, 100.0%)
02/16 07:37:47 AM | Train: [16/50] Step 050/078 Loss1 3.021 Prec1@(1,5) (78.0%, 98.7%)
02/16 07:41:05 AM | Train: [16/50] Step 078/078 Loss1 3.014 Prec1@(1,5) (77.9%, 98.6%)
02/16 07:41:05 AM | Train: [16/50] Final Prec1@1 77.9000%
02/16 07:41:05 AM | Valid: [16/50] Step 000/078 Loss1 1.155 Prec1@(1,5) (62.5%, 93.8%)
02/16 07:41:16 AM | Valid: [16/50] Step 050/078 Loss1 1.029 Prec1@(1,5) (65.3%, 96.3%)
02/16 07:41:22 AM | Valid: [16/50] Step 078/078 Loss1 1.028 Prec1@(1,5) (65.8%, 96.5%)
02/16 07:41:22 AM | Valid: [16/50] Final Prec1@1 65.8000%
02/16 07:41:22 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1243, 0.1227, 0.1238, 0.1253, 0.1261, 0.1263, 0.1260, 0.1254],
        [0.1235, 0.1226, 0.1235, 0.1248, 0.1268, 0.1262, 0.1263, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1241, 0.1225, 0.1233, 0.1271, 0.1258, 0.1258, 0.1256, 0.1259],
        [0.1236, 0.1222, 0.1232, 0.1259, 0.1265, 0.1258, 0.1261, 0.1267],
        [0.1223, 0.1216, 0.1234, 0.1264, 0.1265, 0.1267, 0.1258, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1245, 0.1226, 0.1235, 0.1262, 0.1257, 0.1256, 0.1256, 0.1263],
        [0.1235, 0.1226, 0.1235, 0.1254, 0.1262, 0.1264, 0.1262, 0.1262],
        [0.1226, 0.1218, 0.1237, 0.1254, 0.1257, 0.1266, 0.1268, 0.1274],
        [0.1224, 0.1218, 0.1231, 0.1254, 0.1267, 0.1269, 0.1262, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1238, 0.1223, 0.1230, 0.1265, 0.1262, 0.1255, 0.1256, 0.1271],
        [0.1228, 0.1223, 0.1231, 0.1260, 0.1268, 0.1255, 0.1264, 0.1271],
        [0.1218, 0.1214, 0.1229, 0.1264, 0.1262, 0.1272, 0.1262, 0.1279],
        [0.1215, 0.1212, 0.1223, 0.1267, 0.1268, 0.1267, 0.1267, 0.1281],
        [0.1214, 0.1211, 0.1217, 0.1266, 0.1267, 0.1271, 0.1273, 0.1282]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1262, 0.1249, 0.1243, 0.1253, 0.1250, 0.1247, 0.1249, 0.1247],
        [0.1250, 0.1241, 0.1245, 0.1251, 0.1252, 0.1248, 0.1255, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1265, 0.1248, 0.1253, 0.1244, 0.1253, 0.1245, 0.1250, 0.1242],
        [0.1251, 0.1240, 0.1258, 0.1245, 0.1255, 0.1248, 0.1253, 0.1250],
        [0.1248, 0.1228, 0.1245, 0.1250, 0.1251, 0.1258, 0.1261, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1263, 0.1245, 0.1250, 0.1247, 0.1254, 0.1245, 0.1253, 0.1243],
        [0.1252, 0.1242, 0.1252, 0.1245, 0.1259, 0.1248, 0.1252, 0.1250],
        [0.1247, 0.1232, 0.1252, 0.1248, 0.1260, 0.1251, 0.1255, 0.1256],
        [0.1244, 0.1232, 0.1247, 0.1260, 0.1258, 0.1258, 0.1256, 0.1246]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1261, 0.1245, 0.1240, 0.1252, 0.1255, 0.1250, 0.1257, 0.1240],
        [0.1249, 0.1236, 0.1246, 0.1259, 0.1250, 0.1256, 0.1250, 0.1252],
        [0.1246, 0.1226, 0.1249, 0.1257, 0.1250, 0.1250, 0.1261, 0.1261],
        [0.1244, 0.1227, 0.1247, 0.1261, 0.1253, 0.1260, 0.1253, 0.1256],
        [0.1239, 0.1229, 0.1244, 0.1248, 0.1265, 0.1257, 0.1262, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 07:41:30 AM | Train: [17/50] Step 000/078 Loss1 2.958 Prec1@(1,5) (76.6%, 100.0%)
02/16 07:47:29 AM | Train: [17/50] Step 050/078 Loss1 2.919 Prec1@(1,5) (80.2%, 99.3%)
02/16 07:50:48 AM | Train: [17/50] Step 078/078 Loss1 2.952 Prec1@(1,5) (78.9%, 99.2%)
02/16 07:50:48 AM | Train: [17/50] Final Prec1@1 78.8600%
02/16 07:50:49 AM | Valid: [17/50] Step 000/078 Loss1 1.150 Prec1@(1,5) (62.5%, 98.4%)
02/16 07:50:59 AM | Valid: [17/50] Step 050/078 Loss1 1.060 Prec1@(1,5) (65.6%, 96.3%)
02/16 07:51:05 AM | Valid: [17/50] Step 078/078 Loss1 1.058 Prec1@(1,5) (65.4%, 96.6%)
02/16 07:51:05 AM | Valid: [17/50] Final Prec1@1 65.4000%
02/16 07:51:05 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1242, 0.1226, 0.1237, 0.1254, 0.1261, 0.1264, 0.1261, 0.1254],
        [0.1233, 0.1224, 0.1233, 0.1248, 0.1268, 0.1263, 0.1264, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1240, 0.1223, 0.1232, 0.1273, 0.1259, 0.1259, 0.1256, 0.1260],
        [0.1234, 0.1220, 0.1231, 0.1259, 0.1265, 0.1260, 0.1263, 0.1268],
        [0.1220, 0.1214, 0.1234, 0.1265, 0.1266, 0.1268, 0.1258, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1244, 0.1224, 0.1234, 0.1263, 0.1258, 0.1256, 0.1256, 0.1264],
        [0.1234, 0.1223, 0.1234, 0.1255, 0.1264, 0.1265, 0.1263, 0.1263],
        [0.1224, 0.1215, 0.1237, 0.1253, 0.1258, 0.1267, 0.1269, 0.1277],
        [0.1221, 0.1216, 0.1229, 0.1254, 0.1268, 0.1271, 0.1264, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1236, 0.1221, 0.1229, 0.1267, 0.1262, 0.1255, 0.1257, 0.1273],
        [0.1225, 0.1221, 0.1230, 0.1261, 0.1269, 0.1256, 0.1265, 0.1273],
        [0.1215, 0.1211, 0.1227, 0.1265, 0.1263, 0.1274, 0.1263, 0.1282],
        [0.1212, 0.1209, 0.1220, 0.1269, 0.1269, 0.1268, 0.1269, 0.1284],
        [0.1210, 0.1207, 0.1214, 0.1267, 0.1268, 0.1273, 0.1274, 0.1285]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1263, 0.1249, 0.1243, 0.1253, 0.1249, 0.1247, 0.1248, 0.1247],
        [0.1250, 0.1241, 0.1244, 0.1252, 0.1252, 0.1248, 0.1256, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1266, 0.1248, 0.1253, 0.1243, 0.1252, 0.1245, 0.1250, 0.1242],
        [0.1251, 0.1241, 0.1259, 0.1244, 0.1254, 0.1248, 0.1254, 0.1249],
        [0.1248, 0.1227, 0.1245, 0.1249, 0.1251, 0.1259, 0.1262, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1263, 0.1244, 0.1251, 0.1247, 0.1254, 0.1245, 0.1253, 0.1243],
        [0.1253, 0.1242, 0.1251, 0.1245, 0.1259, 0.1248, 0.1252, 0.1250],
        [0.1246, 0.1231, 0.1252, 0.1248, 0.1260, 0.1251, 0.1255, 0.1257],
        [0.1242, 0.1230, 0.1246, 0.1261, 0.1259, 0.1258, 0.1257, 0.1246]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1262, 0.1245, 0.1240, 0.1252, 0.1255, 0.1251, 0.1258, 0.1238],
        [0.1249, 0.1236, 0.1246, 0.1261, 0.1250, 0.1257, 0.1250, 0.1252],
        [0.1246, 0.1225, 0.1250, 0.1257, 0.1250, 0.1249, 0.1261, 0.1261],
        [0.1243, 0.1225, 0.1247, 0.1261, 0.1252, 0.1261, 0.1253, 0.1257],
        [0.1239, 0.1228, 0.1245, 0.1246, 0.1267, 0.1257, 0.1263, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 07:51:13 AM | Train: [18/50] Step 000/078 Loss1 2.947 Prec1@(1,5) (79.7%, 100.0%)
02/16 07:57:14 AM | Train: [18/50] Step 050/078 Loss1 2.892 Prec1@(1,5) (81.1%, 99.3%)
02/16 08:00:33 AM | Train: [18/50] Step 078/078 Loss1 2.900 Prec1@(1,5) (80.5%, 99.2%)
02/16 08:00:33 AM | Train: [18/50] Final Prec1@1 80.4600%
02/16 08:00:33 AM | Valid: [18/50] Step 000/078 Loss1 1.638 Prec1@(1,5) (59.4%, 93.8%)
02/16 08:00:44 AM | Valid: [18/50] Step 050/078 Loss1 1.234 Prec1@(1,5) (62.1%, 96.5%)
02/16 08:00:50 AM | Valid: [18/50] Step 078/078 Loss1 1.237 Prec1@(1,5) (62.0%, 96.6%)
02/16 08:00:50 AM | Valid: [18/50] Final Prec1@1 61.9600%
02/16 08:00:50 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1241, 0.1225, 0.1237, 0.1254, 0.1262, 0.1265, 0.1262, 0.1254],
        [0.1230, 0.1222, 0.1232, 0.1248, 0.1269, 0.1265, 0.1266, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1239, 0.1221, 0.1231, 0.1274, 0.1258, 0.1260, 0.1257, 0.1260],
        [0.1231, 0.1217, 0.1229, 0.1260, 0.1266, 0.1261, 0.1265, 0.1270],
        [0.1217, 0.1211, 0.1232, 0.1266, 0.1267, 0.1269, 0.1260, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1243, 0.1223, 0.1234, 0.1265, 0.1259, 0.1257, 0.1256, 0.1265],
        [0.1231, 0.1221, 0.1232, 0.1257, 0.1265, 0.1266, 0.1264, 0.1266],
        [0.1221, 0.1212, 0.1235, 0.1253, 0.1260, 0.1269, 0.1271, 0.1279],
        [0.1218, 0.1213, 0.1227, 0.1254, 0.1268, 0.1273, 0.1266, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1235, 0.1219, 0.1228, 0.1267, 0.1264, 0.1256, 0.1257, 0.1274],
        [0.1222, 0.1218, 0.1227, 0.1262, 0.1271, 0.1257, 0.1267, 0.1276],
        [0.1212, 0.1208, 0.1225, 0.1266, 0.1265, 0.1275, 0.1265, 0.1285],
        [0.1208, 0.1206, 0.1217, 0.1270, 0.1271, 0.1271, 0.1270, 0.1288],
        [0.1207, 0.1204, 0.1211, 0.1268, 0.1270, 0.1275, 0.1276, 0.1289]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1264, 0.1249, 0.1243, 0.1253, 0.1249, 0.1248, 0.1248, 0.1247],
        [0.1249, 0.1240, 0.1244, 0.1252, 0.1252, 0.1248, 0.1257, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1267, 0.1249, 0.1253, 0.1242, 0.1252, 0.1245, 0.1250, 0.1242],
        [0.1251, 0.1240, 0.1260, 0.1243, 0.1255, 0.1248, 0.1254, 0.1249],
        [0.1248, 0.1226, 0.1246, 0.1249, 0.1250, 0.1259, 0.1262, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1264, 0.1245, 0.1251, 0.1246, 0.1255, 0.1245, 0.1253, 0.1243],
        [0.1253, 0.1242, 0.1251, 0.1244, 0.1260, 0.1248, 0.1252, 0.1250],
        [0.1245, 0.1229, 0.1253, 0.1248, 0.1260, 0.1251, 0.1256, 0.1258],
        [0.1241, 0.1228, 0.1246, 0.1262, 0.1260, 0.1259, 0.1258, 0.1246]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1263, 0.1245, 0.1239, 0.1252, 0.1256, 0.1251, 0.1259, 0.1237],
        [0.1249, 0.1236, 0.1246, 0.1262, 0.1249, 0.1257, 0.1250, 0.1252],
        [0.1245, 0.1223, 0.1250, 0.1258, 0.1250, 0.1249, 0.1262, 0.1262],
        [0.1242, 0.1223, 0.1247, 0.1262, 0.1253, 0.1262, 0.1253, 0.1258],
        [0.1237, 0.1226, 0.1245, 0.1246, 0.1268, 0.1257, 0.1264, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 08:00:58 AM | Train: [19/50] Step 000/078 Loss1 2.860 Prec1@(1,5) (84.4%, 98.4%)
02/16 08:06:53 AM | Train: [19/50] Step 050/078 Loss1 2.840 Prec1@(1,5) (83.4%, 99.1%)
02/16 08:10:07 AM | Train: [19/50] Step 078/078 Loss1 2.848 Prec1@(1,5) (82.8%, 99.1%)
02/16 08:10:07 AM | Train: [19/50] Final Prec1@1 82.7600%
02/16 08:10:07 AM | Valid: [19/50] Step 000/078 Loss1 1.179 Prec1@(1,5) (64.1%, 96.9%)
02/16 08:10:18 AM | Valid: [19/50] Step 050/078 Loss1 1.110 Prec1@(1,5) (66.3%, 97.3%)
02/16 08:10:24 AM | Valid: [19/50] Step 078/078 Loss1 1.114 Prec1@(1,5) (66.9%, 97.1%)
02/16 08:10:24 AM | Valid: [19/50] Final Prec1@1 66.8600%
02/16 08:10:24 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1240, 0.1224, 0.1237, 0.1254, 0.1262, 0.1265, 0.1263, 0.1253],
        [0.1227, 0.1219, 0.1230, 0.1248, 0.1270, 0.1267, 0.1267, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1238, 0.1220, 0.1231, 0.1275, 0.1259, 0.1260, 0.1258, 0.1260],
        [0.1229, 0.1214, 0.1227, 0.1261, 0.1268, 0.1262, 0.1266, 0.1273],
        [0.1214, 0.1208, 0.1231, 0.1267, 0.1268, 0.1271, 0.1261, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1242, 0.1221, 0.1233, 0.1265, 0.1260, 0.1257, 0.1256, 0.1265],
        [0.1228, 0.1218, 0.1229, 0.1258, 0.1267, 0.1267, 0.1265, 0.1268],
        [0.1218, 0.1209, 0.1234, 0.1254, 0.1261, 0.1270, 0.1273, 0.1282],
        [0.1215, 0.1210, 0.1225, 0.1254, 0.1269, 0.1274, 0.1268, 0.1284]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1233, 0.1217, 0.1227, 0.1269, 0.1264, 0.1257, 0.1258, 0.1276],
        [0.1219, 0.1214, 0.1224, 0.1264, 0.1272, 0.1259, 0.1269, 0.1279],
        [0.1208, 0.1204, 0.1222, 0.1268, 0.1266, 0.1277, 0.1266, 0.1288],
        [0.1205, 0.1202, 0.1214, 0.1271, 0.1272, 0.1272, 0.1272, 0.1291],
        [0.1203, 0.1200, 0.1207, 0.1270, 0.1272, 0.1278, 0.1278, 0.1292]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1265, 0.1250, 0.1242, 0.1253, 0.1248, 0.1248, 0.1247, 0.1247],
        [0.1250, 0.1240, 0.1243, 0.1252, 0.1252, 0.1247, 0.1257, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1249, 0.1254, 0.1242, 0.1251, 0.1245, 0.1250, 0.1241],
        [0.1252, 0.1241, 0.1260, 0.1242, 0.1255, 0.1248, 0.1255, 0.1248],
        [0.1248, 0.1225, 0.1246, 0.1249, 0.1250, 0.1260, 0.1263, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1264, 0.1244, 0.1252, 0.1245, 0.1254, 0.1244, 0.1253, 0.1243],
        [0.1253, 0.1242, 0.1251, 0.1243, 0.1261, 0.1247, 0.1253, 0.1249],
        [0.1244, 0.1228, 0.1253, 0.1248, 0.1261, 0.1251, 0.1256, 0.1259],
        [0.1240, 0.1227, 0.1246, 0.1263, 0.1260, 0.1259, 0.1259, 0.1246]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1263, 0.1245, 0.1238, 0.1251, 0.1257, 0.1251, 0.1259, 0.1236],
        [0.1250, 0.1236, 0.1245, 0.1262, 0.1249, 0.1257, 0.1249, 0.1251],
        [0.1244, 0.1222, 0.1251, 0.1258, 0.1251, 0.1249, 0.1261, 0.1263],
        [0.1241, 0.1222, 0.1248, 0.1261, 0.1253, 0.1263, 0.1254, 0.1259],
        [0.1237, 0.1225, 0.1246, 0.1245, 0.1270, 0.1256, 0.1264, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 08:10:32 AM | Train: [20/50] Step 000/078 Loss1 2.718 Prec1@(1,5) (87.5%, 100.0%)
02/16 08:16:28 AM | Train: [20/50] Step 050/078 Loss1 2.793 Prec1@(1,5) (83.2%, 99.6%)
02/16 08:19:46 AM | Train: [20/50] Step 078/078 Loss1 2.801 Prec1@(1,5) (82.7%, 99.5%)
02/16 08:19:46 AM | Train: [20/50] Final Prec1@1 82.6800%
02/16 08:19:47 AM | Valid: [20/50] Step 000/078 Loss1 1.321 Prec1@(1,5) (59.4%, 96.9%)
02/16 08:19:58 AM | Valid: [20/50] Step 050/078 Loss1 1.093 Prec1@(1,5) (66.0%, 96.8%)
02/16 08:20:04 AM | Valid: [20/50] Step 078/078 Loss1 1.090 Prec1@(1,5) (66.6%, 96.7%)
02/16 08:20:04 AM | Valid: [20/50] Final Prec1@1 66.5600%
02/16 08:20:04 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1240, 0.1223, 0.1237, 0.1254, 0.1263, 0.1266, 0.1264, 0.1253],
        [0.1225, 0.1217, 0.1228, 0.1249, 0.1271, 0.1269, 0.1268, 0.1273]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1237, 0.1218, 0.1230, 0.1277, 0.1259, 0.1261, 0.1258, 0.1260],
        [0.1227, 0.1212, 0.1226, 0.1261, 0.1268, 0.1264, 0.1267, 0.1275],
        [0.1212, 0.1205, 0.1230, 0.1268, 0.1269, 0.1272, 0.1261, 0.1283]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1242, 0.1220, 0.1233, 0.1266, 0.1261, 0.1257, 0.1256, 0.1266],
        [0.1225, 0.1215, 0.1228, 0.1259, 0.1268, 0.1268, 0.1266, 0.1270],
        [0.1215, 0.1206, 0.1233, 0.1254, 0.1262, 0.1271, 0.1274, 0.1285],
        [0.1213, 0.1207, 0.1223, 0.1254, 0.1270, 0.1276, 0.1270, 0.1287]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1232, 0.1215, 0.1226, 0.1270, 0.1265, 0.1257, 0.1258, 0.1277],
        [0.1216, 0.1211, 0.1222, 0.1265, 0.1274, 0.1260, 0.1271, 0.1281],
        [0.1205, 0.1201, 0.1221, 0.1270, 0.1267, 0.1279, 0.1267, 0.1292],
        [0.1201, 0.1199, 0.1212, 0.1272, 0.1273, 0.1274, 0.1274, 0.1295],
        [0.1199, 0.1197, 0.1204, 0.1271, 0.1274, 0.1280, 0.1279, 0.1296]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1267, 0.1251, 0.1241, 0.1252, 0.1248, 0.1247, 0.1246, 0.1247],
        [0.1251, 0.1240, 0.1242, 0.1253, 0.1252, 0.1246, 0.1257, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1270, 0.1251, 0.1253, 0.1241, 0.1250, 0.1245, 0.1249, 0.1241],
        [0.1253, 0.1241, 0.1259, 0.1241, 0.1255, 0.1247, 0.1255, 0.1247],
        [0.1247, 0.1224, 0.1246, 0.1249, 0.1250, 0.1261, 0.1264, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1266, 0.1246, 0.1252, 0.1244, 0.1254, 0.1243, 0.1252, 0.1242],
        [0.1255, 0.1243, 0.1251, 0.1242, 0.1261, 0.1247, 0.1253, 0.1248],
        [0.1244, 0.1227, 0.1255, 0.1247, 0.1261, 0.1250, 0.1256, 0.1260],
        [0.1239, 0.1225, 0.1247, 0.1262, 0.1262, 0.1258, 0.1260, 0.1247]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1265, 0.1246, 0.1237, 0.1251, 0.1257, 0.1250, 0.1259, 0.1235],
        [0.1251, 0.1236, 0.1244, 0.1263, 0.1249, 0.1257, 0.1248, 0.1251],
        [0.1244, 0.1220, 0.1253, 0.1258, 0.1251, 0.1249, 0.1261, 0.1265],
        [0.1240, 0.1220, 0.1248, 0.1262, 0.1253, 0.1264, 0.1253, 0.1260],
        [0.1235, 0.1224, 0.1247, 0.1244, 0.1271, 0.1256, 0.1265, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 08:20:12 AM | Train: [21/50] Step 000/078 Loss1 2.812 Prec1@(1,5) (82.8%, 98.4%)
02/16 08:26:06 AM | Train: [21/50] Step 050/078 Loss1 2.745 Prec1@(1,5) (84.9%, 99.6%)
02/16 08:29:27 AM | Train: [21/50] Step 078/078 Loss1 2.749 Prec1@(1,5) (84.6%, 99.5%)
02/16 08:29:27 AM | Train: [21/50] Final Prec1@1 84.5800%
02/16 08:29:27 AM | Valid: [21/50] Step 000/078 Loss1 1.377 Prec1@(1,5) (71.9%, 96.9%)
02/16 08:29:38 AM | Valid: [21/50] Step 050/078 Loss1 1.098 Prec1@(1,5) (68.0%, 97.2%)
02/16 08:29:44 AM | Valid: [21/50] Step 078/078 Loss1 1.082 Prec1@(1,5) (68.2%, 97.2%)
02/16 08:29:44 AM | Valid: [21/50] Final Prec1@1 68.2400%
02/16 08:29:44 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1239, 0.1221, 0.1238, 0.1254, 0.1263, 0.1266, 0.1265, 0.1253],
        [0.1224, 0.1215, 0.1227, 0.1249, 0.1272, 0.1270, 0.1269, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1237, 0.1216, 0.1230, 0.1277, 0.1260, 0.1261, 0.1258, 0.1261],
        [0.1225, 0.1210, 0.1224, 0.1262, 0.1269, 0.1265, 0.1268, 0.1276],
        [0.1210, 0.1202, 0.1229, 0.1268, 0.1269, 0.1273, 0.1262, 0.1285]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1241, 0.1218, 0.1232, 0.1267, 0.1261, 0.1258, 0.1257, 0.1267],
        [0.1224, 0.1213, 0.1226, 0.1259, 0.1269, 0.1269, 0.1268, 0.1273],
        [0.1213, 0.1203, 0.1233, 0.1254, 0.1263, 0.1271, 0.1275, 0.1288],
        [0.1210, 0.1204, 0.1221, 0.1254, 0.1271, 0.1278, 0.1272, 0.1291]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1231, 0.1213, 0.1225, 0.1271, 0.1265, 0.1257, 0.1258, 0.1279],
        [0.1213, 0.1208, 0.1219, 0.1267, 0.1275, 0.1261, 0.1272, 0.1284],
        [0.1202, 0.1197, 0.1218, 0.1272, 0.1268, 0.1281, 0.1267, 0.1295],
        [0.1198, 0.1195, 0.1209, 0.1274, 0.1274, 0.1276, 0.1275, 0.1298],
        [0.1196, 0.1193, 0.1201, 0.1272, 0.1275, 0.1282, 0.1282, 0.1299]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1269, 0.1252, 0.1241, 0.1252, 0.1248, 0.1247, 0.1245, 0.1246],
        [0.1251, 0.1240, 0.1241, 0.1253, 0.1253, 0.1245, 0.1257, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1251, 0.1254, 0.1241, 0.1250, 0.1244, 0.1249, 0.1240],
        [0.1254, 0.1242, 0.1260, 0.1240, 0.1255, 0.1246, 0.1255, 0.1247],
        [0.1247, 0.1223, 0.1247, 0.1248, 0.1250, 0.1261, 0.1264, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1246, 0.1253, 0.1243, 0.1254, 0.1243, 0.1252, 0.1242],
        [0.1256, 0.1244, 0.1251, 0.1241, 0.1261, 0.1247, 0.1253, 0.1248],
        [0.1243, 0.1226, 0.1256, 0.1247, 0.1261, 0.1250, 0.1256, 0.1261],
        [0.1239, 0.1225, 0.1248, 0.1262, 0.1262, 0.1258, 0.1259, 0.1247]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1266, 0.1246, 0.1237, 0.1251, 0.1258, 0.1250, 0.1259, 0.1234],
        [0.1251, 0.1237, 0.1243, 0.1264, 0.1250, 0.1257, 0.1248, 0.1250],
        [0.1243, 0.1219, 0.1253, 0.1258, 0.1251, 0.1249, 0.1261, 0.1266],
        [0.1239, 0.1219, 0.1249, 0.1262, 0.1253, 0.1265, 0.1253, 0.1260],
        [0.1234, 0.1222, 0.1247, 0.1244, 0.1272, 0.1256, 0.1265, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 08:29:52 AM | Train: [22/50] Step 000/078 Loss1 2.600 Prec1@(1,5) (87.5%, 98.4%)
02/16 08:35:47 AM | Train: [22/50] Step 050/078 Loss1 2.642 Prec1@(1,5) (88.0%, 99.7%)
02/16 08:39:06 AM | Train: [22/50] Step 078/078 Loss1 2.651 Prec1@(1,5) (87.4%, 99.6%)
02/16 08:39:06 AM | Train: [22/50] Final Prec1@1 87.3800%
02/16 08:39:06 AM | Valid: [22/50] Step 000/078 Loss1 1.075 Prec1@(1,5) (64.1%, 95.3%)
02/16 08:39:16 AM | Valid: [22/50] Step 050/078 Loss1 1.281 Prec1@(1,5) (64.5%, 96.2%)
02/16 08:39:23 AM | Valid: [22/50] Step 078/078 Loss1 1.281 Prec1@(1,5) (64.9%, 96.0%)
02/16 08:39:23 AM | Valid: [22/50] Final Prec1@1 64.9400%
02/16 08:39:23 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1238, 0.1220, 0.1237, 0.1255, 0.1263, 0.1267, 0.1267, 0.1253],
        [0.1221, 0.1213, 0.1225, 0.1250, 0.1272, 0.1271, 0.1270, 0.1276]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1236, 0.1214, 0.1229, 0.1279, 0.1260, 0.1262, 0.1259, 0.1261],
        [0.1222, 0.1208, 0.1222, 0.1263, 0.1271, 0.1266, 0.1269, 0.1278],
        [0.1207, 0.1200, 0.1228, 0.1269, 0.1270, 0.1275, 0.1264, 0.1288]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1240, 0.1216, 0.1230, 0.1269, 0.1262, 0.1258, 0.1258, 0.1268],
        [0.1221, 0.1211, 0.1224, 0.1260, 0.1270, 0.1270, 0.1269, 0.1275],
        [0.1210, 0.1200, 0.1232, 0.1254, 0.1264, 0.1273, 0.1276, 0.1291],
        [0.1207, 0.1201, 0.1219, 0.1254, 0.1272, 0.1279, 0.1274, 0.1294]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1229, 0.1211, 0.1223, 0.1272, 0.1266, 0.1259, 0.1259, 0.1281],
        [0.1210, 0.1206, 0.1217, 0.1268, 0.1277, 0.1262, 0.1274, 0.1286],
        [0.1198, 0.1194, 0.1216, 0.1274, 0.1269, 0.1282, 0.1268, 0.1298],
        [0.1195, 0.1192, 0.1206, 0.1275, 0.1276, 0.1277, 0.1278, 0.1302],
        [0.1193, 0.1189, 0.1197, 0.1273, 0.1277, 0.1284, 0.1284, 0.1303]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1271, 0.1253, 0.1240, 0.1252, 0.1247, 0.1247, 0.1244, 0.1246],
        [0.1252, 0.1241, 0.1240, 0.1253, 0.1253, 0.1245, 0.1258, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1273, 0.1252, 0.1254, 0.1241, 0.1249, 0.1243, 0.1248, 0.1239],
        [0.1255, 0.1243, 0.1261, 0.1239, 0.1254, 0.1246, 0.1255, 0.1246],
        [0.1246, 0.1222, 0.1247, 0.1247, 0.1251, 0.1262, 0.1265, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1269, 0.1247, 0.1253, 0.1242, 0.1253, 0.1243, 0.1252, 0.1241],
        [0.1257, 0.1245, 0.1251, 0.1239, 0.1262, 0.1247, 0.1253, 0.1247],
        [0.1242, 0.1226, 0.1257, 0.1247, 0.1261, 0.1250, 0.1255, 0.1262],
        [0.1238, 0.1224, 0.1249, 0.1262, 0.1262, 0.1258, 0.1259, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1247, 0.1235, 0.1251, 0.1258, 0.1249, 0.1260, 0.1232],
        [0.1252, 0.1238, 0.1242, 0.1264, 0.1250, 0.1258, 0.1247, 0.1249],
        [0.1241, 0.1217, 0.1254, 0.1258, 0.1251, 0.1250, 0.1261, 0.1267],
        [0.1238, 0.1217, 0.1249, 0.1263, 0.1253, 0.1265, 0.1253, 0.1262],
        [0.1233, 0.1221, 0.1248, 0.1244, 0.1273, 0.1257, 0.1266, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 08:39:30 AM | Train: [23/50] Step 000/078 Loss1 2.571 Prec1@(1,5) (92.2%, 100.0%)
02/16 08:45:24 AM | Train: [23/50] Step 050/078 Loss1 2.624 Prec1@(1,5) (87.8%, 99.7%)
02/16 08:48:43 AM | Train: [23/50] Step 078/078 Loss1 2.641 Prec1@(1,5) (87.1%, 99.6%)
02/16 08:48:43 AM | Train: [23/50] Final Prec1@1 87.0800%
02/16 08:48:44 AM | Valid: [23/50] Step 000/078 Loss1 1.286 Prec1@(1,5) (56.2%, 98.4%)
02/16 08:48:54 AM | Valid: [23/50] Step 050/078 Loss1 1.125 Prec1@(1,5) (67.9%, 96.9%)
02/16 08:49:00 AM | Valid: [23/50] Step 078/078 Loss1 1.152 Prec1@(1,5) (67.4%, 96.7%)
02/16 08:49:00 AM | Valid: [23/50] Final Prec1@1 67.4000%
02/16 08:49:00 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_3x3', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1237, 0.1219, 0.1237, 0.1255, 0.1264, 0.1267, 0.1268, 0.1253],
        [0.1219, 0.1211, 0.1224, 0.1250, 0.1273, 0.1273, 0.1272, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1235, 0.1213, 0.1229, 0.1280, 0.1260, 0.1263, 0.1259, 0.1262],
        [0.1220, 0.1206, 0.1221, 0.1263, 0.1272, 0.1268, 0.1270, 0.1280],
        [0.1204, 0.1197, 0.1228, 0.1270, 0.1270, 0.1276, 0.1265, 0.1291]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1239, 0.1214, 0.1230, 0.1270, 0.1263, 0.1259, 0.1258, 0.1268],
        [0.1219, 0.1209, 0.1223, 0.1261, 0.1270, 0.1271, 0.1270, 0.1277],
        [0.1208, 0.1197, 0.1231, 0.1255, 0.1265, 0.1273, 0.1277, 0.1294],
        [0.1204, 0.1198, 0.1217, 0.1254, 0.1272, 0.1281, 0.1276, 0.1298]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1228, 0.1208, 0.1222, 0.1274, 0.1266, 0.1259, 0.1260, 0.1283],
        [0.1206, 0.1202, 0.1215, 0.1270, 0.1278, 0.1263, 0.1276, 0.1289],
        [0.1194, 0.1190, 0.1214, 0.1275, 0.1270, 0.1285, 0.1270, 0.1302],
        [0.1191, 0.1188, 0.1203, 0.1276, 0.1277, 0.1279, 0.1280, 0.1306],
        [0.1189, 0.1186, 0.1193, 0.1275, 0.1278, 0.1286, 0.1286, 0.1307]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1272, 0.1255, 0.1241, 0.1251, 0.1247, 0.1246, 0.1243, 0.1245],
        [0.1252, 0.1241, 0.1240, 0.1253, 0.1252, 0.1245, 0.1258, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1274, 0.1253, 0.1255, 0.1240, 0.1249, 0.1243, 0.1249, 0.1238],
        [0.1256, 0.1243, 0.1260, 0.1238, 0.1254, 0.1246, 0.1256, 0.1246],
        [0.1245, 0.1220, 0.1248, 0.1246, 0.1250, 0.1263, 0.1267, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1248, 0.1253, 0.1241, 0.1253, 0.1243, 0.1251, 0.1240],
        [0.1257, 0.1246, 0.1251, 0.1238, 0.1262, 0.1247, 0.1253, 0.1247],
        [0.1241, 0.1225, 0.1258, 0.1247, 0.1261, 0.1250, 0.1255, 0.1263],
        [0.1237, 0.1223, 0.1250, 0.1263, 0.1262, 0.1258, 0.1259, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1269, 0.1247, 0.1234, 0.1250, 0.1259, 0.1249, 0.1261, 0.1230],
        [0.1253, 0.1238, 0.1241, 0.1265, 0.1250, 0.1258, 0.1247, 0.1249],
        [0.1240, 0.1215, 0.1255, 0.1258, 0.1251, 0.1251, 0.1261, 0.1268],
        [0.1237, 0.1216, 0.1250, 0.1264, 0.1253, 0.1265, 0.1254, 0.1262],
        [0.1231, 0.1219, 0.1248, 0.1243, 0.1274, 0.1257, 0.1266, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 08:49:08 AM | Train: [24/50] Step 000/078 Loss1 2.665 Prec1@(1,5) (82.8%, 100.0%)
02/16 08:54:59 AM | Train: [24/50] Step 050/078 Loss1 2.604 Prec1@(1,5) (88.1%, 99.7%)
02/16 08:58:18 AM | Train: [24/50] Step 078/078 Loss1 2.603 Prec1@(1,5) (87.9%, 99.7%)
02/16 08:58:18 AM | Train: [24/50] Final Prec1@1 87.9400%
02/16 08:58:19 AM | Valid: [24/50] Step 000/078 Loss1 1.082 Prec1@(1,5) (64.1%, 96.9%)
02/16 08:58:29 AM | Valid: [24/50] Step 050/078 Loss1 1.066 Prec1@(1,5) (71.0%, 97.3%)
02/16 08:58:35 AM | Valid: [24/50] Step 078/078 Loss1 1.077 Prec1@(1,5) (70.2%, 97.3%)
02/16 08:58:35 AM | Valid: [24/50] Final Prec1@1 70.2200%
02/16 08:58:35 AM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1236, 0.1217, 0.1237, 0.1256, 0.1264, 0.1267, 0.1269, 0.1253],
        [0.1216, 0.1208, 0.1222, 0.1251, 0.1275, 0.1274, 0.1273, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1234, 0.1211, 0.1229, 0.1281, 0.1259, 0.1263, 0.1259, 0.1263],
        [0.1217, 0.1204, 0.1219, 0.1264, 0.1273, 0.1269, 0.1271, 0.1282],
        [0.1201, 0.1194, 0.1227, 0.1271, 0.1271, 0.1277, 0.1266, 0.1293]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1238, 0.1212, 0.1229, 0.1271, 0.1264, 0.1258, 0.1259, 0.1269],
        [0.1216, 0.1206, 0.1222, 0.1261, 0.1271, 0.1272, 0.1272, 0.1279],
        [0.1205, 0.1194, 0.1231, 0.1255, 0.1265, 0.1275, 0.1279, 0.1297],
        [0.1201, 0.1195, 0.1215, 0.1254, 0.1273, 0.1283, 0.1277, 0.1301]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1226, 0.1207, 0.1221, 0.1275, 0.1267, 0.1259, 0.1260, 0.1285],
        [0.1203, 0.1200, 0.1213, 0.1271, 0.1280, 0.1264, 0.1278, 0.1292],
        [0.1191, 0.1187, 0.1212, 0.1277, 0.1271, 0.1286, 0.1271, 0.1305],
        [0.1188, 0.1185, 0.1200, 0.1278, 0.1278, 0.1280, 0.1281, 0.1310],
        [0.1185, 0.1182, 0.1190, 0.1276, 0.1280, 0.1288, 0.1288, 0.1311]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1274, 0.1256, 0.1240, 0.1251, 0.1247, 0.1246, 0.1242, 0.1245],
        [0.1252, 0.1241, 0.1239, 0.1253, 0.1251, 0.1245, 0.1259, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1276, 0.1254, 0.1255, 0.1239, 0.1248, 0.1242, 0.1248, 0.1237],
        [0.1257, 0.1244, 0.1261, 0.1237, 0.1254, 0.1245, 0.1257, 0.1246],
        [0.1244, 0.1219, 0.1249, 0.1245, 0.1248, 0.1264, 0.1268, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1249, 0.1253, 0.1240, 0.1252, 0.1243, 0.1251, 0.1239],
        [0.1258, 0.1246, 0.1251, 0.1237, 0.1262, 0.1247, 0.1253, 0.1246],
        [0.1240, 0.1223, 0.1259, 0.1247, 0.1261, 0.1251, 0.1255, 0.1264],
        [0.1235, 0.1221, 0.1250, 0.1263, 0.1264, 0.1258, 0.1259, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1248, 0.1234, 0.1250, 0.1259, 0.1249, 0.1261, 0.1229],
        [0.1254, 0.1239, 0.1241, 0.1265, 0.1250, 0.1259, 0.1246, 0.1248],
        [0.1239, 0.1214, 0.1256, 0.1259, 0.1251, 0.1251, 0.1261, 0.1269],
        [0.1235, 0.1214, 0.1250, 0.1265, 0.1253, 0.1267, 0.1254, 0.1263],
        [0.1230, 0.1218, 0.1249, 0.1243, 0.1275, 0.1257, 0.1267, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 08:58:43 AM | Train: [25/50] Step 000/078 Loss1 2.582 Prec1@(1,5) (87.5%, 100.0%)
02/16 09:04:36 AM | Train: [25/50] Step 050/078 Loss1 2.526 Prec1@(1,5) (90.2%, 99.8%)
02/16 09:07:52 AM | Train: [25/50] Step 078/078 Loss1 2.533 Prec1@(1,5) (90.0%, 99.8%)
02/16 09:07:52 AM | Train: [25/50] Final Prec1@1 90.0000%
02/16 09:07:52 AM | Valid: [25/50] Step 000/078 Loss1 1.276 Prec1@(1,5) (73.4%, 98.4%)
02/16 09:08:03 AM | Valid: [25/50] Step 050/078 Loss1 1.154 Prec1@(1,5) (68.4%, 97.2%)
02/16 09:08:08 AM | Valid: [25/50] Step 078/078 Loss1 1.161 Prec1@(1,5) (68.0%, 97.4%)
02/16 09:08:08 AM | Valid: [25/50] Final Prec1@1 68.0000%
02/16 09:08:08 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1235, 0.1216, 0.1238, 0.1256, 0.1265, 0.1268, 0.1270, 0.1253],
        [0.1214, 0.1207, 0.1221, 0.1251, 0.1275, 0.1275, 0.1275, 0.1283]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1233, 0.1210, 0.1230, 0.1283, 0.1259, 0.1263, 0.1259, 0.1263],
        [0.1215, 0.1202, 0.1219, 0.1264, 0.1274, 0.1271, 0.1272, 0.1285],
        [0.1197, 0.1191, 0.1226, 0.1272, 0.1271, 0.1278, 0.1267, 0.1296]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1236, 0.1211, 0.1228, 0.1271, 0.1265, 0.1259, 0.1260, 0.1269],
        [0.1213, 0.1204, 0.1219, 0.1262, 0.1273, 0.1273, 0.1274, 0.1282],
        [0.1201, 0.1191, 0.1229, 0.1255, 0.1266, 0.1276, 0.1281, 0.1301],
        [0.1198, 0.1191, 0.1212, 0.1254, 0.1274, 0.1285, 0.1280, 0.1305]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1224, 0.1204, 0.1220, 0.1276, 0.1268, 0.1260, 0.1261, 0.1287],
        [0.1200, 0.1197, 0.1211, 0.1272, 0.1281, 0.1265, 0.1279, 0.1295],
        [0.1187, 0.1183, 0.1210, 0.1278, 0.1273, 0.1289, 0.1272, 0.1309],
        [0.1184, 0.1181, 0.1197, 0.1279, 0.1280, 0.1282, 0.1284, 0.1314],
        [0.1182, 0.1179, 0.1187, 0.1278, 0.1281, 0.1291, 0.1289, 0.1315]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1276, 0.1257, 0.1240, 0.1250, 0.1247, 0.1246, 0.1241, 0.1244],
        [0.1252, 0.1241, 0.1239, 0.1253, 0.1250, 0.1245, 0.1259, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1277, 0.1255, 0.1255, 0.1238, 0.1248, 0.1242, 0.1249, 0.1236],
        [0.1256, 0.1244, 0.1261, 0.1236, 0.1254, 0.1245, 0.1258, 0.1245],
        [0.1242, 0.1217, 0.1249, 0.1245, 0.1249, 0.1265, 0.1269, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1274, 0.1250, 0.1253, 0.1240, 0.1252, 0.1242, 0.1250, 0.1238],
        [0.1258, 0.1246, 0.1250, 0.1236, 0.1262, 0.1248, 0.1253, 0.1246],
        [0.1239, 0.1222, 0.1259, 0.1247, 0.1262, 0.1251, 0.1255, 0.1265],
        [0.1234, 0.1221, 0.1251, 0.1263, 0.1265, 0.1257, 0.1259, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1249, 0.1233, 0.1249, 0.1259, 0.1248, 0.1261, 0.1227],
        [0.1253, 0.1238, 0.1240, 0.1267, 0.1250, 0.1259, 0.1246, 0.1247],
        [0.1237, 0.1212, 0.1256, 0.1259, 0.1251, 0.1252, 0.1262, 0.1272],
        [0.1234, 0.1213, 0.1251, 0.1265, 0.1253, 0.1267, 0.1254, 0.1264],
        [0.1228, 0.1216, 0.1249, 0.1242, 0.1276, 0.1258, 0.1267, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 09:08:16 AM | Train: [26/50] Step 000/078 Loss1 2.537 Prec1@(1,5) (89.1%, 100.0%)
02/16 09:14:08 AM | Train: [26/50] Step 050/078 Loss1 2.524 Prec1@(1,5) (90.0%, 99.8%)
02/16 09:17:20 AM | Train: [26/50] Step 078/078 Loss1 2.519 Prec1@(1,5) (90.1%, 99.8%)
02/16 09:17:20 AM | Train: [26/50] Final Prec1@1 90.0800%
02/16 09:17:20 AM | Valid: [26/50] Step 000/078 Loss1 0.878 Prec1@(1,5) (76.6%, 96.9%)
02/16 09:17:31 AM | Valid: [26/50] Step 050/078 Loss1 1.183 Prec1@(1,5) (69.6%, 96.6%)
02/16 09:17:37 AM | Valid: [26/50] Step 078/078 Loss1 1.175 Prec1@(1,5) (69.4%, 96.8%)
02/16 09:17:37 AM | Valid: [26/50] Final Prec1@1 69.4400%
02/16 09:17:37 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1235, 0.1216, 0.1238, 0.1256, 0.1265, 0.1268, 0.1272, 0.1251],
        [0.1211, 0.1204, 0.1220, 0.1251, 0.1276, 0.1277, 0.1277, 0.1286]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1232, 0.1209, 0.1230, 0.1285, 0.1259, 0.1263, 0.1259, 0.1263],
        [0.1212, 0.1199, 0.1217, 0.1264, 0.1275, 0.1273, 0.1273, 0.1288],
        [0.1194, 0.1188, 0.1225, 0.1272, 0.1273, 0.1280, 0.1269, 0.1299]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1236, 0.1210, 0.1228, 0.1271, 0.1266, 0.1259, 0.1260, 0.1270],
        [0.1210, 0.1201, 0.1217, 0.1264, 0.1274, 0.1275, 0.1276, 0.1284],
        [0.1198, 0.1188, 0.1229, 0.1255, 0.1266, 0.1277, 0.1282, 0.1304],
        [0.1195, 0.1189, 0.1211, 0.1254, 0.1274, 0.1286, 0.1282, 0.1309]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1223, 0.1203, 0.1220, 0.1276, 0.1268, 0.1260, 0.1262, 0.1288],
        [0.1197, 0.1194, 0.1208, 0.1273, 0.1283, 0.1266, 0.1280, 0.1298],
        [0.1184, 0.1180, 0.1208, 0.1279, 0.1273, 0.1291, 0.1273, 0.1312],
        [0.1181, 0.1178, 0.1195, 0.1280, 0.1281, 0.1283, 0.1285, 0.1317],
        [0.1178, 0.1176, 0.1184, 0.1278, 0.1283, 0.1293, 0.1290, 0.1318]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1277, 0.1258, 0.1239, 0.1250, 0.1246, 0.1246, 0.1241, 0.1243],
        [0.1252, 0.1241, 0.1238, 0.1253, 0.1251, 0.1245, 0.1260, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1278, 0.1256, 0.1255, 0.1237, 0.1247, 0.1242, 0.1249, 0.1235],
        [0.1257, 0.1244, 0.1262, 0.1235, 0.1254, 0.1245, 0.1259, 0.1244],
        [0.1241, 0.1216, 0.1249, 0.1244, 0.1248, 0.1266, 0.1270, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1275, 0.1251, 0.1254, 0.1239, 0.1251, 0.1243, 0.1250, 0.1237],
        [0.1259, 0.1246, 0.1250, 0.1235, 0.1263, 0.1247, 0.1253, 0.1245],
        [0.1237, 0.1221, 0.1259, 0.1247, 0.1262, 0.1252, 0.1256, 0.1266],
        [0.1233, 0.1220, 0.1252, 0.1264, 0.1266, 0.1257, 0.1259, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1274, 0.1249, 0.1232, 0.1250, 0.1260, 0.1248, 0.1262, 0.1225],
        [0.1254, 0.1238, 0.1239, 0.1267, 0.1249, 0.1259, 0.1245, 0.1247],
        [0.1235, 0.1210, 0.1257, 0.1259, 0.1251, 0.1252, 0.1263, 0.1273],
        [0.1233, 0.1211, 0.1251, 0.1265, 0.1254, 0.1268, 0.1254, 0.1264],
        [0.1227, 0.1215, 0.1250, 0.1241, 0.1277, 0.1258, 0.1268, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 09:17:44 AM | Train: [27/50] Step 000/078 Loss1 2.411 Prec1@(1,5) (95.3%, 100.0%)
02/16 09:23:32 AM | Train: [27/50] Step 050/078 Loss1 2.463 Prec1@(1,5) (92.1%, 100.0%)
02/16 09:26:54 AM | Train: [27/50] Step 078/078 Loss1 2.460 Prec1@(1,5) (92.1%, 99.9%)
02/16 09:26:54 AM | Train: [27/50] Final Prec1@1 92.1000%
02/16 09:26:54 AM | Valid: [27/50] Step 000/078 Loss1 1.288 Prec1@(1,5) (68.8%, 95.3%)
02/16 09:27:06 AM | Valid: [27/50] Step 050/078 Loss1 1.172 Prec1@(1,5) (68.8%, 97.5%)
02/16 09:27:12 AM | Valid: [27/50] Step 078/078 Loss1 1.142 Prec1@(1,5) (70.0%, 97.5%)
02/16 09:27:12 AM | Valid: [27/50] Final Prec1@1 70.0200%
02/16 09:27:12 AM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1234, 0.1214, 0.1238, 0.1256, 0.1265, 0.1268, 0.1273, 0.1251],
        [0.1208, 0.1203, 0.1218, 0.1251, 0.1276, 0.1278, 0.1278, 0.1288]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1231, 0.1207, 0.1230, 0.1286, 0.1259, 0.1264, 0.1259, 0.1264],
        [0.1209, 0.1197, 0.1216, 0.1264, 0.1276, 0.1274, 0.1274, 0.1289],
        [0.1191, 0.1185, 0.1224, 0.1273, 0.1274, 0.1282, 0.1271, 0.1302]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1235, 0.1208, 0.1228, 0.1271, 0.1267, 0.1260, 0.1260, 0.1270],
        [0.1207, 0.1199, 0.1216, 0.1264, 0.1275, 0.1276, 0.1278, 0.1286],
        [0.1195, 0.1185, 0.1228, 0.1256, 0.1267, 0.1278, 0.1284, 0.1307],
        [0.1192, 0.1186, 0.1209, 0.1254, 0.1275, 0.1288, 0.1283, 0.1313]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1222, 0.1201, 0.1218, 0.1277, 0.1270, 0.1261, 0.1262, 0.1290],
        [0.1194, 0.1191, 0.1206, 0.1275, 0.1285, 0.1267, 0.1282, 0.1301],
        [0.1180, 0.1176, 0.1206, 0.1281, 0.1274, 0.1293, 0.1274, 0.1316],
        [0.1177, 0.1174, 0.1192, 0.1282, 0.1282, 0.1286, 0.1287, 0.1320],
        [0.1175, 0.1172, 0.1180, 0.1279, 0.1284, 0.1295, 0.1292, 0.1322]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1279, 0.1260, 0.1238, 0.1249, 0.1246, 0.1245, 0.1240, 0.1243],
        [0.1252, 0.1240, 0.1237, 0.1253, 0.1250, 0.1245, 0.1260, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1280, 0.1257, 0.1256, 0.1236, 0.1246, 0.1242, 0.1249, 0.1234],
        [0.1257, 0.1244, 0.1262, 0.1235, 0.1254, 0.1244, 0.1259, 0.1244],
        [0.1240, 0.1214, 0.1249, 0.1244, 0.1248, 0.1267, 0.1271, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1277, 0.1253, 0.1254, 0.1238, 0.1250, 0.1242, 0.1250, 0.1237],
        [0.1259, 0.1247, 0.1249, 0.1234, 0.1264, 0.1248, 0.1254, 0.1245],
        [0.1236, 0.1220, 0.1260, 0.1247, 0.1263, 0.1252, 0.1256, 0.1267],
        [0.1232, 0.1219, 0.1253, 0.1264, 0.1266, 0.1258, 0.1258, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1275, 0.1251, 0.1232, 0.1249, 0.1260, 0.1248, 0.1262, 0.1224],
        [0.1254, 0.1238, 0.1239, 0.1268, 0.1249, 0.1260, 0.1244, 0.1247],
        [0.1234, 0.1209, 0.1258, 0.1259, 0.1251, 0.1252, 0.1263, 0.1274],
        [0.1231, 0.1210, 0.1252, 0.1266, 0.1253, 0.1269, 0.1253, 0.1265],
        [0.1226, 0.1214, 0.1251, 0.1241, 0.1278, 0.1258, 0.1268, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 09:27:20 AM | Train: [28/50] Step 000/078 Loss1 2.384 Prec1@(1,5) (93.8%, 100.0%)
02/16 09:33:22 AM | Train: [28/50] Step 050/078 Loss1 2.440 Prec1@(1,5) (92.0%, 99.9%)
02/16 09:36:45 AM | Train: [28/50] Step 078/078 Loss1 2.443 Prec1@(1,5) (91.8%, 99.9%)
02/16 09:36:45 AM | Train: [28/50] Final Prec1@1 91.7600%
02/16 09:36:45 AM | Valid: [28/50] Step 000/078 Loss1 2.284 Prec1@(1,5) (56.2%, 93.8%)
02/16 09:36:58 AM | Valid: [28/50] Step 050/078 Loss1 1.304 Prec1@(1,5) (68.6%, 97.4%)
02/16 09:37:04 AM | Valid: [28/50] Step 078/078 Loss1 1.327 Prec1@(1,5) (68.5%, 97.1%)
02/16 09:37:04 AM | Valid: [28/50] Final Prec1@1 68.5200%
02/16 09:37:04 AM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1233, 0.1213, 0.1239, 0.1256, 0.1265, 0.1269, 0.1273, 0.1251],
        [0.1206, 0.1200, 0.1217, 0.1251, 0.1278, 0.1279, 0.1280, 0.1290]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1230, 0.1206, 0.1230, 0.1286, 0.1260, 0.1265, 0.1260, 0.1263],
        [0.1207, 0.1194, 0.1214, 0.1265, 0.1277, 0.1275, 0.1275, 0.1292],
        [0.1187, 0.1182, 0.1223, 0.1274, 0.1275, 0.1283, 0.1272, 0.1305]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1234, 0.1207, 0.1228, 0.1272, 0.1268, 0.1260, 0.1261, 0.1271],
        [0.1204, 0.1197, 0.1214, 0.1264, 0.1277, 0.1277, 0.1279, 0.1288],
        [0.1192, 0.1182, 0.1227, 0.1256, 0.1268, 0.1279, 0.1285, 0.1310],
        [0.1189, 0.1183, 0.1208, 0.1254, 0.1275, 0.1291, 0.1284, 0.1316]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1220, 0.1199, 0.1218, 0.1278, 0.1270, 0.1262, 0.1262, 0.1292],
        [0.1190, 0.1188, 0.1204, 0.1276, 0.1287, 0.1268, 0.1284, 0.1303],
        [0.1176, 0.1173, 0.1205, 0.1282, 0.1275, 0.1295, 0.1275, 0.1319],
        [0.1174, 0.1171, 0.1189, 0.1283, 0.1283, 0.1288, 0.1288, 0.1324],
        [0.1171, 0.1168, 0.1177, 0.1280, 0.1285, 0.1298, 0.1295, 0.1326]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1281, 0.1261, 0.1237, 0.1248, 0.1245, 0.1246, 0.1239, 0.1243],
        [0.1252, 0.1240, 0.1237, 0.1254, 0.1251, 0.1245, 0.1259, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1281, 0.1258, 0.1256, 0.1236, 0.1246, 0.1242, 0.1249, 0.1233],
        [0.1258, 0.1244, 0.1263, 0.1234, 0.1254, 0.1244, 0.1260, 0.1244],
        [0.1239, 0.1213, 0.1250, 0.1243, 0.1248, 0.1267, 0.1272, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1279, 0.1254, 0.1254, 0.1237, 0.1250, 0.1242, 0.1249, 0.1236],
        [0.1259, 0.1247, 0.1249, 0.1233, 0.1265, 0.1248, 0.1254, 0.1245],
        [0.1235, 0.1219, 0.1261, 0.1247, 0.1263, 0.1253, 0.1255, 0.1267],
        [0.1230, 0.1218, 0.1254, 0.1265, 0.1267, 0.1258, 0.1258, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1277, 0.1252, 0.1231, 0.1248, 0.1260, 0.1247, 0.1263, 0.1222],
        [0.1254, 0.1238, 0.1239, 0.1268, 0.1249, 0.1260, 0.1244, 0.1247],
        [0.1233, 0.1207, 0.1258, 0.1260, 0.1251, 0.1252, 0.1264, 0.1275],
        [0.1230, 0.1208, 0.1252, 0.1267, 0.1253, 0.1271, 0.1254, 0.1265],
        [0.1224, 0.1213, 0.1252, 0.1240, 0.1279, 0.1257, 0.1269, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 09:37:12 AM | Train: [29/50] Step 000/078 Loss1 2.302 Prec1@(1,5) (98.4%, 100.0%)
02/16 09:43:14 AM | Train: [29/50] Step 050/078 Loss1 2.387 Prec1@(1,5) (93.8%, 100.0%)
02/16 09:46:36 AM | Train: [29/50] Step 078/078 Loss1 2.396 Prec1@(1,5) (93.3%, 100.0%)
02/16 09:46:36 AM | Train: [29/50] Final Prec1@1 93.3400%
02/16 09:46:36 AM | Valid: [29/50] Step 000/078 Loss1 1.642 Prec1@(1,5) (53.1%, 95.3%)
02/16 09:46:48 AM | Valid: [29/50] Step 050/078 Loss1 1.167 Prec1@(1,5) (69.1%, 97.2%)
02/16 09:46:55 AM | Valid: [29/50] Step 078/078 Loss1 1.209 Prec1@(1,5) (69.2%, 97.2%)
02/16 09:46:55 AM | Valid: [29/50] Final Prec1@1 69.1800%
02/16 09:46:55 AM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1233, 0.1213, 0.1240, 0.1256, 0.1266, 0.1268, 0.1274, 0.1250],
        [0.1203, 0.1198, 0.1216, 0.1251, 0.1278, 0.1280, 0.1280, 0.1293]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1229, 0.1205, 0.1231, 0.1287, 0.1260, 0.1266, 0.1260, 0.1263],
        [0.1205, 0.1193, 0.1213, 0.1266, 0.1278, 0.1276, 0.1275, 0.1294],
        [0.1184, 0.1179, 0.1222, 0.1275, 0.1275, 0.1284, 0.1273, 0.1307]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1233, 0.1205, 0.1227, 0.1273, 0.1269, 0.1260, 0.1261, 0.1272],
        [0.1202, 0.1195, 0.1213, 0.1265, 0.1277, 0.1278, 0.1280, 0.1290],
        [0.1189, 0.1180, 0.1227, 0.1256, 0.1269, 0.1280, 0.1286, 0.1313],
        [0.1186, 0.1181, 0.1206, 0.1253, 0.1275, 0.1293, 0.1286, 0.1320]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1219, 0.1197, 0.1218, 0.1278, 0.1270, 0.1262, 0.1262, 0.1293],
        [0.1188, 0.1186, 0.1202, 0.1277, 0.1288, 0.1268, 0.1286, 0.1306],
        [0.1173, 0.1170, 0.1203, 0.1284, 0.1275, 0.1296, 0.1275, 0.1323],
        [0.1171, 0.1168, 0.1187, 0.1284, 0.1284, 0.1289, 0.1290, 0.1328],
        [0.1168, 0.1165, 0.1174, 0.1280, 0.1287, 0.1300, 0.1296, 0.1330]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1283, 0.1262, 0.1237, 0.1247, 0.1245, 0.1245, 0.1238, 0.1243],
        [0.1253, 0.1241, 0.1236, 0.1254, 0.1250, 0.1245, 0.1259, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1282, 0.1258, 0.1256, 0.1235, 0.1246, 0.1241, 0.1250, 0.1232],
        [0.1259, 0.1246, 0.1263, 0.1233, 0.1253, 0.1243, 0.1260, 0.1243],
        [0.1238, 0.1213, 0.1251, 0.1241, 0.1247, 0.1268, 0.1273, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1280, 0.1254, 0.1255, 0.1236, 0.1249, 0.1241, 0.1249, 0.1236],
        [0.1260, 0.1248, 0.1249, 0.1233, 0.1265, 0.1248, 0.1253, 0.1244],
        [0.1234, 0.1218, 0.1262, 0.1248, 0.1263, 0.1253, 0.1255, 0.1268],
        [0.1229, 0.1216, 0.1254, 0.1265, 0.1267, 0.1258, 0.1259, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1279, 0.1252, 0.1230, 0.1247, 0.1260, 0.1248, 0.1263, 0.1221],
        [0.1255, 0.1239, 0.1238, 0.1269, 0.1249, 0.1261, 0.1243, 0.1246],
        [0.1231, 0.1205, 0.1259, 0.1261, 0.1251, 0.1252, 0.1264, 0.1276],
        [0.1228, 0.1207, 0.1253, 0.1267, 0.1253, 0.1271, 0.1253, 0.1267],
        [0.1223, 0.1212, 0.1253, 0.1239, 0.1280, 0.1257, 0.1270, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 09:47:02 AM | Train: [30/50] Step 000/078 Loss1 2.478 Prec1@(1,5) (90.6%, 100.0%)
02/16 09:53:02 AM | Train: [30/50] Step 050/078 Loss1 2.351 Prec1@(1,5) (95.1%, 100.0%)
02/16 09:56:24 AM | Train: [30/50] Step 078/078 Loss1 2.354 Prec1@(1,5) (94.9%, 99.9%)
02/16 09:56:24 AM | Train: [30/50] Final Prec1@1 94.8600%
02/16 09:56:24 AM | Valid: [30/50] Step 000/078 Loss1 1.314 Prec1@(1,5) (70.3%, 95.3%)
02/16 09:56:36 AM | Valid: [30/50] Step 050/078 Loss1 1.499 Prec1@(1,5) (66.9%, 95.7%)
02/16 09:56:42 AM | Valid: [30/50] Step 078/078 Loss1 1.454 Prec1@(1,5) (67.9%, 96.1%)
02/16 09:56:42 AM | Valid: [30/50] Final Prec1@1 67.9200%
02/16 09:56:42 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1232, 0.1212, 0.1240, 0.1257, 0.1267, 0.1269, 0.1275, 0.1249],
        [0.1201, 0.1196, 0.1215, 0.1251, 0.1279, 0.1282, 0.1281, 0.1295]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1228, 0.1204, 0.1231, 0.1288, 0.1259, 0.1266, 0.1260, 0.1263],
        [0.1203, 0.1191, 0.1212, 0.1266, 0.1279, 0.1277, 0.1276, 0.1296],
        [0.1182, 0.1177, 0.1222, 0.1276, 0.1275, 0.1285, 0.1274, 0.1310]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1232, 0.1205, 0.1228, 0.1273, 0.1269, 0.1260, 0.1261, 0.1272],
        [0.1199, 0.1192, 0.1211, 0.1266, 0.1278, 0.1280, 0.1281, 0.1292],
        [0.1186, 0.1177, 0.1226, 0.1256, 0.1269, 0.1281, 0.1287, 0.1316],
        [0.1183, 0.1178, 0.1205, 0.1253, 0.1274, 0.1295, 0.1287, 0.1324]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1218, 0.1196, 0.1217, 0.1278, 0.1271, 0.1263, 0.1262, 0.1295],
        [0.1185, 0.1184, 0.1200, 0.1278, 0.1288, 0.1269, 0.1288, 0.1309],
        [0.1170, 0.1167, 0.1202, 0.1286, 0.1275, 0.1298, 0.1276, 0.1326],
        [0.1167, 0.1164, 0.1184, 0.1286, 0.1285, 0.1291, 0.1291, 0.1332],
        [0.1164, 0.1162, 0.1171, 0.1281, 0.1288, 0.1302, 0.1297, 0.1334]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1284, 0.1263, 0.1237, 0.1247, 0.1244, 0.1245, 0.1237, 0.1243],
        [0.1254, 0.1241, 0.1236, 0.1254, 0.1250, 0.1245, 0.1259, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1283, 0.1259, 0.1256, 0.1234, 0.1247, 0.1241, 0.1249, 0.1231],
        [0.1260, 0.1246, 0.1264, 0.1233, 0.1252, 0.1242, 0.1261, 0.1243],
        [0.1237, 0.1211, 0.1251, 0.1240, 0.1247, 0.1270, 0.1274, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1281, 0.1255, 0.1255, 0.1236, 0.1249, 0.1240, 0.1250, 0.1235],
        [0.1261, 0.1249, 0.1248, 0.1232, 0.1265, 0.1248, 0.1254, 0.1243],
        [0.1232, 0.1217, 0.1262, 0.1248, 0.1263, 0.1252, 0.1256, 0.1269],
        [0.1228, 0.1216, 0.1255, 0.1264, 0.1268, 0.1258, 0.1259, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1280, 0.1252, 0.1230, 0.1246, 0.1260, 0.1248, 0.1264, 0.1220],
        [0.1257, 0.1241, 0.1237, 0.1270, 0.1248, 0.1260, 0.1241, 0.1245],
        [0.1230, 0.1204, 0.1260, 0.1262, 0.1250, 0.1252, 0.1264, 0.1278],
        [0.1227, 0.1206, 0.1254, 0.1268, 0.1252, 0.1272, 0.1254, 0.1267],
        [0.1222, 0.1211, 0.1254, 0.1239, 0.1281, 0.1257, 0.1270, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 09:56:50 AM | Train: [31/50] Step 000/078 Loss1 2.312 Prec1@(1,5) (95.3%, 100.0%)
02/16 10:02:52 AM | Train: [31/50] Step 050/078 Loss1 2.332 Prec1@(1,5) (95.5%, 100.0%)
02/16 10:06:13 AM | Train: [31/50] Step 078/078 Loss1 2.338 Prec1@(1,5) (95.0%, 99.9%)
02/16 10:06:13 AM | Train: [31/50] Final Prec1@1 95.0000%
02/16 10:06:13 AM | Valid: [31/50] Step 000/078 Loss1 1.413 Prec1@(1,5) (75.0%, 96.9%)
02/16 10:06:25 AM | Valid: [31/50] Step 050/078 Loss1 1.337 Prec1@(1,5) (69.8%, 96.9%)
02/16 10:06:32 AM | Valid: [31/50] Step 078/078 Loss1 1.365 Prec1@(1,5) (69.4%, 96.7%)
02/16 10:06:32 AM | Valid: [31/50] Final Prec1@1 69.3600%
02/16 10:06:32 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1231, 0.1211, 0.1241, 0.1258, 0.1267, 0.1269, 0.1276, 0.1248],
        [0.1199, 0.1194, 0.1214, 0.1251, 0.1279, 0.1283, 0.1282, 0.1298]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1227, 0.1203, 0.1232, 0.1289, 0.1260, 0.1266, 0.1260, 0.1263],
        [0.1200, 0.1189, 0.1211, 0.1266, 0.1280, 0.1278, 0.1277, 0.1298],
        [0.1179, 0.1174, 0.1221, 0.1276, 0.1275, 0.1286, 0.1275, 0.1313]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1231, 0.1203, 0.1228, 0.1273, 0.1270, 0.1261, 0.1261, 0.1272],
        [0.1197, 0.1190, 0.1210, 0.1267, 0.1279, 0.1281, 0.1282, 0.1294],
        [0.1183, 0.1174, 0.1226, 0.1256, 0.1270, 0.1283, 0.1289, 0.1319],
        [0.1180, 0.1175, 0.1204, 0.1252, 0.1274, 0.1297, 0.1289, 0.1329]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1216, 0.1194, 0.1217, 0.1279, 0.1271, 0.1263, 0.1263, 0.1297],
        [0.1182, 0.1181, 0.1198, 0.1280, 0.1290, 0.1270, 0.1289, 0.1312],
        [0.1166, 0.1163, 0.1200, 0.1289, 0.1276, 0.1300, 0.1277, 0.1329],
        [0.1164, 0.1161, 0.1181, 0.1287, 0.1286, 0.1292, 0.1292, 0.1336],
        [0.1161, 0.1159, 0.1168, 0.1282, 0.1289, 0.1304, 0.1300, 0.1338]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1286, 0.1263, 0.1236, 0.1247, 0.1244, 0.1245, 0.1236, 0.1243],
        [0.1255, 0.1242, 0.1235, 0.1254, 0.1250, 0.1244, 0.1260, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1284, 0.1259, 0.1257, 0.1234, 0.1247, 0.1240, 0.1249, 0.1230],
        [0.1261, 0.1247, 0.1264, 0.1232, 0.1252, 0.1241, 0.1261, 0.1241],
        [0.1236, 0.1210, 0.1252, 0.1239, 0.1246, 0.1271, 0.1275, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1282, 0.1255, 0.1254, 0.1235, 0.1248, 0.1240, 0.1250, 0.1235],
        [0.1263, 0.1250, 0.1248, 0.1231, 0.1265, 0.1248, 0.1253, 0.1242],
        [0.1230, 0.1216, 0.1263, 0.1248, 0.1264, 0.1252, 0.1256, 0.1270],
        [0.1226, 0.1215, 0.1255, 0.1265, 0.1270, 0.1258, 0.1259, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1280, 0.1252, 0.1230, 0.1246, 0.1261, 0.1248, 0.1264, 0.1219],
        [0.1259, 0.1243, 0.1237, 0.1270, 0.1247, 0.1260, 0.1241, 0.1244],
        [0.1228, 0.1203, 0.1261, 0.1262, 0.1250, 0.1252, 0.1265, 0.1279],
        [0.1226, 0.1205, 0.1255, 0.1269, 0.1251, 0.1273, 0.1254, 0.1267],
        [0.1220, 0.1210, 0.1255, 0.1238, 0.1281, 0.1257, 0.1270, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 10:06:40 AM | Train: [32/50] Step 000/078 Loss1 2.346 Prec1@(1,5) (95.3%, 100.0%)
02/16 10:12:41 AM | Train: [32/50] Step 050/078 Loss1 2.313 Prec1@(1,5) (95.4%, 100.0%)
02/16 10:16:03 AM | Train: [32/50] Step 078/078 Loss1 2.312 Prec1@(1,5) (95.4%, 100.0%)
02/16 10:16:03 AM | Train: [32/50] Final Prec1@1 95.4200%
02/16 10:16:04 AM | Valid: [32/50] Step 000/078 Loss1 1.441 Prec1@(1,5) (68.8%, 96.9%)
02/16 10:16:15 AM | Valid: [32/50] Step 050/078 Loss1 1.359 Prec1@(1,5) (69.1%, 97.0%)
02/16 10:16:22 AM | Valid: [32/50] Step 078/078 Loss1 1.358 Prec1@(1,5) (69.2%, 96.8%)
02/16 10:16:22 AM | Valid: [32/50] Final Prec1@1 69.2000%
02/16 10:16:22 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1231, 0.1211, 0.1242, 0.1257, 0.1267, 0.1268, 0.1277, 0.1247],
        [0.1197, 0.1192, 0.1213, 0.1251, 0.1280, 0.1284, 0.1283, 0.1301]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1227, 0.1202, 0.1233, 0.1289, 0.1260, 0.1267, 0.1260, 0.1263],
        [0.1198, 0.1187, 0.1210, 0.1267, 0.1280, 0.1279, 0.1278, 0.1300],
        [0.1176, 0.1171, 0.1221, 0.1277, 0.1275, 0.1288, 0.1275, 0.1316]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1231, 0.1202, 0.1228, 0.1273, 0.1271, 0.1260, 0.1261, 0.1272],
        [0.1195, 0.1188, 0.1208, 0.1268, 0.1280, 0.1282, 0.1284, 0.1297],
        [0.1181, 0.1171, 0.1225, 0.1257, 0.1269, 0.1284, 0.1290, 0.1323],
        [0.1178, 0.1173, 0.1202, 0.1251, 0.1274, 0.1298, 0.1291, 0.1332]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1215, 0.1192, 0.1217, 0.1280, 0.1271, 0.1263, 0.1263, 0.1298],
        [0.1179, 0.1178, 0.1195, 0.1281, 0.1291, 0.1272, 0.1290, 0.1314],
        [0.1163, 0.1160, 0.1198, 0.1290, 0.1277, 0.1302, 0.1277, 0.1332],
        [0.1161, 0.1158, 0.1179, 0.1289, 0.1286, 0.1293, 0.1293, 0.1339],
        [0.1158, 0.1156, 0.1165, 0.1282, 0.1290, 0.1306, 0.1302, 0.1342]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1287, 0.1264, 0.1236, 0.1246, 0.1243, 0.1246, 0.1235, 0.1243],
        [0.1256, 0.1243, 0.1234, 0.1253, 0.1250, 0.1244, 0.1259, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1286, 0.1260, 0.1256, 0.1233, 0.1246, 0.1240, 0.1249, 0.1230],
        [0.1263, 0.1249, 0.1264, 0.1232, 0.1251, 0.1240, 0.1261, 0.1240],
        [0.1235, 0.1210, 0.1253, 0.1238, 0.1244, 0.1272, 0.1275, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1283, 0.1256, 0.1255, 0.1234, 0.1247, 0.1240, 0.1250, 0.1234],
        [0.1264, 0.1251, 0.1248, 0.1230, 0.1265, 0.1248, 0.1253, 0.1241],
        [0.1229, 0.1215, 0.1264, 0.1248, 0.1264, 0.1252, 0.1256, 0.1272],
        [0.1225, 0.1213, 0.1255, 0.1265, 0.1271, 0.1258, 0.1259, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1281, 0.1253, 0.1228, 0.1246, 0.1261, 0.1248, 0.1265, 0.1218],
        [0.1260, 0.1244, 0.1236, 0.1270, 0.1246, 0.1259, 0.1240, 0.1243],
        [0.1227, 0.1202, 0.1262, 0.1262, 0.1249, 0.1251, 0.1265, 0.1280],
        [0.1225, 0.1204, 0.1256, 0.1269, 0.1250, 0.1274, 0.1254, 0.1268],
        [0.1220, 0.1210, 0.1256, 0.1235, 0.1282, 0.1257, 0.1270, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 10:16:30 AM | Train: [33/50] Step 000/078 Loss1 2.277 Prec1@(1,5) (98.4%, 100.0%)
02/16 10:22:31 AM | Train: [33/50] Step 050/078 Loss1 2.278 Prec1@(1,5) (96.4%, 100.0%)
02/16 10:25:57 AM | Train: [33/50] Step 078/078 Loss1 2.280 Prec1@(1,5) (96.1%, 100.0%)
02/16 10:25:57 AM | Train: [33/50] Final Prec1@1 96.1400%
02/16 10:25:57 AM | Valid: [33/50] Step 000/078 Loss1 1.191 Prec1@(1,5) (73.4%, 96.9%)
02/16 10:26:09 AM | Valid: [33/50] Step 050/078 Loss1 1.286 Prec1@(1,5) (70.1%, 96.9%)
02/16 10:26:15 AM | Valid: [33/50] Step 078/078 Loss1 1.279 Prec1@(1,5) (70.9%, 97.1%)
02/16 10:26:15 AM | Valid: [33/50] Final Prec1@1 70.9000%
02/16 10:26:15 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1231, 0.1211, 0.1243, 0.1257, 0.1267, 0.1268, 0.1277, 0.1245],
        [0.1194, 0.1190, 0.1212, 0.1251, 0.1280, 0.1285, 0.1284, 0.1304]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1227, 0.1201, 0.1233, 0.1291, 0.1259, 0.1267, 0.1259, 0.1263],
        [0.1196, 0.1185, 0.1209, 0.1268, 0.1281, 0.1280, 0.1279, 0.1302],
        [0.1173, 0.1169, 0.1220, 0.1278, 0.1275, 0.1289, 0.1276, 0.1319]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1231, 0.1201, 0.1229, 0.1273, 0.1272, 0.1260, 0.1261, 0.1272],
        [0.1192, 0.1185, 0.1206, 0.1268, 0.1280, 0.1283, 0.1286, 0.1299],
        [0.1178, 0.1168, 0.1224, 0.1257, 0.1270, 0.1285, 0.1292, 0.1326],
        [0.1175, 0.1170, 0.1201, 0.1251, 0.1274, 0.1301, 0.1292, 0.1336]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1214, 0.1191, 0.1216, 0.1280, 0.1272, 0.1263, 0.1263, 0.1300],
        [0.1176, 0.1175, 0.1193, 0.1282, 0.1292, 0.1274, 0.1292, 0.1317],
        [0.1160, 0.1157, 0.1196, 0.1292, 0.1278, 0.1303, 0.1278, 0.1336],
        [0.1158, 0.1155, 0.1176, 0.1290, 0.1287, 0.1296, 0.1295, 0.1343],
        [0.1155, 0.1152, 0.1161, 0.1282, 0.1292, 0.1308, 0.1304, 0.1346]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1289, 0.1265, 0.1235, 0.1246, 0.1242, 0.1246, 0.1233, 0.1243],
        [0.1257, 0.1244, 0.1233, 0.1253, 0.1250, 0.1244, 0.1259, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1287, 0.1261, 0.1257, 0.1232, 0.1245, 0.1240, 0.1249, 0.1228],
        [0.1264, 0.1250, 0.1264, 0.1231, 0.1251, 0.1239, 0.1261, 0.1239],
        [0.1234, 0.1209, 0.1254, 0.1237, 0.1243, 0.1273, 0.1276, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1285, 0.1257, 0.1255, 0.1233, 0.1246, 0.1239, 0.1251, 0.1233],
        [0.1266, 0.1252, 0.1248, 0.1229, 0.1265, 0.1247, 0.1253, 0.1240],
        [0.1228, 0.1214, 0.1266, 0.1248, 0.1264, 0.1252, 0.1255, 0.1273],
        [0.1224, 0.1212, 0.1256, 0.1265, 0.1272, 0.1258, 0.1259, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1284, 0.1254, 0.1227, 0.1246, 0.1261, 0.1248, 0.1265, 0.1216],
        [0.1262, 0.1245, 0.1235, 0.1270, 0.1245, 0.1259, 0.1240, 0.1242],
        [0.1226, 0.1201, 0.1264, 0.1262, 0.1249, 0.1251, 0.1265, 0.1281],
        [0.1225, 0.1203, 0.1258, 0.1269, 0.1250, 0.1274, 0.1253, 0.1268],
        [0.1219, 0.1210, 0.1258, 0.1234, 0.1282, 0.1257, 0.1270, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 10:26:23 AM | Train: [34/50] Step 000/078 Loss1 2.234 Prec1@(1,5) (98.4%, 100.0%)
02/16 10:32:28 AM | Train: [34/50] Step 050/078 Loss1 2.264 Prec1@(1,5) (96.7%, 100.0%)
02/16 10:35:50 AM | Train: [34/50] Step 078/078 Loss1 2.258 Prec1@(1,5) (96.8%, 100.0%)
02/16 10:35:50 AM | Train: [34/50] Final Prec1@1 96.7600%
02/16 10:35:50 AM | Valid: [34/50] Step 000/078 Loss1 1.290 Prec1@(1,5) (68.8%, 90.6%)
02/16 10:36:03 AM | Valid: [34/50] Step 050/078 Loss1 1.335 Prec1@(1,5) (70.3%, 96.8%)
02/16 10:36:10 AM | Valid: [34/50] Step 078/078 Loss1 1.329 Prec1@(1,5) (70.7%, 96.9%)
02/16 10:36:10 AM | Valid: [34/50] Final Prec1@1 70.7000%
02/16 10:36:10 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1231, 0.1210, 0.1244, 0.1256, 0.1267, 0.1268, 0.1278, 0.1245],
        [0.1192, 0.1188, 0.1211, 0.1250, 0.1281, 0.1286, 0.1285, 0.1306]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1226, 0.1200, 0.1234, 0.1291, 0.1258, 0.1267, 0.1261, 0.1262],
        [0.1194, 0.1183, 0.1208, 0.1268, 0.1281, 0.1281, 0.1281, 0.1304],
        [0.1171, 0.1166, 0.1220, 0.1278, 0.1276, 0.1290, 0.1277, 0.1322]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1231, 0.1201, 0.1230, 0.1273, 0.1273, 0.1260, 0.1261, 0.1273],
        [0.1190, 0.1183, 0.1205, 0.1268, 0.1281, 0.1283, 0.1288, 0.1302],
        [0.1175, 0.1166, 0.1223, 0.1257, 0.1270, 0.1286, 0.1294, 0.1329],
        [0.1173, 0.1168, 0.1200, 0.1251, 0.1273, 0.1302, 0.1294, 0.1339]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1213, 0.1189, 0.1216, 0.1281, 0.1273, 0.1263, 0.1263, 0.1301],
        [0.1173, 0.1173, 0.1191, 0.1283, 0.1293, 0.1274, 0.1294, 0.1319],
        [0.1157, 0.1154, 0.1195, 0.1294, 0.1278, 0.1305, 0.1278, 0.1339],
        [0.1155, 0.1152, 0.1174, 0.1291, 0.1287, 0.1297, 0.1297, 0.1347],
        [0.1152, 0.1150, 0.1159, 0.1282, 0.1293, 0.1310, 0.1306, 0.1349]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1291, 0.1266, 0.1235, 0.1245, 0.1242, 0.1247, 0.1231, 0.1243],
        [0.1258, 0.1244, 0.1232, 0.1254, 0.1249, 0.1243, 0.1259, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1288, 0.1261, 0.1257, 0.1231, 0.1246, 0.1240, 0.1249, 0.1228],
        [0.1265, 0.1251, 0.1265, 0.1231, 0.1251, 0.1237, 0.1261, 0.1239],
        [0.1233, 0.1207, 0.1254, 0.1236, 0.1243, 0.1274, 0.1277, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1286, 0.1258, 0.1257, 0.1232, 0.1245, 0.1239, 0.1251, 0.1233],
        [0.1266, 0.1253, 0.1247, 0.1229, 0.1265, 0.1247, 0.1253, 0.1239],
        [0.1227, 0.1213, 0.1267, 0.1248, 0.1264, 0.1252, 0.1255, 0.1274],
        [0.1222, 0.1211, 0.1257, 0.1265, 0.1272, 0.1257, 0.1259, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1285, 0.1255, 0.1226, 0.1246, 0.1262, 0.1248, 0.1266, 0.1214],
        [0.1263, 0.1246, 0.1234, 0.1271, 0.1245, 0.1259, 0.1239, 0.1242],
        [0.1225, 0.1200, 0.1265, 0.1263, 0.1250, 0.1251, 0.1265, 0.1282],
        [0.1224, 0.1202, 0.1258, 0.1269, 0.1250, 0.1275, 0.1253, 0.1269],
        [0.1218, 0.1209, 0.1259, 0.1233, 0.1283, 0.1257, 0.1269, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 10:36:18 AM | Train: [35/50] Step 000/078 Loss1 2.214 Prec1@(1,5) (98.4%, 100.0%)
02/16 10:42:25 AM | Train: [35/50] Step 050/078 Loss1 2.236 Prec1@(1,5) (97.6%, 100.0%)
02/16 10:45:48 AM | Train: [35/50] Step 078/078 Loss1 2.241 Prec1@(1,5) (97.4%, 100.0%)
02/16 10:45:48 AM | Train: [35/50] Final Prec1@1 97.3600%
02/16 10:45:48 AM | Valid: [35/50] Step 000/078 Loss1 1.625 Prec1@(1,5) (60.9%, 95.3%)
02/16 10:46:01 AM | Valid: [35/50] Step 050/078 Loss1 1.317 Prec1@(1,5) (71.3%, 96.7%)
02/16 10:46:07 AM | Valid: [35/50] Step 078/078 Loss1 1.310 Prec1@(1,5) (71.0%, 97.0%)
02/16 10:46:07 AM | Valid: [35/50] Final Prec1@1 71.0000%
02/16 10:46:07 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1231, 0.1210, 0.1245, 0.1256, 0.1267, 0.1269, 0.1279, 0.1244],
        [0.1190, 0.1186, 0.1209, 0.1250, 0.1282, 0.1288, 0.1286, 0.1308]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1226, 0.1199, 0.1235, 0.1292, 0.1259, 0.1268, 0.1260, 0.1262],
        [0.1191, 0.1181, 0.1207, 0.1268, 0.1282, 0.1282, 0.1282, 0.1307],
        [0.1168, 0.1164, 0.1219, 0.1279, 0.1276, 0.1291, 0.1278, 0.1325]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1230, 0.1199, 0.1229, 0.1273, 0.1274, 0.1260, 0.1261, 0.1273],
        [0.1188, 0.1181, 0.1204, 0.1268, 0.1281, 0.1285, 0.1289, 0.1304],
        [0.1172, 0.1163, 0.1222, 0.1258, 0.1270, 0.1287, 0.1296, 0.1332],
        [0.1170, 0.1165, 0.1198, 0.1251, 0.1273, 0.1303, 0.1296, 0.1343]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1212, 0.1187, 0.1216, 0.1282, 0.1273, 0.1263, 0.1263, 0.1303],
        [0.1170, 0.1170, 0.1189, 0.1284, 0.1294, 0.1275, 0.1296, 0.1322],
        [0.1154, 0.1151, 0.1192, 0.1296, 0.1279, 0.1307, 0.1279, 0.1342],
        [0.1152, 0.1149, 0.1172, 0.1291, 0.1288, 0.1299, 0.1299, 0.1350],
        [0.1149, 0.1147, 0.1155, 0.1282, 0.1294, 0.1313, 0.1307, 0.1353]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1292, 0.1267, 0.1235, 0.1244, 0.1242, 0.1246, 0.1230, 0.1243],
        [0.1258, 0.1244, 0.1232, 0.1253, 0.1250, 0.1243, 0.1260, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1289, 0.1262, 0.1257, 0.1230, 0.1246, 0.1240, 0.1250, 0.1226],
        [0.1265, 0.1251, 0.1265, 0.1230, 0.1250, 0.1236, 0.1262, 0.1239],
        [0.1232, 0.1206, 0.1255, 0.1235, 0.1242, 0.1275, 0.1278, 0.1276]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1287, 0.1259, 0.1257, 0.1231, 0.1244, 0.1239, 0.1250, 0.1232],
        [0.1267, 0.1253, 0.1247, 0.1229, 0.1266, 0.1247, 0.1253, 0.1238],
        [0.1225, 0.1212, 0.1268, 0.1249, 0.1264, 0.1252, 0.1255, 0.1274],
        [0.1221, 0.1210, 0.1258, 0.1265, 0.1273, 0.1258, 0.1259, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1286, 0.1255, 0.1225, 0.1245, 0.1262, 0.1248, 0.1267, 0.1212],
        [0.1263, 0.1246, 0.1234, 0.1271, 0.1245, 0.1260, 0.1239, 0.1241],
        [0.1223, 0.1199, 0.1266, 0.1264, 0.1249, 0.1251, 0.1266, 0.1283],
        [0.1222, 0.1200, 0.1259, 0.1270, 0.1250, 0.1275, 0.1253, 0.1270],
        [0.1217, 0.1208, 0.1260, 0.1232, 0.1283, 0.1257, 0.1270, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 10:46:15 AM | Train: [36/50] Step 000/078 Loss1 2.235 Prec1@(1,5) (96.9%, 100.0%)
02/16 10:52:24 AM | Train: [36/50] Step 050/078 Loss1 2.223 Prec1@(1,5) (98.0%, 100.0%)
02/16 10:55:50 AM | Train: [36/50] Step 078/078 Loss1 2.222 Prec1@(1,5) (97.9%, 100.0%)
02/16 10:55:50 AM | Train: [36/50] Final Prec1@1 97.9400%
02/16 10:55:50 AM | Valid: [36/50] Step 000/078 Loss1 0.996 Prec1@(1,5) (70.3%, 96.9%)
02/16 10:56:03 AM | Valid: [36/50] Step 050/078 Loss1 1.268 Prec1@(1,5) (72.3%, 97.0%)
02/16 10:56:10 AM | Valid: [36/50] Step 078/078 Loss1 1.276 Prec1@(1,5) (71.9%, 97.2%)
02/16 10:56:10 AM | Valid: [36/50] Final Prec1@1 71.9000%
02/16 10:56:10 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1230, 0.1209, 0.1246, 0.1257, 0.1266, 0.1269, 0.1280, 0.1242],
        [0.1188, 0.1184, 0.1208, 0.1250, 0.1283, 0.1289, 0.1287, 0.1311]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1225, 0.1198, 0.1236, 0.1292, 0.1258, 0.1268, 0.1260, 0.1262],
        [0.1190, 0.1179, 0.1206, 0.1268, 0.1282, 0.1283, 0.1283, 0.1309],
        [0.1166, 0.1162, 0.1219, 0.1280, 0.1276, 0.1292, 0.1278, 0.1327]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1230, 0.1198, 0.1229, 0.1273, 0.1275, 0.1261, 0.1261, 0.1273],
        [0.1186, 0.1179, 0.1202, 0.1268, 0.1281, 0.1287, 0.1291, 0.1306],
        [0.1170, 0.1161, 0.1222, 0.1257, 0.1270, 0.1288, 0.1297, 0.1335],
        [0.1168, 0.1163, 0.1196, 0.1251, 0.1274, 0.1305, 0.1298, 0.1346]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1211, 0.1186, 0.1215, 0.1283, 0.1274, 0.1264, 0.1263, 0.1304],
        [0.1168, 0.1167, 0.1187, 0.1286, 0.1295, 0.1275, 0.1298, 0.1324],
        [0.1151, 0.1148, 0.1192, 0.1297, 0.1279, 0.1309, 0.1280, 0.1345],
        [0.1149, 0.1146, 0.1169, 0.1293, 0.1288, 0.1301, 0.1300, 0.1354],
        [0.1146, 0.1144, 0.1153, 0.1282, 0.1295, 0.1315, 0.1308, 0.1357]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1294, 0.1269, 0.1234, 0.1244, 0.1242, 0.1246, 0.1229, 0.1243],
        [0.1259, 0.1244, 0.1231, 0.1253, 0.1250, 0.1243, 0.1260, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1290, 0.1263, 0.1257, 0.1229, 0.1246, 0.1240, 0.1251, 0.1225],
        [0.1266, 0.1252, 0.1266, 0.1229, 0.1250, 0.1236, 0.1263, 0.1238],
        [0.1231, 0.1206, 0.1256, 0.1234, 0.1240, 0.1276, 0.1279, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1289, 0.1260, 0.1257, 0.1231, 0.1243, 0.1238, 0.1250, 0.1231],
        [0.1268, 0.1255, 0.1246, 0.1228, 0.1266, 0.1248, 0.1252, 0.1237],
        [0.1224, 0.1212, 0.1269, 0.1250, 0.1265, 0.1251, 0.1255, 0.1276],
        [0.1220, 0.1210, 0.1259, 0.1264, 0.1274, 0.1257, 0.1259, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1287, 0.1256, 0.1224, 0.1245, 0.1262, 0.1248, 0.1266, 0.1211],
        [0.1264, 0.1247, 0.1233, 0.1272, 0.1244, 0.1261, 0.1239, 0.1239],
        [0.1222, 0.1198, 0.1266, 0.1264, 0.1249, 0.1251, 0.1266, 0.1284],
        [0.1221, 0.1200, 0.1260, 0.1271, 0.1249, 0.1276, 0.1253, 0.1271],
        [0.1215, 0.1207, 0.1261, 0.1232, 0.1284, 0.1256, 0.1270, 0.1276]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 10:56:18 AM | Train: [37/50] Step 000/078 Loss1 2.182 Prec1@(1,5) (98.4%, 100.0%)
02/16 11:02:36 AM | Train: [37/50] Step 050/078 Loss1 2.212 Prec1@(1,5) (98.0%, 100.0%)
02/16 11:05:59 AM | Train: [37/50] Step 078/078 Loss1 2.212 Prec1@(1,5) (98.0%, 100.0%)
02/16 11:05:59 AM | Train: [37/50] Final Prec1@1 97.9800%
02/16 11:05:59 AM | Valid: [37/50] Step 000/078 Loss1 1.301 Prec1@(1,5) (70.3%, 96.9%)
02/16 11:06:11 AM | Valid: [37/50] Step 050/078 Loss1 1.361 Prec1@(1,5) (70.8%, 96.9%)
02/16 11:06:17 AM | Valid: [37/50] Step 078/078 Loss1 1.351 Prec1@(1,5) (71.1%, 96.9%)
02/16 11:06:17 AM | Valid: [37/50] Final Prec1@1 71.0800%
02/16 11:06:17 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1229, 0.1208, 0.1247, 0.1257, 0.1266, 0.1269, 0.1282, 0.1241],
        [0.1185, 0.1182, 0.1207, 0.1251, 0.1284, 0.1291, 0.1287, 0.1313]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1225, 0.1197, 0.1236, 0.1294, 0.1258, 0.1269, 0.1261, 0.1262],
        [0.1187, 0.1177, 0.1205, 0.1268, 0.1282, 0.1285, 0.1284, 0.1311],
        [0.1163, 0.1160, 0.1219, 0.1281, 0.1275, 0.1293, 0.1279, 0.1330]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1229, 0.1197, 0.1229, 0.1273, 0.1276, 0.1261, 0.1261, 0.1274],
        [0.1184, 0.1177, 0.1201, 0.1268, 0.1282, 0.1287, 0.1292, 0.1309],
        [0.1168, 0.1159, 0.1222, 0.1257, 0.1270, 0.1289, 0.1298, 0.1337],
        [0.1165, 0.1160, 0.1195, 0.1250, 0.1273, 0.1306, 0.1300, 0.1350]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1210, 0.1184, 0.1215, 0.1284, 0.1274, 0.1264, 0.1263, 0.1306],
        [0.1165, 0.1164, 0.1185, 0.1287, 0.1297, 0.1277, 0.1300, 0.1327],
        [0.1149, 0.1146, 0.1190, 0.1298, 0.1279, 0.1310, 0.1280, 0.1348],
        [0.1146, 0.1143, 0.1167, 0.1292, 0.1289, 0.1302, 0.1302, 0.1358],
        [0.1143, 0.1141, 0.1150, 0.1283, 0.1296, 0.1317, 0.1310, 0.1360]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1296, 0.1271, 0.1232, 0.1243, 0.1242, 0.1246, 0.1228, 0.1242],
        [0.1260, 0.1245, 0.1230, 0.1252, 0.1249, 0.1243, 0.1260, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1291, 0.1263, 0.1258, 0.1228, 0.1245, 0.1239, 0.1251, 0.1223],
        [0.1267, 0.1253, 0.1266, 0.1228, 0.1249, 0.1235, 0.1264, 0.1238],
        [0.1229, 0.1205, 0.1257, 0.1234, 0.1239, 0.1277, 0.1280, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1290, 0.1262, 0.1257, 0.1230, 0.1242, 0.1238, 0.1250, 0.1231],
        [0.1269, 0.1255, 0.1246, 0.1227, 0.1266, 0.1248, 0.1253, 0.1236],
        [0.1222, 0.1211, 0.1270, 0.1250, 0.1265, 0.1251, 0.1254, 0.1277],
        [0.1219, 0.1210, 0.1259, 0.1265, 0.1274, 0.1257, 0.1258, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1289, 0.1257, 0.1224, 0.1244, 0.1262, 0.1248, 0.1267, 0.1209],
        [0.1265, 0.1248, 0.1233, 0.1273, 0.1243, 0.1261, 0.1238, 0.1238],
        [0.1220, 0.1196, 0.1267, 0.1264, 0.1249, 0.1251, 0.1267, 0.1286],
        [0.1220, 0.1199, 0.1261, 0.1270, 0.1248, 0.1277, 0.1252, 0.1272],
        [0.1214, 0.1207, 0.1262, 0.1231, 0.1284, 0.1255, 0.1270, 0.1277]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 11:06:25 AM | Train: [38/50] Step 000/078 Loss1 2.151 Prec1@(1,5) (100.0%, 100.0%)
02/16 11:12:30 AM | Train: [38/50] Step 050/078 Loss1 2.199 Prec1@(1,5) (98.2%, 100.0%)
02/16 11:15:57 AM | Train: [38/50] Step 078/078 Loss1 2.195 Prec1@(1,5) (98.5%, 100.0%)
02/16 11:15:57 AM | Train: [38/50] Final Prec1@1 98.4600%
02/16 11:15:57 AM | Valid: [38/50] Step 000/078 Loss1 1.202 Prec1@(1,5) (67.2%, 95.3%)
02/16 11:16:09 AM | Valid: [38/50] Step 050/078 Loss1 1.301 Prec1@(1,5) (70.3%, 97.2%)
02/16 11:16:16 AM | Valid: [38/50] Step 078/078 Loss1 1.332 Prec1@(1,5) (70.9%, 97.1%)
02/16 11:16:16 AM | Valid: [38/50] Final Prec1@1 70.9000%
02/16 11:16:16 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1228, 0.1207, 0.1247, 0.1257, 0.1267, 0.1270, 0.1283, 0.1241],
        [0.1183, 0.1181, 0.1206, 0.1251, 0.1283, 0.1292, 0.1289, 0.1316]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1224, 0.1196, 0.1236, 0.1295, 0.1258, 0.1269, 0.1261, 0.1261],
        [0.1185, 0.1175, 0.1204, 0.1268, 0.1283, 0.1287, 0.1285, 0.1313],
        [0.1161, 0.1158, 0.1220, 0.1281, 0.1275, 0.1293, 0.1280, 0.1332]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1228, 0.1196, 0.1229, 0.1272, 0.1277, 0.1262, 0.1262, 0.1274],
        [0.1182, 0.1175, 0.1200, 0.1267, 0.1283, 0.1288, 0.1294, 0.1311],
        [0.1166, 0.1156, 0.1222, 0.1257, 0.1270, 0.1289, 0.1300, 0.1340],
        [0.1163, 0.1158, 0.1194, 0.1249, 0.1273, 0.1308, 0.1300, 0.1354]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1208, 0.1183, 0.1215, 0.1286, 0.1273, 0.1264, 0.1263, 0.1308],
        [0.1162, 0.1162, 0.1183, 0.1288, 0.1298, 0.1277, 0.1301, 0.1329],
        [0.1146, 0.1143, 0.1189, 0.1300, 0.1278, 0.1312, 0.1280, 0.1352],
        [0.1143, 0.1141, 0.1165, 0.1293, 0.1290, 0.1303, 0.1304, 0.1361],
        [0.1140, 0.1138, 0.1147, 0.1283, 0.1297, 0.1318, 0.1312, 0.1364]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1298, 0.1272, 0.1231, 0.1242, 0.1242, 0.1246, 0.1227, 0.1242],
        [0.1261, 0.1246, 0.1229, 0.1251, 0.1249, 0.1243, 0.1261, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1293, 0.1265, 0.1258, 0.1228, 0.1245, 0.1239, 0.1250, 0.1222],
        [0.1268, 0.1254, 0.1266, 0.1228, 0.1249, 0.1234, 0.1264, 0.1237],
        [0.1228, 0.1203, 0.1257, 0.1234, 0.1239, 0.1277, 0.1282, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1292, 0.1263, 0.1257, 0.1229, 0.1241, 0.1238, 0.1250, 0.1230],
        [0.1270, 0.1257, 0.1245, 0.1226, 0.1266, 0.1247, 0.1254, 0.1235],
        [0.1220, 0.1211, 0.1271, 0.1250, 0.1266, 0.1251, 0.1254, 0.1278],
        [0.1218, 0.1209, 0.1260, 0.1265, 0.1275, 0.1256, 0.1258, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1290, 0.1259, 0.1223, 0.1244, 0.1263, 0.1248, 0.1267, 0.1208],
        [0.1266, 0.1249, 0.1232, 0.1274, 0.1243, 0.1261, 0.1238, 0.1237],
        [0.1218, 0.1195, 0.1268, 0.1265, 0.1249, 0.1252, 0.1267, 0.1287],
        [0.1219, 0.1198, 0.1262, 0.1270, 0.1247, 0.1278, 0.1251, 0.1274],
        [0.1213, 0.1206, 0.1263, 0.1230, 0.1284, 0.1254, 0.1271, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 11:16:24 AM | Train: [39/50] Step 000/078 Loss1 2.220 Prec1@(1,5) (96.9%, 100.0%)
02/16 11:22:31 AM | Train: [39/50] Step 050/078 Loss1 2.191 Prec1@(1,5) (98.3%, 100.0%)
02/16 11:25:54 AM | Train: [39/50] Step 078/078 Loss1 2.190 Prec1@(1,5) (98.4%, 100.0%)
02/16 11:25:54 AM | Train: [39/50] Final Prec1@1 98.4200%
02/16 11:25:54 AM | Valid: [39/50] Step 000/078 Loss1 2.063 Prec1@(1,5) (62.5%, 95.3%)
02/16 11:26:06 AM | Valid: [39/50] Step 050/078 Loss1 1.316 Prec1@(1,5) (72.2%, 97.7%)
02/16 11:26:12 AM | Valid: [39/50] Step 078/078 Loss1 1.347 Prec1@(1,5) (72.0%, 97.5%)
02/16 11:26:12 AM | Valid: [39/50] Final Prec1@1 71.9800%
02/16 11:26:12 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1228, 0.1207, 0.1248, 0.1257, 0.1267, 0.1271, 0.1284, 0.1239],
        [0.1181, 0.1178, 0.1204, 0.1251, 0.1284, 0.1293, 0.1290, 0.1318]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1224, 0.1195, 0.1237, 0.1296, 0.1257, 0.1270, 0.1261, 0.1260],
        [0.1183, 0.1173, 0.1202, 0.1268, 0.1284, 0.1288, 0.1287, 0.1316],
        [0.1159, 0.1155, 0.1219, 0.1282, 0.1275, 0.1294, 0.1281, 0.1335]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1228, 0.1195, 0.1230, 0.1273, 0.1277, 0.1262, 0.1262, 0.1274],
        [0.1179, 0.1173, 0.1199, 0.1267, 0.1283, 0.1289, 0.1296, 0.1314],
        [0.1163, 0.1154, 0.1221, 0.1257, 0.1270, 0.1290, 0.1301, 0.1343],
        [0.1160, 0.1156, 0.1193, 0.1248, 0.1273, 0.1310, 0.1302, 0.1358]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1208, 0.1182, 0.1215, 0.1286, 0.1273, 0.1265, 0.1263, 0.1309],
        [0.1159, 0.1160, 0.1181, 0.1289, 0.1300, 0.1278, 0.1303, 0.1331],
        [0.1143, 0.1141, 0.1189, 0.1301, 0.1278, 0.1313, 0.1281, 0.1354],
        [0.1141, 0.1138, 0.1163, 0.1294, 0.1290, 0.1305, 0.1306, 0.1364],
        [0.1138, 0.1136, 0.1145, 0.1283, 0.1298, 0.1320, 0.1313, 0.1368]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1299, 0.1273, 0.1230, 0.1242, 0.1241, 0.1246, 0.1226, 0.1242],
        [0.1261, 0.1247, 0.1229, 0.1251, 0.1248, 0.1243, 0.1261, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1294, 0.1265, 0.1259, 0.1226, 0.1245, 0.1239, 0.1250, 0.1221],
        [0.1269, 0.1255, 0.1266, 0.1226, 0.1249, 0.1233, 0.1264, 0.1237],
        [0.1227, 0.1203, 0.1258, 0.1233, 0.1238, 0.1278, 0.1283, 0.1282]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1292, 0.1263, 0.1258, 0.1229, 0.1241, 0.1237, 0.1250, 0.1229],
        [0.1271, 0.1258, 0.1244, 0.1225, 0.1267, 0.1247, 0.1254, 0.1234],
        [0.1219, 0.1210, 0.1272, 0.1250, 0.1266, 0.1251, 0.1254, 0.1279],
        [0.1217, 0.1209, 0.1261, 0.1264, 0.1276, 0.1256, 0.1258, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1291, 0.1259, 0.1222, 0.1244, 0.1263, 0.1248, 0.1267, 0.1207],
        [0.1267, 0.1250, 0.1232, 0.1274, 0.1243, 0.1261, 0.1237, 0.1237],
        [0.1217, 0.1194, 0.1269, 0.1265, 0.1248, 0.1252, 0.1267, 0.1288],
        [0.1218, 0.1197, 0.1263, 0.1270, 0.1247, 0.1278, 0.1252, 0.1274],
        [0.1212, 0.1206, 0.1264, 0.1229, 0.1284, 0.1253, 0.1271, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 11:26:19 AM | Train: [40/50] Step 000/078 Loss1 2.151 Prec1@(1,5) (100.0%, 100.0%)
02/16 11:32:24 AM | Train: [40/50] Step 050/078 Loss1 2.174 Prec1@(1,5) (98.9%, 100.0%)
02/16 11:35:46 AM | Train: [40/50] Step 078/078 Loss1 2.174 Prec1@(1,5) (98.9%, 100.0%)
02/16 11:35:46 AM | Train: [40/50] Final Prec1@1 98.8600%
02/16 11:35:47 AM | Valid: [40/50] Step 000/078 Loss1 1.243 Prec1@(1,5) (75.0%, 95.3%)
02/16 11:35:58 AM | Valid: [40/50] Step 050/078 Loss1 1.419 Prec1@(1,5) (70.6%, 96.4%)
02/16 11:36:05 AM | Valid: [40/50] Step 078/078 Loss1 1.416 Prec1@(1,5) (71.0%, 96.7%)
02/16 11:36:05 AM | Valid: [40/50] Final Prec1@1 70.9600%
02/16 11:36:05 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1227, 0.1206, 0.1248, 0.1257, 0.1267, 0.1271, 0.1285, 0.1238],
        [0.1179, 0.1176, 0.1203, 0.1251, 0.1285, 0.1294, 0.1292, 0.1320]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1223, 0.1194, 0.1238, 0.1297, 0.1257, 0.1270, 0.1261, 0.1260],
        [0.1181, 0.1171, 0.1202, 0.1267, 0.1284, 0.1289, 0.1288, 0.1318],
        [0.1156, 0.1154, 0.1219, 0.1283, 0.1275, 0.1294, 0.1283, 0.1337]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1227, 0.1194, 0.1229, 0.1273, 0.1278, 0.1263, 0.1262, 0.1274],
        [0.1177, 0.1170, 0.1197, 0.1268, 0.1284, 0.1290, 0.1297, 0.1316],
        [0.1161, 0.1152, 0.1221, 0.1257, 0.1270, 0.1292, 0.1302, 0.1345],
        [0.1158, 0.1154, 0.1192, 0.1248, 0.1273, 0.1311, 0.1303, 0.1361]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1206, 0.1180, 0.1214, 0.1287, 0.1274, 0.1266, 0.1262, 0.1311],
        [0.1157, 0.1157, 0.1178, 0.1291, 0.1301, 0.1278, 0.1304, 0.1334],
        [0.1141, 0.1138, 0.1187, 0.1302, 0.1278, 0.1315, 0.1282, 0.1357],
        [0.1138, 0.1135, 0.1160, 0.1295, 0.1291, 0.1307, 0.1307, 0.1368],
        [0.1135, 0.1133, 0.1142, 0.1284, 0.1299, 0.1321, 0.1315, 0.1371]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1300, 0.1274, 0.1230, 0.1241, 0.1241, 0.1246, 0.1226, 0.1242],
        [0.1262, 0.1247, 0.1229, 0.1251, 0.1248, 0.1243, 0.1261, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1294, 0.1265, 0.1259, 0.1226, 0.1245, 0.1239, 0.1250, 0.1221],
        [0.1270, 0.1255, 0.1267, 0.1226, 0.1248, 0.1233, 0.1264, 0.1236],
        [0.1226, 0.1202, 0.1258, 0.1232, 0.1236, 0.1279, 0.1285, 0.1283]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1293, 0.1264, 0.1259, 0.1228, 0.1240, 0.1237, 0.1250, 0.1229],
        [0.1272, 0.1258, 0.1244, 0.1225, 0.1267, 0.1248, 0.1254, 0.1233],
        [0.1218, 0.1210, 0.1272, 0.1250, 0.1266, 0.1251, 0.1254, 0.1279],
        [0.1216, 0.1209, 0.1261, 0.1265, 0.1277, 0.1256, 0.1259, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1292, 0.1260, 0.1221, 0.1244, 0.1263, 0.1248, 0.1267, 0.1206],
        [0.1268, 0.1251, 0.1231, 0.1274, 0.1242, 0.1261, 0.1236, 0.1236],
        [0.1215, 0.1193, 0.1270, 0.1265, 0.1248, 0.1252, 0.1269, 0.1289],
        [0.1217, 0.1197, 0.1264, 0.1270, 0.1247, 0.1279, 0.1252, 0.1275],
        [0.1211, 0.1206, 0.1265, 0.1229, 0.1284, 0.1253, 0.1271, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 11:36:13 AM | Train: [41/50] Step 000/078 Loss1 2.159 Prec1@(1,5) (100.0%, 100.0%)
02/16 11:42:21 AM | Train: [41/50] Step 050/078 Loss1 2.170 Prec1@(1,5) (99.4%, 100.0%)
02/16 11:45:41 AM | Train: [41/50] Step 078/078 Loss1 2.168 Prec1@(1,5) (99.3%, 100.0%)
02/16 11:45:41 AM | Train: [41/50] Final Prec1@1 99.3400%
02/16 11:45:41 AM | Valid: [41/50] Step 000/078 Loss1 1.639 Prec1@(1,5) (68.8%, 95.3%)
02/16 11:45:53 AM | Valid: [41/50] Step 050/078 Loss1 1.275 Prec1@(1,5) (72.1%, 97.3%)
02/16 11:46:00 AM | Valid: [41/50] Step 078/078 Loss1 1.299 Prec1@(1,5) (71.7%, 97.1%)
02/16 11:46:00 AM | Valid: [41/50] Final Prec1@1 71.6800%
02/16 11:46:00 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1227, 0.1206, 0.1249, 0.1258, 0.1267, 0.1271, 0.1286, 0.1237],
        [0.1176, 0.1174, 0.1202, 0.1251, 0.1285, 0.1296, 0.1293, 0.1323]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1222, 0.1194, 0.1239, 0.1297, 0.1256, 0.1271, 0.1261, 0.1260],
        [0.1179, 0.1170, 0.1201, 0.1267, 0.1285, 0.1289, 0.1289, 0.1320],
        [0.1155, 0.1152, 0.1219, 0.1282, 0.1274, 0.1295, 0.1283, 0.1339]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1227, 0.1193, 0.1229, 0.1273, 0.1278, 0.1263, 0.1262, 0.1274],
        [0.1175, 0.1169, 0.1196, 0.1268, 0.1285, 0.1291, 0.1298, 0.1318],
        [0.1159, 0.1150, 0.1221, 0.1257, 0.1270, 0.1292, 0.1303, 0.1348],
        [0.1156, 0.1152, 0.1191, 0.1248, 0.1273, 0.1312, 0.1304, 0.1365]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1205, 0.1179, 0.1214, 0.1289, 0.1273, 0.1266, 0.1262, 0.1312],
        [0.1154, 0.1155, 0.1177, 0.1292, 0.1302, 0.1279, 0.1306, 0.1336],
        [0.1138, 0.1136, 0.1187, 0.1303, 0.1278, 0.1316, 0.1282, 0.1360],
        [0.1135, 0.1132, 0.1158, 0.1296, 0.1291, 0.1308, 0.1308, 0.1371],
        [0.1132, 0.1130, 0.1139, 0.1284, 0.1300, 0.1323, 0.1317, 0.1375]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1302, 0.1276, 0.1229, 0.1241, 0.1241, 0.1245, 0.1225, 0.1242],
        [0.1262, 0.1247, 0.1228, 0.1250, 0.1248, 0.1243, 0.1262, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1296, 0.1267, 0.1259, 0.1225, 0.1244, 0.1239, 0.1250, 0.1219],
        [0.1271, 0.1256, 0.1267, 0.1226, 0.1248, 0.1232, 0.1265, 0.1236],
        [0.1225, 0.1201, 0.1259, 0.1231, 0.1235, 0.1281, 0.1286, 0.1283]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1294, 0.1265, 0.1259, 0.1227, 0.1240, 0.1237, 0.1249, 0.1228],
        [0.1272, 0.1259, 0.1243, 0.1224, 0.1267, 0.1247, 0.1255, 0.1233],
        [0.1216, 0.1209, 0.1273, 0.1250, 0.1266, 0.1251, 0.1255, 0.1280],
        [0.1214, 0.1208, 0.1262, 0.1265, 0.1278, 0.1256, 0.1259, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1293, 0.1261, 0.1220, 0.1243, 0.1263, 0.1248, 0.1267, 0.1204],
        [0.1269, 0.1252, 0.1231, 0.1274, 0.1241, 0.1261, 0.1236, 0.1236],
        [0.1214, 0.1193, 0.1271, 0.1265, 0.1248, 0.1252, 0.1269, 0.1289],
        [0.1216, 0.1196, 0.1265, 0.1270, 0.1246, 0.1279, 0.1252, 0.1276],
        [0.1211, 0.1206, 0.1267, 0.1228, 0.1284, 0.1253, 0.1271, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 11:46:08 AM | Train: [42/50] Step 000/078 Loss1 2.145 Prec1@(1,5) (100.0%, 100.0%)
02/16 11:52:13 AM | Train: [42/50] Step 050/078 Loss1 2.160 Prec1@(1,5) (99.4%, 100.0%)
02/16 11:55:37 AM | Train: [42/50] Step 078/078 Loss1 2.162 Prec1@(1,5) (99.3%, 100.0%)
02/16 11:55:37 AM | Train: [42/50] Final Prec1@1 99.3000%
02/16 11:55:37 AM | Valid: [42/50] Step 000/078 Loss1 0.910 Prec1@(1,5) (79.7%, 100.0%)
02/16 11:55:49 AM | Valid: [42/50] Step 050/078 Loss1 1.286 Prec1@(1,5) (72.2%, 97.4%)
02/16 11:55:55 AM | Valid: [42/50] Step 078/078 Loss1 1.319 Prec1@(1,5) (71.4%, 97.3%)
02/16 11:55:55 AM | Valid: [42/50] Final Prec1@1 71.3800%
02/16 11:55:55 AM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1226, 0.1206, 0.1250, 0.1257, 0.1266, 0.1272, 0.1286, 0.1236],
        [0.1174, 0.1172, 0.1201, 0.1251, 0.1286, 0.1297, 0.1294, 0.1325]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1222, 0.1193, 0.1239, 0.1299, 0.1255, 0.1271, 0.1262, 0.1259],
        [0.1177, 0.1168, 0.1200, 0.1267, 0.1285, 0.1291, 0.1290, 0.1322],
        [0.1152, 0.1150, 0.1220, 0.1282, 0.1273, 0.1297, 0.1284, 0.1342]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1226, 0.1192, 0.1230, 0.1273, 0.1279, 0.1263, 0.1262, 0.1274],
        [0.1173, 0.1167, 0.1194, 0.1268, 0.1286, 0.1292, 0.1300, 0.1320],
        [0.1157, 0.1148, 0.1220, 0.1257, 0.1270, 0.1292, 0.1304, 0.1351],
        [0.1154, 0.1150, 0.1190, 0.1247, 0.1272, 0.1314, 0.1306, 0.1368]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1204, 0.1177, 0.1214, 0.1289, 0.1274, 0.1267, 0.1261, 0.1313],
        [0.1152, 0.1152, 0.1175, 0.1292, 0.1303, 0.1280, 0.1307, 0.1339],
        [0.1136, 0.1133, 0.1185, 0.1304, 0.1278, 0.1317, 0.1283, 0.1363],
        [0.1133, 0.1130, 0.1156, 0.1296, 0.1292, 0.1309, 0.1310, 0.1374],
        [0.1130, 0.1128, 0.1137, 0.1284, 0.1301, 0.1324, 0.1318, 0.1378]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1304, 0.1277, 0.1228, 0.1241, 0.1240, 0.1245, 0.1223, 0.1242],
        [0.1263, 0.1248, 0.1228, 0.1250, 0.1247, 0.1243, 0.1262, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1297, 0.1268, 0.1259, 0.1224, 0.1244, 0.1240, 0.1250, 0.1218],
        [0.1272, 0.1257, 0.1267, 0.1225, 0.1248, 0.1231, 0.1265, 0.1235],
        [0.1224, 0.1201, 0.1259, 0.1230, 0.1234, 0.1281, 0.1286, 0.1285]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1296, 0.1267, 0.1260, 0.1226, 0.1239, 0.1236, 0.1249, 0.1227],
        [0.1273, 0.1259, 0.1243, 0.1224, 0.1267, 0.1247, 0.1255, 0.1232],
        [0.1215, 0.1208, 0.1273, 0.1251, 0.1267, 0.1251, 0.1255, 0.1281],
        [0.1213, 0.1207, 0.1262, 0.1265, 0.1278, 0.1256, 0.1259, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1294, 0.1262, 0.1219, 0.1242, 0.1264, 0.1248, 0.1268, 0.1203],
        [0.1270, 0.1253, 0.1231, 0.1275, 0.1241, 0.1261, 0.1235, 0.1235],
        [0.1212, 0.1192, 0.1271, 0.1266, 0.1248, 0.1252, 0.1269, 0.1290],
        [0.1215, 0.1195, 0.1265, 0.1271, 0.1246, 0.1279, 0.1252, 0.1277],
        [0.1209, 0.1205, 0.1267, 0.1228, 0.1284, 0.1253, 0.1272, 0.1282]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 11:56:03 AM | Train: [43/50] Step 000/078 Loss1 2.143 Prec1@(1,5) (100.0%, 100.0%)
02/16 12:02:06 PM | Train: [43/50] Step 050/078 Loss1 2.161 Prec1@(1,5) (99.3%, 100.0%)
02/16 12:05:30 PM | Train: [43/50] Step 078/078 Loss1 2.159 Prec1@(1,5) (99.3%, 100.0%)
02/16 12:05:30 PM | Train: [43/50] Final Prec1@1 99.3400%
02/16 12:05:30 PM | Valid: [43/50] Step 000/078 Loss1 0.797 Prec1@(1,5) (81.2%, 98.4%)
02/16 12:05:42 PM | Valid: [43/50] Step 050/078 Loss1 1.406 Prec1@(1,5) (71.6%, 97.5%)
02/16 12:05:49 PM | Valid: [43/50] Step 078/078 Loss1 1.367 Prec1@(1,5) (72.0%, 97.4%)
02/16 12:05:49 PM | Valid: [43/50] Final Prec1@1 72.0400%
02/16 12:05:49 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1226, 0.1206, 0.1251, 0.1257, 0.1266, 0.1272, 0.1287, 0.1235],
        [0.1172, 0.1170, 0.1199, 0.1251, 0.1286, 0.1299, 0.1295, 0.1328]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1222, 0.1192, 0.1240, 0.1299, 0.1254, 0.1271, 0.1263, 0.1259],
        [0.1175, 0.1166, 0.1199, 0.1267, 0.1286, 0.1291, 0.1291, 0.1324],
        [0.1150, 0.1148, 0.1220, 0.1282, 0.1273, 0.1297, 0.1285, 0.1344]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1226, 0.1191, 0.1230, 0.1273, 0.1280, 0.1264, 0.1263, 0.1274],
        [0.1171, 0.1164, 0.1193, 0.1269, 0.1287, 0.1293, 0.1301, 0.1322],
        [0.1155, 0.1146, 0.1220, 0.1257, 0.1270, 0.1293, 0.1306, 0.1354],
        [0.1151, 0.1148, 0.1189, 0.1247, 0.1272, 0.1316, 0.1307, 0.1371]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1204, 0.1176, 0.1214, 0.1290, 0.1274, 0.1267, 0.1261, 0.1315],
        [0.1149, 0.1150, 0.1173, 0.1294, 0.1305, 0.1280, 0.1308, 0.1341],
        [0.1133, 0.1131, 0.1184, 0.1306, 0.1278, 0.1318, 0.1284, 0.1366],
        [0.1130, 0.1128, 0.1154, 0.1297, 0.1292, 0.1311, 0.1312, 0.1377],
        [0.1127, 0.1125, 0.1134, 0.1285, 0.1302, 0.1326, 0.1319, 0.1381]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1305, 0.1279, 0.1227, 0.1240, 0.1240, 0.1245, 0.1222, 0.1242],
        [0.1264, 0.1248, 0.1227, 0.1250, 0.1247, 0.1243, 0.1262, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1298, 0.1268, 0.1260, 0.1224, 0.1244, 0.1240, 0.1250, 0.1217],
        [0.1273, 0.1258, 0.1267, 0.1225, 0.1248, 0.1230, 0.1265, 0.1235],
        [0.1222, 0.1200, 0.1260, 0.1230, 0.1233, 0.1282, 0.1287, 0.1286]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1297, 0.1268, 0.1260, 0.1225, 0.1239, 0.1236, 0.1249, 0.1227],
        [0.1274, 0.1260, 0.1243, 0.1223, 0.1268, 0.1247, 0.1254, 0.1232],
        [0.1214, 0.1208, 0.1274, 0.1250, 0.1267, 0.1251, 0.1255, 0.1282],
        [0.1212, 0.1207, 0.1263, 0.1264, 0.1278, 0.1256, 0.1259, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1296, 0.1263, 0.1218, 0.1241, 0.1264, 0.1248, 0.1267, 0.1202],
        [0.1271, 0.1253, 0.1231, 0.1275, 0.1240, 0.1261, 0.1235, 0.1234],
        [0.1211, 0.1191, 0.1271, 0.1266, 0.1248, 0.1252, 0.1270, 0.1291],
        [0.1214, 0.1194, 0.1266, 0.1271, 0.1246, 0.1280, 0.1252, 0.1277],
        [0.1208, 0.1204, 0.1268, 0.1227, 0.1284, 0.1253, 0.1272, 0.1283]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 12:05:57 PM | Train: [44/50] Step 000/078 Loss1 2.163 Prec1@(1,5) (100.0%, 100.0%)
02/16 12:12:04 PM | Train: [44/50] Step 050/078 Loss1 2.157 Prec1@(1,5) (99.3%, 100.0%)
02/16 12:15:25 PM | Train: [44/50] Step 078/078 Loss1 2.155 Prec1@(1,5) (99.4%, 100.0%)
02/16 12:15:25 PM | Train: [44/50] Final Prec1@1 99.4000%
02/16 12:15:26 PM | Valid: [44/50] Step 000/078 Loss1 1.441 Prec1@(1,5) (70.3%, 98.4%)
02/16 12:15:38 PM | Valid: [44/50] Step 050/078 Loss1 1.406 Prec1@(1,5) (70.3%, 96.5%)
02/16 12:15:45 PM | Valid: [44/50] Step 078/078 Loss1 1.410 Prec1@(1,5) (70.3%, 96.6%)
02/16 12:15:45 PM | Valid: [44/50] Final Prec1@1 70.3000%
02/16 12:15:45 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1225, 0.1205, 0.1252, 0.1257, 0.1267, 0.1273, 0.1288, 0.1234],
        [0.1170, 0.1168, 0.1197, 0.1251, 0.1287, 0.1300, 0.1297, 0.1330]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1221, 0.1191, 0.1240, 0.1301, 0.1254, 0.1272, 0.1264, 0.1258],
        [0.1173, 0.1164, 0.1197, 0.1267, 0.1287, 0.1292, 0.1293, 0.1326],
        [0.1148, 0.1146, 0.1220, 0.1282, 0.1273, 0.1298, 0.1286, 0.1347]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1225, 0.1190, 0.1230, 0.1273, 0.1282, 0.1264, 0.1263, 0.1274],
        [0.1169, 0.1162, 0.1191, 0.1269, 0.1288, 0.1294, 0.1303, 0.1324],
        [0.1153, 0.1145, 0.1221, 0.1256, 0.1269, 0.1293, 0.1306, 0.1357],
        [0.1149, 0.1146, 0.1188, 0.1246, 0.1272, 0.1317, 0.1307, 0.1375]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1202, 0.1175, 0.1213, 0.1291, 0.1274, 0.1267, 0.1261, 0.1316],
        [0.1147, 0.1148, 0.1171, 0.1295, 0.1306, 0.1280, 0.1310, 0.1343],
        [0.1130, 0.1128, 0.1184, 0.1308, 0.1278, 0.1319, 0.1284, 0.1369],
        [0.1128, 0.1125, 0.1152, 0.1298, 0.1292, 0.1312, 0.1313, 0.1380],
        [0.1125, 0.1123, 0.1132, 0.1285, 0.1303, 0.1327, 0.1320, 0.1385]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1306, 0.1279, 0.1227, 0.1240, 0.1240, 0.1245, 0.1221, 0.1242],
        [0.1265, 0.1249, 0.1227, 0.1249, 0.1247, 0.1243, 0.1261, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1299, 0.1269, 0.1259, 0.1223, 0.1244, 0.1239, 0.1250, 0.1216],
        [0.1273, 0.1258, 0.1267, 0.1224, 0.1248, 0.1230, 0.1266, 0.1234],
        [0.1221, 0.1199, 0.1261, 0.1229, 0.1233, 0.1282, 0.1288, 0.1288]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1297, 0.1268, 0.1261, 0.1225, 0.1238, 0.1236, 0.1249, 0.1226],
        [0.1274, 0.1262, 0.1243, 0.1221, 0.1268, 0.1247, 0.1255, 0.1230],
        [0.1212, 0.1207, 0.1274, 0.1251, 0.1267, 0.1251, 0.1255, 0.1283],
        [0.1211, 0.1207, 0.1264, 0.1264, 0.1279, 0.1255, 0.1259, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1297, 0.1264, 0.1218, 0.1241, 0.1264, 0.1247, 0.1267, 0.1201],
        [0.1272, 0.1255, 0.1230, 0.1275, 0.1240, 0.1261, 0.1234, 0.1233],
        [0.1209, 0.1190, 0.1273, 0.1266, 0.1248, 0.1252, 0.1270, 0.1292],
        [0.1213, 0.1194, 0.1267, 0.1271, 0.1245, 0.1280, 0.1251, 0.1278],
        [0.1207, 0.1204, 0.1269, 0.1226, 0.1284, 0.1253, 0.1272, 0.1284]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 12:15:54 PM | Train: [45/50] Step 000/078 Loss1 2.135 Prec1@(1,5) (100.0%, 100.0%)
02/16 12:22:00 PM | Train: [45/50] Step 050/078 Loss1 2.154 Prec1@(1,5) (99.4%, 100.0%)
02/16 12:25:25 PM | Train: [45/50] Step 078/078 Loss1 2.151 Prec1@(1,5) (99.4%, 100.0%)
02/16 12:25:25 PM | Train: [45/50] Final Prec1@1 99.4400%
02/16 12:25:26 PM | Valid: [45/50] Step 000/078 Loss1 1.345 Prec1@(1,5) (75.0%, 95.3%)
02/16 12:25:37 PM | Valid: [45/50] Step 050/078 Loss1 1.400 Prec1@(1,5) (71.2%, 97.3%)
02/16 12:25:43 PM | Valid: [45/50] Step 078/078 Loss1 1.353 Prec1@(1,5) (71.7%, 97.4%)
02/16 12:25:43 PM | Valid: [45/50] Final Prec1@1 71.7200%
02/16 12:25:43 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1225, 0.1205, 0.1253, 0.1257, 0.1267, 0.1273, 0.1288, 0.1232],
        [0.1168, 0.1166, 0.1196, 0.1251, 0.1287, 0.1301, 0.1298, 0.1333]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1221, 0.1191, 0.1241, 0.1302, 0.1253, 0.1272, 0.1264, 0.1257],
        [0.1171, 0.1162, 0.1196, 0.1267, 0.1288, 0.1293, 0.1294, 0.1328],
        [0.1146, 0.1144, 0.1220, 0.1282, 0.1272, 0.1298, 0.1288, 0.1349]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1224, 0.1189, 0.1230, 0.1273, 0.1282, 0.1264, 0.1263, 0.1274],
        [0.1167, 0.1161, 0.1190, 0.1269, 0.1288, 0.1295, 0.1304, 0.1326],
        [0.1151, 0.1142, 0.1220, 0.1256, 0.1269, 0.1294, 0.1308, 0.1359],
        [0.1147, 0.1144, 0.1187, 0.1245, 0.1271, 0.1319, 0.1308, 0.1378]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1201, 0.1174, 0.1213, 0.1292, 0.1274, 0.1268, 0.1261, 0.1318],
        [0.1144, 0.1145, 0.1169, 0.1296, 0.1308, 0.1281, 0.1311, 0.1346],
        [0.1128, 0.1126, 0.1183, 0.1309, 0.1278, 0.1320, 0.1285, 0.1372],
        [0.1125, 0.1123, 0.1150, 0.1299, 0.1293, 0.1313, 0.1315, 0.1383],
        [0.1122, 0.1121, 0.1129, 0.1285, 0.1304, 0.1329, 0.1322, 0.1388]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1308, 0.1280, 0.1227, 0.1240, 0.1239, 0.1245, 0.1220, 0.1241],
        [0.1265, 0.1249, 0.1227, 0.1249, 0.1247, 0.1242, 0.1262, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1300, 0.1270, 0.1260, 0.1222, 0.1244, 0.1239, 0.1250, 0.1215],
        [0.1274, 0.1258, 0.1268, 0.1223, 0.1247, 0.1229, 0.1266, 0.1234],
        [0.1220, 0.1198, 0.1261, 0.1229, 0.1232, 0.1284, 0.1288, 0.1288]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1298, 0.1269, 0.1261, 0.1224, 0.1238, 0.1235, 0.1249, 0.1226],
        [0.1275, 0.1262, 0.1242, 0.1220, 0.1268, 0.1247, 0.1255, 0.1230],
        [0.1211, 0.1206, 0.1275, 0.1251, 0.1267, 0.1251, 0.1255, 0.1284],
        [0.1211, 0.1206, 0.1264, 0.1264, 0.1280, 0.1255, 0.1259, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1297, 0.1265, 0.1217, 0.1241, 0.1264, 0.1248, 0.1268, 0.1200],
        [0.1272, 0.1255, 0.1230, 0.1276, 0.1239, 0.1261, 0.1233, 0.1233],
        [0.1208, 0.1189, 0.1273, 0.1268, 0.1248, 0.1252, 0.1270, 0.1293],
        [0.1213, 0.1193, 0.1267, 0.1272, 0.1244, 0.1281, 0.1251, 0.1278],
        [0.1206, 0.1203, 0.1270, 0.1226, 0.1285, 0.1253, 0.1273, 0.1285]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 12:25:50 PM | Train: [46/50] Step 000/078 Loss1 2.132 Prec1@(1,5) (100.0%, 100.0%)
02/16 12:31:54 PM | Train: [46/50] Step 050/078 Loss1 2.150 Prec1@(1,5) (99.4%, 100.0%)
02/16 12:35:15 PM | Train: [46/50] Step 078/078 Loss1 2.149 Prec1@(1,5) (99.3%, 100.0%)
02/16 12:35:15 PM | Train: [46/50] Final Prec1@1 99.3200%
02/16 12:35:15 PM | Valid: [46/50] Step 000/078 Loss1 1.167 Prec1@(1,5) (71.9%, 98.4%)
02/16 12:35:28 PM | Valid: [46/50] Step 050/078 Loss1 1.443 Prec1@(1,5) (70.3%, 97.3%)
02/16 12:35:34 PM | Valid: [46/50] Step 078/078 Loss1 1.444 Prec1@(1,5) (70.6%, 97.4%)
02/16 12:35:34 PM | Valid: [46/50] Final Prec1@1 70.6000%
02/16 12:35:34 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1225, 0.1205, 0.1254, 0.1256, 0.1266, 0.1274, 0.1289, 0.1231],
        [0.1166, 0.1165, 0.1196, 0.1250, 0.1287, 0.1302, 0.1299, 0.1335]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1221, 0.1191, 0.1242, 0.1302, 0.1253, 0.1272, 0.1264, 0.1256],
        [0.1169, 0.1161, 0.1195, 0.1267, 0.1288, 0.1294, 0.1295, 0.1330],
        [0.1144, 0.1142, 0.1220, 0.1283, 0.1272, 0.1298, 0.1289, 0.1352]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1223, 0.1188, 0.1230, 0.1273, 0.1283, 0.1264, 0.1263, 0.1274],
        [0.1165, 0.1159, 0.1188, 0.1270, 0.1289, 0.1296, 0.1306, 0.1328],
        [0.1148, 0.1140, 0.1219, 0.1256, 0.1270, 0.1295, 0.1309, 0.1362],
        [0.1145, 0.1142, 0.1186, 0.1245, 0.1271, 0.1321, 0.1309, 0.1381]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1200, 0.1172, 0.1213, 0.1292, 0.1274, 0.1268, 0.1261, 0.1319],
        [0.1142, 0.1143, 0.1168, 0.1297, 0.1308, 0.1282, 0.1312, 0.1348],
        [0.1125, 0.1123, 0.1181, 0.1310, 0.1279, 0.1321, 0.1285, 0.1375],
        [0.1123, 0.1120, 0.1148, 0.1300, 0.1293, 0.1315, 0.1316, 0.1386],
        [0.1120, 0.1118, 0.1127, 0.1285, 0.1305, 0.1331, 0.1323, 0.1392]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1309, 0.1281, 0.1226, 0.1239, 0.1239, 0.1246, 0.1220, 0.1241],
        [0.1265, 0.1248, 0.1227, 0.1249, 0.1247, 0.1243, 0.1262, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1301, 0.1271, 0.1260, 0.1222, 0.1243, 0.1238, 0.1250, 0.1214],
        [0.1274, 0.1259, 0.1269, 0.1223, 0.1247, 0.1228, 0.1266, 0.1234],
        [0.1218, 0.1197, 0.1261, 0.1228, 0.1232, 0.1285, 0.1290, 0.1289]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1299, 0.1270, 0.1262, 0.1223, 0.1237, 0.1235, 0.1248, 0.1225],
        [0.1275, 0.1262, 0.1242, 0.1220, 0.1269, 0.1247, 0.1255, 0.1230],
        [0.1209, 0.1206, 0.1276, 0.1251, 0.1267, 0.1251, 0.1255, 0.1285],
        [0.1210, 0.1206, 0.1265, 0.1264, 0.1281, 0.1254, 0.1259, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1298, 0.1265, 0.1217, 0.1240, 0.1264, 0.1248, 0.1268, 0.1199],
        [0.1273, 0.1256, 0.1229, 0.1276, 0.1238, 0.1262, 0.1233, 0.1233],
        [0.1206, 0.1188, 0.1274, 0.1268, 0.1247, 0.1252, 0.1271, 0.1294],
        [0.1212, 0.1193, 0.1268, 0.1272, 0.1244, 0.1282, 0.1251, 0.1278],
        [0.1205, 0.1203, 0.1271, 0.1225, 0.1285, 0.1253, 0.1273, 0.1286]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 12:35:42 PM | Train: [47/50] Step 000/078 Loss1 2.135 Prec1@(1,5) (100.0%, 100.0%)
02/16 12:41:38 PM | Train: [47/50] Step 050/078 Loss1 2.147 Prec1@(1,5) (99.5%, 100.0%)
02/16 12:44:54 PM | Train: [47/50] Step 078/078 Loss1 2.147 Prec1@(1,5) (99.4%, 100.0%)
02/16 12:44:54 PM | Train: [47/50] Final Prec1@1 99.4000%
02/16 12:44:55 PM | Valid: [47/50] Step 000/078 Loss1 1.335 Prec1@(1,5) (73.4%, 98.4%)
02/16 12:45:06 PM | Valid: [47/50] Step 050/078 Loss1 1.386 Prec1@(1,5) (71.4%, 97.1%)
02/16 12:45:13 PM | Valid: [47/50] Step 078/078 Loss1 1.355 Prec1@(1,5) (71.6%, 97.1%)
02/16 12:45:13 PM | Valid: [47/50] Final Prec1@1 71.6200%
02/16 12:45:13 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1224, 0.1204, 0.1254, 0.1257, 0.1267, 0.1274, 0.1290, 0.1230],
        [0.1164, 0.1163, 0.1195, 0.1250, 0.1287, 0.1303, 0.1300, 0.1337]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1220, 0.1190, 0.1243, 0.1302, 0.1252, 0.1272, 0.1264, 0.1256],
        [0.1167, 0.1159, 0.1194, 0.1267, 0.1289, 0.1295, 0.1296, 0.1332],
        [0.1142, 0.1141, 0.1220, 0.1283, 0.1271, 0.1299, 0.1290, 0.1354]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1223, 0.1187, 0.1230, 0.1272, 0.1284, 0.1265, 0.1264, 0.1275],
        [0.1163, 0.1157, 0.1188, 0.1270, 0.1289, 0.1296, 0.1307, 0.1329],
        [0.1146, 0.1138, 0.1219, 0.1257, 0.1270, 0.1296, 0.1310, 0.1364],
        [0.1143, 0.1140, 0.1186, 0.1244, 0.1271, 0.1322, 0.1310, 0.1385]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1199, 0.1171, 0.1213, 0.1293, 0.1275, 0.1268, 0.1261, 0.1320],
        [0.1140, 0.1141, 0.1166, 0.1298, 0.1309, 0.1282, 0.1314, 0.1350],
        [0.1123, 0.1121, 0.1181, 0.1311, 0.1279, 0.1322, 0.1285, 0.1378],
        [0.1120, 0.1118, 0.1146, 0.1300, 0.1293, 0.1315, 0.1318, 0.1389],
        [0.1118, 0.1116, 0.1125, 0.1286, 0.1305, 0.1332, 0.1324, 0.1395]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1310, 0.1282, 0.1225, 0.1239, 0.1239, 0.1245, 0.1218, 0.1241],
        [0.1265, 0.1248, 0.1227, 0.1249, 0.1247, 0.1243, 0.1262, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1302, 0.1272, 0.1260, 0.1222, 0.1243, 0.1238, 0.1250, 0.1213],
        [0.1274, 0.1260, 0.1269, 0.1223, 0.1247, 0.1227, 0.1267, 0.1234],
        [0.1217, 0.1196, 0.1261, 0.1228, 0.1231, 0.1286, 0.1291, 0.1290]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1300, 0.1271, 0.1262, 0.1222, 0.1236, 0.1235, 0.1248, 0.1225],
        [0.1275, 0.1263, 0.1241, 0.1220, 0.1268, 0.1247, 0.1256, 0.1229],
        [0.1208, 0.1205, 0.1277, 0.1252, 0.1268, 0.1250, 0.1254, 0.1286],
        [0.1209, 0.1206, 0.1266, 0.1263, 0.1281, 0.1254, 0.1259, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1300, 0.1266, 0.1217, 0.1239, 0.1264, 0.1248, 0.1269, 0.1199],
        [0.1274, 0.1257, 0.1229, 0.1276, 0.1238, 0.1263, 0.1232, 0.1232],
        [0.1205, 0.1187, 0.1274, 0.1268, 0.1247, 0.1252, 0.1271, 0.1294],
        [0.1211, 0.1192, 0.1269, 0.1273, 0.1243, 0.1282, 0.1251, 0.1279],
        [0.1204, 0.1203, 0.1272, 0.1225, 0.1285, 0.1252, 0.1273, 0.1286]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 12:45:21 PM | Train: [48/50] Step 000/078 Loss1 2.135 Prec1@(1,5) (100.0%, 100.0%)
02/16 12:51:17 PM | Train: [48/50] Step 050/078 Loss1 2.146 Prec1@(1,5) (99.5%, 100.0%)
02/16 12:54:35 PM | Train: [48/50] Step 078/078 Loss1 2.150 Prec1@(1,5) (99.3%, 100.0%)
02/16 12:54:35 PM | Train: [48/50] Final Prec1@1 99.2600%
02/16 12:54:35 PM | Valid: [48/50] Step 000/078 Loss1 1.144 Prec1@(1,5) (75.0%, 98.4%)
02/16 12:54:47 PM | Valid: [48/50] Step 050/078 Loss1 1.396 Prec1@(1,5) (72.9%, 97.2%)
02/16 12:54:54 PM | Valid: [48/50] Step 078/078 Loss1 1.404 Prec1@(1,5) (72.6%, 97.4%)
02/16 12:54:54 PM | Valid: [48/50] Final Prec1@1 72.5800%
02/16 12:54:54 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1224, 0.1204, 0.1255, 0.1256, 0.1267, 0.1274, 0.1290, 0.1228],
        [0.1162, 0.1162, 0.1194, 0.1250, 0.1288, 0.1304, 0.1301, 0.1339]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1220, 0.1190, 0.1244, 0.1303, 0.1251, 0.1273, 0.1264, 0.1255],
        [0.1165, 0.1158, 0.1193, 0.1268, 0.1289, 0.1296, 0.1297, 0.1334],
        [0.1140, 0.1139, 0.1221, 0.1284, 0.1271, 0.1299, 0.1291, 0.1356]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1222, 0.1186, 0.1231, 0.1272, 0.1284, 0.1265, 0.1264, 0.1275],
        [0.1161, 0.1155, 0.1186, 0.1270, 0.1290, 0.1297, 0.1309, 0.1331],
        [0.1144, 0.1136, 0.1219, 0.1257, 0.1270, 0.1296, 0.1311, 0.1367],
        [0.1140, 0.1138, 0.1185, 0.1244, 0.1271, 0.1323, 0.1311, 0.1388]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1198, 0.1170, 0.1213, 0.1293, 0.1275, 0.1269, 0.1261, 0.1322],
        [0.1137, 0.1139, 0.1164, 0.1300, 0.1310, 0.1283, 0.1315, 0.1353],
        [0.1121, 0.1119, 0.1180, 0.1313, 0.1279, 0.1323, 0.1285, 0.1380],
        [0.1118, 0.1116, 0.1144, 0.1301, 0.1293, 0.1316, 0.1319, 0.1392],
        [0.1115, 0.1114, 0.1123, 0.1286, 0.1305, 0.1334, 0.1325, 0.1398]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1311, 0.1283, 0.1224, 0.1239, 0.1239, 0.1245, 0.1217, 0.1241],
        [0.1265, 0.1248, 0.1227, 0.1249, 0.1246, 0.1243, 0.1262, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1303, 0.1273, 0.1260, 0.1222, 0.1243, 0.1238, 0.1250, 0.1212],
        [0.1275, 0.1260, 0.1269, 0.1222, 0.1247, 0.1226, 0.1267, 0.1234],
        [0.1216, 0.1195, 0.1262, 0.1227, 0.1230, 0.1287, 0.1292, 0.1291]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1302, 0.1272, 0.1262, 0.1221, 0.1236, 0.1234, 0.1248, 0.1224],
        [0.1276, 0.1263, 0.1241, 0.1219, 0.1268, 0.1248, 0.1256, 0.1229],
        [0.1206, 0.1204, 0.1278, 0.1252, 0.1268, 0.1250, 0.1254, 0.1287],
        [0.1207, 0.1205, 0.1267, 0.1263, 0.1282, 0.1254, 0.1259, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1301, 0.1267, 0.1216, 0.1238, 0.1264, 0.1248, 0.1269, 0.1198],
        [0.1274, 0.1257, 0.1229, 0.1277, 0.1237, 0.1263, 0.1232, 0.1232],
        [0.1204, 0.1186, 0.1275, 0.1268, 0.1248, 0.1252, 0.1271, 0.1296],
        [0.1210, 0.1192, 0.1270, 0.1274, 0.1243, 0.1283, 0.1250, 0.1279],
        [0.1203, 0.1202, 0.1272, 0.1224, 0.1285, 0.1252, 0.1274, 0.1287]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 12:55:02 PM | Train: [49/50] Step 000/078 Loss1 2.145 Prec1@(1,5) (100.0%, 100.0%)
02/16 01:00:57 PM | Train: [49/50] Step 050/078 Loss1 2.144 Prec1@(1,5) (99.5%, 100.0%)
02/16 01:04:18 PM | Train: [49/50] Step 078/078 Loss1 2.143 Prec1@(1,5) (99.5%, 100.0%)
02/16 01:04:18 PM | Train: [49/50] Final Prec1@1 99.5400%
02/16 01:04:18 PM | Valid: [49/50] Step 000/078 Loss1 1.490 Prec1@(1,5) (71.9%, 98.4%)
02/16 01:04:29 PM | Valid: [49/50] Step 050/078 Loss1 1.425 Prec1@(1,5) (71.7%, 97.1%)
02/16 01:04:36 PM | Valid: [49/50] Step 078/078 Loss1 1.393 Prec1@(1,5) (72.1%, 97.3%)
02/16 01:04:36 PM | Valid: [49/50] Final Prec1@1 72.0800%
02/16 01:04:36 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1223, 0.1204, 0.1255, 0.1257, 0.1267, 0.1275, 0.1292, 0.1227],
        [0.1160, 0.1160, 0.1193, 0.1250, 0.1288, 0.1306, 0.1302, 0.1342]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1220, 0.1189, 0.1244, 0.1303, 0.1251, 0.1274, 0.1264, 0.1255],
        [0.1164, 0.1156, 0.1193, 0.1268, 0.1290, 0.1297, 0.1298, 0.1335],
        [0.1138, 0.1138, 0.1221, 0.1284, 0.1270, 0.1300, 0.1292, 0.1358]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1222, 0.1185, 0.1230, 0.1272, 0.1285, 0.1266, 0.1264, 0.1276],
        [0.1160, 0.1154, 0.1185, 0.1270, 0.1290, 0.1298, 0.1310, 0.1333],
        [0.1143, 0.1135, 0.1219, 0.1257, 0.1270, 0.1296, 0.1312, 0.1369],
        [0.1138, 0.1136, 0.1184, 0.1244, 0.1270, 0.1324, 0.1313, 0.1391]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1197, 0.1169, 0.1212, 0.1293, 0.1275, 0.1270, 0.1261, 0.1323],
        [0.1135, 0.1137, 0.1163, 0.1300, 0.1310, 0.1283, 0.1316, 0.1355],
        [0.1119, 0.1117, 0.1179, 0.1314, 0.1279, 0.1324, 0.1286, 0.1383],
        [0.1116, 0.1113, 0.1143, 0.1302, 0.1293, 0.1318, 0.1320, 0.1395],
        [0.1113, 0.1112, 0.1121, 0.1286, 0.1306, 0.1336, 0.1326, 0.1401]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1313, 0.1285, 0.1223, 0.1238, 0.1239, 0.1245, 0.1216, 0.1241],
        [0.1265, 0.1249, 0.1226, 0.1249, 0.1246, 0.1243, 0.1262, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1304, 0.1274, 0.1260, 0.1221, 0.1242, 0.1238, 0.1250, 0.1211],
        [0.1275, 0.1261, 0.1270, 0.1222, 0.1247, 0.1225, 0.1267, 0.1233],
        [0.1215, 0.1195, 0.1262, 0.1227, 0.1229, 0.1287, 0.1293, 0.1292]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1303, 0.1273, 0.1263, 0.1220, 0.1235, 0.1234, 0.1247, 0.1224],
        [0.1277, 0.1264, 0.1241, 0.1218, 0.1268, 0.1248, 0.1256, 0.1228],
        [0.1205, 0.1204, 0.1278, 0.1252, 0.1268, 0.1250, 0.1254, 0.1288],
        [0.1206, 0.1205, 0.1267, 0.1264, 0.1282, 0.1254, 0.1259, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1302, 0.1268, 0.1216, 0.1237, 0.1264, 0.1248, 0.1269, 0.1196],
        [0.1275, 0.1258, 0.1229, 0.1277, 0.1236, 0.1263, 0.1231, 0.1231],
        [0.1202, 0.1185, 0.1275, 0.1269, 0.1248, 0.1253, 0.1272, 0.1296],
        [0.1209, 0.1191, 0.1271, 0.1274, 0.1242, 0.1283, 0.1250, 0.1280],
        [0.1202, 0.1201, 0.1273, 0.1223, 0.1286, 0.1252, 0.1274, 0.1288]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
02/16 01:04:43 PM | Train: [50/50] Step 000/078 Loss1 2.142 Prec1@(1,5) (98.4%, 100.0%)
02/16 01:10:30 PM | Train: [50/50] Step 050/078 Loss1 2.141 Prec1@(1,5) (99.5%, 100.0%)
02/16 01:13:48 PM | Train: [50/50] Step 078/078 Loss1 2.140 Prec1@(1,5) (99.6%, 100.0%)
02/16 01:13:48 PM | Train: [50/50] Final Prec1@1 99.5600%
02/16 01:13:49 PM | Valid: [50/50] Step 000/078 Loss1 1.729 Prec1@(1,5) (62.5%, 95.3%)
02/16 01:14:00 PM | Valid: [50/50] Step 050/078 Loss1 1.336 Prec1@(1,5) (72.2%, 97.2%)
02/16 01:14:06 PM | Valid: [50/50] Step 078/078 Loss1 1.374 Prec1@(1,5) (72.1%, 97.2%)
02/16 01:14:06 PM | Valid: [50/50] Final Prec1@1 72.0600%
02/16 01:14:06 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_3x3', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 3)], [('max_pool_3x3', 0), ('sep_conv_5x5', 4)]], reduce_concat=range(2, 6))
02/16 01:14:06 PM | Final best Prec1@1 = 65.8000%
02/16 01:14:06 PM | Best Genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_3x3', 3), ('dil_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_5x5', 1)], [('max_pool_3x3', 0), ('dil_conv_5x5', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 4), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
